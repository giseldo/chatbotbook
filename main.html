<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>main</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="main_files/libs/clipboard/clipboard.min.js"></script>
<script src="main_files/libs/quarto-html/quarto.js"></script>
<script src="main_files/libs/quarto-html/popper.min.js"></script>
<script src="main_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="main_files/libs/quarto-html/anchor.min.js"></script>
<link href="main_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="main_files/libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="main_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="main_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="main_files/libs/bootstrap/bootstrap-1bc8a17f135ab3d594c857e9f48e611b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<figure class="figure">
</figure>
<section id="chatbots-definições-e-contexto" class="level1">
<h1>Chatbots: Definições e Contexto</h1>
<section id="introdução" class="level2">
<h2 class="anchored" data-anchor-id="introdução">Introdução</h2>
<p>Um chatbot é um programa de computador que simula uma conversa humana, geralmente utilizando texto ou áudio. Eles oferecem respostas diretas a perguntas e auxiliam em diversas tarefas, servindo tanto para conversas gerais quanto para ações específicas, como abrir uma conta bancária.</p>
<p>Embora o chatbot ELIZA <span class="citation" data-cites="Weizenbaum1996">(<a href="#ref-Weizenbaum1996" role="doc-biblioref">Weizenbaum 1966</a>)</span> seja frequentemente considerado um dos primeiros exemplos de software conversacional, o termo “chatbot” ainda não era utilizado na época de sua criação. O termo “chatterbot”, sinônimo de “chatbot”, foi popularizado por Michael Mauldin em 1994, ao descrever seu programa JULIA <span class="citation" data-cites="Mauldin1994">(<a href="#ref-Mauldin1994" role="doc-biblioref">Mauldin 1994</a>)</span>. Publicações acadêmicas, como os anais da <em>Virtual Worlds and Simulation Conference</em> de 1998 <span class="citation" data-cites="Jacobstein1998">(<a href="#ref-Jacobstein1998" role="doc-biblioref">Jacobstein et al. 1998</a>)</span>, também ajudaram a consolidar o uso do termo.</p>
<p>O ELIZA, criado em 1966 por Joseph Weizenbaum, representou um experimento revolucionário na interação humano-computador <span class="citation" data-cites="Weizenbaum1996">(<a href="#ref-Weizenbaum1996" role="doc-biblioref">Weizenbaum 1966</a>)</span>. Seu roteiro (ou script) mais famoso, DOCTOR, imitava rudimentarmente um psicoterapeuta, utilizando correspondência de padrões simples. Por exemplo, quando um usuário inseria a frase “Estou triste”, o ELIZA respondia “Por que você está triste hoje?”, reformulando a entrada como uma pergunta. Seu funcionamento baseia-se em um conjunto de regras que lhe permitem analisar e compreender a linguagem humana de forma limitada e aproximada.</p>
<p>Esse tipo de aplicação do ELIZA (simular um psicólogo muito rudimentar da técnica rogeriana) adequou-se bem a esse domínio, pois dependia de pouco conhecimento sobre o ambiente externo; as regras no script DOCTOR permitiam que o programa respondesse ao usuário com outras perguntas ou simplesmente refletisse a afirmação original. O ELIZA não possuía uma real “compreensão” da linguagem humana; ele apenas utilizava palavras-chave e manipulava frases para que a interação parecesse natural. Uma descrição detalhada do funcionamento do ELIZA, com exemplos em Python, será apresentada em seções posteriores deste livro.</p>
<p>Outro chatbot famoso é o ChatGPT. Desenvolvido pela OpenAI, este é um modelo de linguagem capaz de gerar texto muito semelhante ao criado por humanos. Ele utiliza aprendizagem profunda (deep learning) e redes neurais para gerar sentenças e parágrafos com base nas entradas e informações fornecidas. É capaz de produzir textos coerentes e até mesmo realizar tarefas simples, como responder a perguntas e gerar ideias. Contudo, é importante lembrar que o ChatGPT não possui consciência nem a capacidade de compreender contexto ou emoções. Ele é um exemplo de Modelo de Linguagem Grande (Large Language Model - LLM), baseado na arquitetura conhecida como Transformers, introduzida em 2017 <span class="citation" data-cites="Vaswani2017">(<a href="#ref-Vaswani2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. Esses modelos são treinados com terabytes de texto, utilizando mecanismos de autoatenção que avaliam a relevância de cada palavra em uma frase. Ao contrário das regras manuais do ELIZA, os LLMs extraem padrões linguísticos a partir da vasta quantidade de dados com que a rede neural foi treinada.</p>
<p>Esses dois chatbots, ELIZA e ChatGPT, são bons representantes do tipo <strong>conversacional</strong>. Apesar de terem surgido com décadas de diferença — ELIZA em 1966 e ChatGPT em 2022 — e de diferirem bastante na forma como geram suas respostas, ambos compartilham semelhanças em seu objetivo: conversar sobre determinado assunto ou responder perguntas, mantendo o usuário em um diálogo fluido quando necessário. Chatbots com essas características podem ser agrupados, de acordo com o objetivo, como chatbots conversacionais e são utilizados para interagir sobre assuntos gerais.</p>
<p>Outro tipo de chatbot classificado em relação ao objetivo é o <strong>orientado a tarefas</strong>. Os chatbots orientados a tarefas executam ações específicas, como abrir uma conta bancária ou pedir uma pizza. Geralmente, as empresas disponibilizam chatbots orientados a tarefas para seus usuários, com regras de negócio embutidas na conversação e com fluxos bem definidos. Normalmente, não se espera pedir uma pizza e, no mesmo chatbot, discutir os estudos sobre Ética do filósofo Immanuel Kant (embora talvez haja quem queira).</p>
<p>Essas duas classificações - conversacional e orientado a tarefas - (Figura&nbsp;<a href="#fig:tipo" data-reference-type="ref" data-reference="fig:tipo">1.1</a>) ainda não são suficientes para uma completa classifição dada diversas caractéristicas e enorme quantidade de chatbots existentes. Existem outras classificações que serão discutidas em seções posteriores.</p>
<figure id="fig:tipo" class="figure">
<figcaption>
Classificação chatbots.
</figcaption>
</figure>
<p>A popularidade dos chatbots tem crescido significativamente em diversos domínios de aplicação <span class="citation" data-cites="B2020 Klopfenstein2017 Sharma2020">(<a href="#ref-B2020" role="doc-biblioref">Marcondes, Almeida, and Novais 2020</a>; <a href="#ref-Klopfenstein2017" role="doc-biblioref">Klopfenstein et al. 2017</a>; <a href="#ref-Sharma2020" role="doc-biblioref">Sharma, Verma, and Sahni 2020</a>)</span>. Essa tendência é corroborada pelo aumento do interesse de busca pelo termo “chatbots”, conforme análise de dados do Google Trends no período entre 2020 e 2025 (Figura&nbsp;<a href="#fig:trends" data-reference-type="ref" data-reference="fig:trends">1.2</a>). Nesta figura, os valores representam o interesse relativo de busca ao longo do tempo, onde 100 indica o pico de popularidade no período analisado e 0 (ou a ausência de dados) indica interesse mínimo ou dados insuficientes.</p>
<figure id="fig:trends" class="figure">
<p>
<img src="fig/trends.png" style="width:100.0%" alt="image" class="figure-img"> <span id="fig:trends" data-label="fig:trends"></span> <span>Fonte: Google Trends acesso em 05/04/2025</span>
</p>
<figcaption>
Evolução do interesse de busca pelo termo “chatbot” (Google Trends, 2020-2025).
</figcaption>
</figure>
</section>
<section id="chatbots-e-agentes-definições-e-distinções" class="level2">
<h2 class="anchored" data-anchor-id="chatbots-e-agentes-definições-e-distinções">Chatbots e Agentes: Definições e Distinções</h2>
<p>Define-se chatbot como um programa computacional projetado para interagir com usuários por meio de linguagem natural. Por outro lado, o conceito de agente possui uma definição mais ampla: trata-se de uma entidade computacional que percebe seu ambiente por meio de sensores e atua sobre esse ambiente por meio de atuadores <span class="citation" data-cites="Russel2013">(<a href="#ref-Russel2013" role="doc-biblioref">Russel and Norving 2013</a>)</span>. A Figura&nbsp;<a href="#fig:agente" data-reference-type="ref" data-reference="fig:agente">1.3</a> ilustra uma arquitetura conceitual de alto nível para um agente.</p>
<figure id="fig:agente" class="figure">
<p>
<img src="fig/ia.png" style="width:70.0%" alt="image" class="figure-img"> <span id="fig:agente" data-label="fig:agente"></span>
</p>
<p>
Fonte: Diretamente retirado de <span class="citation" data-cites="Russel2013"></span>
</p>
<figcaption>
Arquitetura conceitual de um agente.
</figcaption>
</figure>
<p>Nesse contexto, um chatbot (Figura&nbsp;<a href="#fig:chatbot" data-reference-type="ref" data-reference="fig:chatbot">1.4</a>) pode ser considerado uma instanciação específica de um agente, cujo propósito primário é a interação conversacional em linguagem natural.</p>
<figure id="fig:chatbot" class="figure">
<p>
<img src="fig/chatbot.png" style="width:90.0%" alt="image" class="figure-img"> <span id="fig:chatbot" data-label="fig:chatbot"></span>
</p>
<figcaption>
Representação esquemática de um chatbot.
</figcaption>
</figure>
<p>Com o advento de modelos de linguagem avançados, como os baseados na arquitetura <em>Generative Pre-trained Transformer</em> (GPT), a exemplo do ChatGPT, observou-se uma recontextualização do termo “agente” no domínio dos sistemas conversacionais. Nessa abordagem mais recente, um sistema focado predominantemente na geração de texto conversacional tende a ser denominado “chatbot”. Em contraste, o termo “agente” é frequentemente reservado para sistemas que, além da capacidade conversacional, integram e utilizam ferramentas externas (por exemplo, acesso à internet, execução de código, interação com APIs) para realizar tarefas complexas e interagir proativamente com o ambiente digital. Um sistema capaz de realizar uma compra online, processar um pagamento e confirmar um endereço de entrega por meio do navegador do usuário seria, portanto, classificado como um agente, diferentemente de chatbots mais simples como ELIZA, ou mesmo versões mais simples do chatGPT (GPT-2), cujo foco era estritamente o diálogo.</p>
</section>
<section id="gerenciamento-do-diálogo-e-fluxo-conversacional" class="level2">
<h2 class="anchored" data-anchor-id="gerenciamento-do-diálogo-e-fluxo-conversacional">Gerenciamento do Diálogo e Fluxo Conversacional</h2>
<p>Um chatbot responde a uma entrada do usuário. Porém, essa interação textual mediada por chatbots não se constitui em uma mera justaposição aleatória de turnos de conversação ou pares isolados de estímulo-resposta. Pelo contrário, espera-se que a conversação exiba coerência e mantenha relações lógicas e semânticas entre os turnos consecutivos. O estudo da estrutura e organização da conversa humana é abordado por disciplinas como a Análise da Conversação.</p>
<p>No contexto da da análise da conversação em língua portuguesa, os trabalhos de Marcuschi <span class="citation" data-cites="Marchuschi1986">(<a href="#ref-Marchuschi1986" role="doc-biblioref">Marcuschi 1986</a>)</span> são relevantes ao investigar a organização dessa conversação. Marcuschi analisou a estrutura conversacional em termos de unidades coesas, como o “tópico conversacional”, que agrupa turnos relacionados a um mesmo assunto ou propósito interacional.</p>
<p>Conceitos oriundos da Análise da Conversação, como a gestão de tópicos, têm sido aplicados no desenvolvimento de chatbots para aprimorar sua capacidade de manter diálogos coerentes e contextualmente relevantes com usuários humanos <span class="citation" data-cites="Neves2005">(<a href="#ref-Neves2005" role="doc-biblioref">Neves and Barros 2005</a>)</span>.</p>
<p>Na prática de desenvolvimento de sistemas conversacionais, a estrutura lógica e sequencial da interação é frequentemente modelada e referida como “fluxo de conversação” ou “fluxo de diálogo”. Contudo, é importante ressaltar que a implementação explícita de modelos sofisticados de gerenciamento de diálogo, inspirados na Análise da Conversação, não é uma característica universal de todos os chatbots, variando conforme a complexidade e o propósito do sistema.</p>
<p>Um exemplo esquemático de um fluxo conversacional é apresentado na Figura&nbsp;<a href="#fig:fluxo" data-reference-type="ref" data-reference="fig:fluxo">1.5</a>. Nesta figura o fluxo de conversação inicia quando o usuário entra com o texto: I WANT PIZZA, o chatbot responde com uma pergunta: HI I AM THE PIZZA BOT. CAN I CONFIRM THIS DELIVERY TO YOUR HOUSE?. O usuário então pode responder: SIM e o chatbot finaliza a conversa com: IT’S ON THE WAY. THANK YOU FOR CHOOSE OUR PRODUCT. Caso o usuário responda: NO, o chatbot responde com a pergunta original: HI I AM THE PIZZA BOT. CAN I CONFIRM THIS DELIVERY TO YOUR HOUSE?. O fluxo de conversação continua até que o usuário responda com um “sim” para a pergunta inicial. Essa estrutura de perguntas e respostas é comum em chatbots orientados a tarefas, onde o objetivo é guiar o usuário por um processo específico, como fazer um pedido de pizza.</p>
<figure id="fig:fluxo" class="figure">
<p>
<img src="fig/fluxo.png" style="width:100.0%" alt="image" class="figure-img"> <span id="fig:fluxo" data-label="fig:fluxo"></span>
</p>
<figcaption>
Exemplo esquemático de um fluxo conversacional em um chatbot.
</figcaption>
</figure>
<p>Um outro tipo de fluxo para um chatbot que vende roupas está representada na Figura&nbsp;<a href="#fig:representacaodeumaarvore" data-reference-type="ref" data-reference="fig:representacaodeumaarvore">1.6</a>.</p>
<figure id="fig:representacaodeumaarvore" class="figure">
<p>
<img src="./fig/image14.png" style="width:90.0%" alt="image" class="figure-img"> <span id="fig:representacaodeumaarvore" data-label="fig:representacaodeumaarvore"></span>
</p>
<p>
Retirado de <span class="citation" data-cites="Raj2019"></span>.
</p>
<figcaption>
Representação de uma árvore de decisão para comprar roupas online
</figcaption>
</figure>
</section>
<section id="depois-do-eliza" class="level2">
<h2 class="anchored" data-anchor-id="depois-do-eliza">Depois do ELIZA</h2>
<p>Um marco significativo na evolução dos chatbots foi o ALICE, que introduziu a Artificial Intelligence Markup Language (AIML), uma linguagem de marcação baseada em XML <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>. A AIML estabeleceu um paradigma para a construção de agentes conversacionais ao empregar algoritmos de correspondência de padrões. Essa abordagem utiliza modelos pré-definidos para mapear as entradas do usuário a respostas correspondentes, permitindo a definição modular de blocos de conhecimento <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>.</p>
<p>No contexto brasileiro, um dos primeiros chatbots documentados capaz de interagir em português, inspirado no modelo ELIZA, foi o Cybele <span class="citation" data-cites="primo2001chatterbot">(<a href="#ref-primo2001chatterbot" role="doc-biblioref">PRIMO and COELHO 2001</a>)</span>. Posteriormente, foi desenvolvido o Elecktra, também em língua portuguesa, com aplicação voltada para a educação a distância <span class="citation" data-cites="Leonhardt2003">(<a href="#ref-Leonhardt2003" role="doc-biblioref">Leonhardt, Neisse, and Tarouco 2003</a>)</span>. Em um exemplo mais recente de aplicação governamental, no ano de 2019, o processo de inscrição para o Exame Nacional do Ensino Médio (ENEM) foi disponibilizado por meio de uma interface conversacional baseada em chatbot (Figura&nbsp;<a href="#fig:enem" data-reference-type="ref" data-reference="fig:enem">1.7</a>).</p>
<figure id="fig:enem" class="figure">
<p>
<img src="fig/enem.png" style="width:50.0%" alt="image" class="figure-img"> <span id="fig:enem" data-label="fig:enem"></span>
</p>
<p>
Fonte: Captura de tela realizada por Giseldo Neo.
</p>
<figcaption>
Interface de chatbot para inscrição no ENEM 2019.
</figcaption>
</figure>
<p>O desenvolvimento de chatbots avançados tem atraído investimentos de grandes corporações. Notavelmente, a IBM desenvolveu um sistema de resposta a perguntas em domínio aberto utilizando sua plataforma Watson <span class="citation" data-cites="Ferrucci2012">(<a href="#ref-Ferrucci2012" role="doc-biblioref">Ferrucci 2012</a>)</span>. Esse tipo de tarefa representa um desafio computacional e de inteligência artificial (IA) considerável. Em 2011, o sistema baseado em Watson demonstrou sua capacidade ao competir e vencer competidores humanos no programa de perguntas e respostas JEOPARDY! <span class="citation" data-cites="Ferrucci2012">(<a href="#ref-Ferrucci2012" role="doc-biblioref">Ferrucci 2012</a>)</span>.</p>
<p>Diversos outros chatbots foram desenvolvidos para atender a demandas específicas em variados domínios. Exemplos incluem: BUTI, um companheiro virtual com computação afetiva para auxiliar na manutenção da saúde cardiovascular <span class="citation" data-cites="Junior2008">(<a href="#ref-Junior2008" role="doc-biblioref">Junior 2008</a>)</span>; EduBot, um agente conversacional projetado para a criação e desenvolvimento de ontologias com lógica de descrição <span class="citation" data-cites="Lima2017">(<a href="#ref-Lima2017" role="doc-biblioref">Lima 2017</a>)</span>; PMKLE, um ambiente inteligente de aprendizado focado na educação em gerenciamento de projetos <span class="citation" data-cites="Torreao2005">(<a href="#ref-Torreao2005" role="doc-biblioref">Torreao 2005</a>)</span>; RENAN, um sistema de diálogo inteligente fundamentado em lógica de descrição <span class="citation" data-cites="AZEVEDO2015">(<a href="#ref-AZEVEDO2015" role="doc-biblioref">Azevedo 2015</a>)</span>; e MOrFEu, voltado para a mediação de atividades cooperativas em ambientes inteligentes na Web <span class="citation" data-cites="Bada2012">(<a href="#ref-Bada2012" role="doc-biblioref">Bada 2012</a>)</span>.</p>
<p>Entre os chatbots baseado em LLMs de destaque atualmente estão o Qwen, desenvolvido pela Alibaba, que se destaca por sua eficiência e suporte multilíngue; o DeepSeek, de código aberto voltado para pesquisa e aplicações empresariais com foco em precisão e escalabilidade; o Maritaca, modelo brasileiro de otimizado para o português; o Gemini, da Google, que integra capacidades multimodais e forte desempenho em tarefas diversas; o Mixtral, da Mistral AI, que utiliza arquitetura de mistura de especialistas para maior eficiência; o Llama, da Meta, reconhecido por ser código aberto e ampla adoção na comunidade; o Claude, da Anthropic, projetado com ênfase em segurança, alinhamento ético que vem ganhando adeptos para tarefas e codificação; e o Nemotron, da NVIDIA, que oferece modelos de linguagem otimizados para execução em GPUs e aplicações empresariais de alto desempenho.</p>
</section>
<section id="abordagens" class="level2">
<h2 class="anchored" data-anchor-id="abordagens">Abordagens</h2>
<p>Desde o pioneirismo do ELIZA, múltiplas abordagens e técnicas foram exploradas para o desenvolvimento de chatbots. Entre as mais relevantes, destacam-se: AIML com correspondência de padrões (pattern matching), análise sintática (Parsing), modelos de cadeia de Markov (Markov Chain Models), uso de ontologias, redes neurais recorrentes (RNNs), redes de memória de longo prazo (LSTMs), modelos neurais sequência-a-sequência (Sequence-to-Sequence), aprendizado adversarial para geração de diálogo, além de abordagens baseadas em recuperação (Retrieval-Based) e generativas (Generative-Based) <span class="citation" data-cites="Borah2019 Ramesh2019 Shaikh2016 Abdul-Kader2015 Li2018">(<a href="#ref-Borah2019" role="doc-biblioref">Borah, Pathak, and Sarmah 2019</a>; <a href="#ref-Ramesh2019" role="doc-biblioref">Ramesh et al. 2017</a>; <a href="#ref-Shaikh2016" role="doc-biblioref">Shaikh et al. 2016</a>; <a href="#ref-Abdul-Kader2015" role="doc-biblioref">Abdul-Kader and Woods 2015</a>; <a href="#ref-Li2018" role="doc-biblioref">Li et al. 2018</a>)</span>, entre outras.</p>
<p>Além disso, diversos frameworks têm sido desenvolvidos para facilitar a criação desses agentes complexos, como CrewAI e bibliotecas associadas a plataformas como Hugging Face (e.g., Transformers Agents), que fornecem abstrações e ferramentas em Python para orquestrar múltiplos componentes e o uso de ferramentas externas.</p>
</section>
<section id="problemática" class="level2">
<h2 class="anchored" data-anchor-id="problemática">Problemática</h2>
<p>Apesar do progresso recente de chatbots, como o ChatGPT, o mecanismo fundamental da inteligência em nível humano, frequentemente refletido na comunicação, ainda não está totalmente esclarecido <span class="citation" data-cites="Shum2018">(<a href="#ref-Shum2018" role="doc-biblioref">Shum, He, and Li 2018</a>)</span>. Para avançar na solução desses desafios, serão necessários progressos em diversas áreas da IA cognitiva, tais como: modelagem empática de conversas, modelagem de conhecimento e memória, inteligência de máquina interpretável e controlável, e calibração de recompensas emocionais <span class="citation" data-cites="Shum2018">(<a href="#ref-Shum2018" role="doc-biblioref">Shum, He, and Li 2018</a>)</span>.</p>
<p>Uma das dificuldades na construção de chatbots do tipo orientado a tarefas reside em gerenciar a complexidade das estruturas condicionais ("se-então") que definem o fluxo do diálogo <span class="citation" data-cites="Raj2019">(<a href="#ref-Raj2019" role="doc-biblioref">Raj 2019</a>)</span>. Quanto maior o número de decisões a serem tomadas, mais numerosas e intrincadas tendem a ser essas estruturas condicionais. Contudo, elas são essenciais para codificar fluxos de conversação complexos. Se a tarefa que o chatbot visa simular é inerentemente complexa e envolve múltiplas condições, o código precisará refletir essa complexidade. Para facilitar a visualização desses fluxos, uma solução eficaz é a utilização de fluxogramas. Embora simples de criar e entender, os fluxogramas constituem uma poderosa ferramenta de representação para este problema.</p>
<p>Os chatbots baseados em AIML apresentam desvantagens específicas. Por exemplo, o conhecimento é representado como instâncias de arquivos AIML. Se esse conhecimento for criado com base em dados coletados da Internet, ele não será atualizado automaticamente, exigindo atualizações periódicas manuais <span class="citation" data-cites="Madhumitha2015">(<a href="#ref-Madhumitha2015" role="doc-biblioref">Madhumitha, Keerthana, and Hemalatha 2015</a>)</span>. No entanto, já existem abordagens para mitigar essa limitação, permitindo carregar conteúdo AIML a partir de fontes como arquivos XML <span class="citation" data-cites="Macedo2014">(<a href="#ref-Macedo2014" role="doc-biblioref">Macedo and Fusco 2014</a>)</span>, um corpus textual <span class="citation" data-cites="DeGasperis2013">(<a href="#ref-DeGasperis2013" role="doc-biblioref">De Gasperis, Chiari, and Florio 2013</a>)</span> ou dados do Twitter <span class="citation" data-cites="Yamaguchi2018">(<a href="#ref-Yamaguchi2018" role="doc-biblioref">Yamaguchi, Mozgovoy, and Danielewicz-Betz 2018</a>)</span>.</p>
<p>Outra desvantagem do AIML, a exemplo do Eliza, reside na relativa complexidade de seus padrões de correspondência (patterns). Além disso, a manutenção do sistema pode ser árdua, pois, embora a inserção de conteúdo (categorias) seja conceitualmente simples, grandes volumes de informação frequentemente precisam ser adicionados manualmente <span class="citation" data-cites="Madhumitha2015">(<a href="#ref-Madhumitha2015" role="doc-biblioref">Madhumitha, Keerthana, and Hemalatha 2015</a>)</span>.</p>
<p>Especificamente no caso do AIML, a construção e a visualização de fluxos de diálogo complexos enfrentam dificuldades adicionais. Devido ao seu formato baseado em texto, muitas vezes é difícil perceber claramente como as diferentes categorias (unidades de conhecimento e resposta) se interligam para formar a estrutura da conversação.</p>
</section>
</section>
<section id="eliza-explicado" class="level1">
<h1>Eliza Explicado</h1>
<section id="introdução-1" class="level2">
<h2 class="anchored" data-anchor-id="introdução-1">Introdução</h2>
<p>o ELIZA foi um dos primeiros programas de processamento de linguagem natural e foi apresentado em 1966 por Joseph Weizenbaum no MIT <span class="citation" data-cites="Weizenbaum1996">(<a href="#ref-Weizenbaum1996" role="doc-biblioref">Weizenbaum 1966</a>)</span>.</p>
<p>O conjunto de padrões e respostas predefinidas constitui o que Weizenbaum chamou de “roteiro” (ou script) de conversa. O mecanismo do ELIZA separa o motor genérico de processamento (o algoritmo de busca de palavras-chave e aplicação de regras) dos dados do script em si. Isso significa que ELIZA podia em teoria simular diferentes personalidades ou tópicos apenas carregando um script diferente, sem alterar o código do programa (veja na Figura&nbsp;<a href="#fig:elizaeditor" data-reference-type="ref" data-reference="fig:elizaeditor">2.1</a>). Também foi codificado um editor de texto para as alterações do próprio Script.</p>
<figure id="fig:elizaeditor" class="figure">
<figcaption>
ELIZA: separação entre o código fonte, o script e o editor de texto.
</figcaption>
</figure>
<p>Um destes scripts (o DOCTOR) o deixou famoso. Com este script carregado, o ELIZA simulava precariamente um psicoterapeuta (do estilo Rogeriano), refletindo as palavras do usuário de volta em forma de pergunta. A primeira linha do script é a introdução do chatbot, a primeira palavra que ele escrever para o usuário. START é um comando técnico do script, serve para indicar que a seguir virão as regras. REMEMBER 5 estabelece que a prioridade da palavra REMEMBER é 5, ou seja, se o usuário disser algo que contenha a palavra REMEMBER, o ELIZA irá responder com uma das perguntas definidas entre parênteses. A seguir estão as regras de transformação de frases (decomposition rule e reassembly rule) associadas à palavra-chave REMEMBER. O exemplo abaixo mostra um trecho do script DOCTOR:</p>
<pre><code>    (REMEMBER 5 
        (
            (0 YOU REMEMBER 0) 
            (DO YOU OFTEN THINK OF 4) 
            (DOES THINKING OF ~ BRING ANYTHING ELSE TO MINO) 
            (WHAT ELSE OO YOU REMEMBER)
            (WHY DO YOU REMEMBER 4 JUST NOW) 
            (WHAT IN THE PRESENT SITUATION REMINDS YOU OF 4) 
            (WHAT IS THE CONNECTION BETWEEN ME AND 4)
        ) 
        (
            (0 DO I REMEMBER 0) 
            (DID YOU THINK I WOULD FORGET 5) 
            (WHY DO YOU THINK I SHOULD RECALL 5 NOW) 
            (WHAT ABOUT 5) 
            (=WHAT) 
            (YOU MENTIONED S)
        ) 
    ) 
    
    (IF 3 
        (
            (0 IF 0) 
            (DO YOU THINK ITS LIKELY THAT 3) 
            (DO YOU WISH THAT 3) 
            (WHAT DO YOU THINK ABOUT 3) 
            (REALLY, 2 3)
        )
    ) 
    </code></pre>
<p>A seguir é apresentado um exemplo de diálogo (retirado do artigo original) entre um usuário humano e ELIZA, mostrando as respostas em letras maiúsculas. Nesse exemplo, o usuário faz afirmações pessoais (“Men are all alike.”, “Well, my boyfriend made me come here.”) e ELIZA responde com perguntas ou reformulações (“IN WHAT WAY”, “YOUR BOYFRIEND MADE YOU COME HERE?”), reutilizando termos do próprio usuário. Esse estilo reflexivo encoraja o usuário a continuar falando sem fornecer respostas diretas.</p>
<pre><code>    Men are all alike. 
    IN WHAT WAY 
    They're always bugging us about something or other. 
    CAN YOU THINK OF A SPECIFIC EXAMPLE 
    Well, my boyfriend made me come here. 
    YOUR BOYFRIEND MADE YOU COME HERE 
    He says I'm depressed much of the time. 
    I AM SORRY TO HEAR YOU ARE DEPRESSED 
    It's true. I am unhappy. 
    DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY 
    I need some help, that much seems certain. 
    WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP 
    Perhaps I could learn to get along with my mother. 
    TELL ME MORE ABOUT YOUR FAMILY 
    My mother takes care of me. 
    WHO ELSE IN YOUR FAMILY TAKES CARE OF YOU 
    My father. 
    YOUR FATHER 
    You are like my father in some ways. 
    WHAT RESEMBLANCE DO YOU SEE 
    You are not very aggressive but I think you don't want me to 
    notice that. 
    WHAT MAKES YOU THINK I AM NOT VERY AGGRESSIVE 
    You don't argue with me. 
    WHY DO YOU THINK I DON'T ARGUE WITH YOU 
    You are afraid of me. 
    DOES IT PLEASE YOU TO BELIEVE I AM AFRAID OF YOU 
    My father is afraid of everybody. 
    WHAT ELSE COMES TO MIND WHEN YOU THINK OF YOUR FATHER 
    Bullies. 
    DOES THAT HAVE ANYTHING TO DO WITH THE FACT THAT YOUR BOYFRIEND MADE YOU COME HERE </code></pre>
</section>
<section id="processamento-de-entradas-e-palavras-chave" class="level2">
<h2 class="anchored" data-anchor-id="processamento-de-entradas-e-palavras-chave">Processamento de Entradas e Palavras-Chave</h2>
<p>O funcionamento do ELIZA baseia-se em correspondência de padrões por palavras-chave. Técnica também chamado casamento de padrão, em inglês <em>pattner matching</em> seu paradigma também se encaixa na técnica baseado em regras (ou <em>rule-based</em>). A cada turno, o texto de entrada do usuário é analisado em busca de palavras-chave predefinidas. O ELIZA fazia uma varredura da sentença da esquerda para a direita, identificando se alguma palavra correspondia a uma palavrachave do script. Caso encontrasse, ELIZA selecionava a palavra-chave mais “importante” (havia um peso de prioridade associado a cada palavra-chave) e ignorava o restante da entrada.</p>
<p>Por exemplo, o script DOCTOR, definia palavras-chave como “ALIKE” ou “SAME” com alta prioridade; assim, na frase “Men are all alike.” o programa detectava a palavra “ALIKE” e disparava uma resposta associada a ela (no caso: “In what way?”). Se múltiplas palavras-chave aparecessem, ELIZA escolhia aquela de maior peso para formular a resposta.</p>
<p>Primeiro o texto de entrada digitado pelo usuário era separado em palavras, em um técnica que hoje chamamos de tokenização de palavras. A palavra-chave era identificada, comparando-a sequencialmente até o fim das palavras existentes, ou até ser encontrado uma pontuação. Caso fosse encontrado uma pontuação (ponto final ou vírgula), o texto após a pontuação era ignorado se já tivesse sido identificado uma palavra-chave. Assim cada processamento da resposta foca em apenas uma única afirmação (ou frase) do usuário. Se várias palavras-chave fossem encontradas antes da pontuação, a de maior peso era selecionada.</p>
<p>Por exemplo, o usuário entra com o texto: “I am sick. but, today is raining”. Se houvesse uma palavra-chave no script rankeando a palavra “SICK" com alta prioridade, a entrada processada seria somente”I am sick”, o restante depois da pontuação (neste caso, o ponto) seria gnorado pelo programa.</p>
<p>Se nenhuma palavra-chave fosse encontrada na entrada, ELIZA recorria a frases genéricas programadas, chamadas de respostas vazias ou sem conteúdo. Nesses casos, o chatbot emitia mensagens do tipo “I see.” ou “Please, go on.” . Esse mecanismo evitava silêncio quando o usuário dizia algo fora do escopo do script.</p>
<p>Além disso, a implementação original incluía uma estrutura de memória: algumas declarações recentes do usuário eram armazenadas e, se uma entrada subsequente não contivesse novas keywords, ELIZA poderia recuperar um tópico anterior e introduzi-lo na conversa. Por exemplo, se o usuário mencionasse família em um momento e depois fizesse uma afirmação vaga, o programa poderia responder retomando o assunto da família (“DOES THAT HAVE ANYTHING TO DO WITH YOUR FAMILY?”). Essa estratégia dava uma pseudo-continuidade ao diálogo, simulando que o sistema “lembrava” de informações fornecidas anteriormente.</p>
</section>
<section id="regras-de-transformação-de-frases" class="level2">
<h2 class="anchored" data-anchor-id="regras-de-transformação-de-frases">Regras de Transformação de Frases</h2>
<p>Encontrada a palavra-chave, ELIZA aplicava uma regra de transformação associada a ela para gerar a resposta. As regras são definidas em pares: um padrão de análise (decomposition rule) e um modelo de reconstrução de frase (reassembly rule).</p>
<p>Primeiro, a frase do usuário é decomposta conforme um padrão que identifica a contexto mínimo em torno da palavra-chave. Essa decomposição frequentemente envolve separar a frase em partes e reconhecer pronomes ou estruturas gramaticais relevantes. Por exemplo, considere a entrada “You are very helpful.”. Uma regra de decomposição pode identificar a estrutura “You are X” — onde “X” representa o restante da frase — e extrair o complemento “very helpful” como um componente separado.</p>
<p>Em seguida, a regra de reassembly correspondente é aplicada, remontando uma sentença de resposta em que “X” é inserido em um template pré-definido. No exemplo dado, o template de resposta poderia ser “What makes you think I am X?”; ao inserir X = “very helpful”, gera-se “What makes you think I am very helpful?”. Observe que há uma inversão de pessoa: o pronome “you” do usuário foi trocado por “I” na resposta do bot.</p>
<p>De fato, uma parte importante das transformações do ELIZA envolve substituir pronomes (eu/você, meu/seu) para que a resposta faça sentido como uma frase do ponto de vista do computador falando com o usuário. Esse algoritmo de substituição é relativamente simples (por exemplo, “meu” → “seu”, “eu” → “você”, etc.), mas essencial para dar a impressão de entendimento gramatical.</p>
</section>
<section id="implementação-original-e-variações-modernas" class="level2">
<h2 class="anchored" data-anchor-id="implementação-original-e-variações-modernas">Implementação Original e Variações Modernas</h2>
<p>A implementação original de ELIZA foi feita em uma linguagem chamada MAD-SLIP (um dialecto de Lisp) rodando em um mainframe IBM 7094 no sistema CTSS do MIT. O código fonte do programa principal continha o mecanismo de correspondência, enquanto as regras de conversação (script DOCTOR) eram fornecidas separadamente em formato de listas associativas, similar a uma lista em Lisp. Infelizmente, Weizenbaum não publicou o código completo no artigo de 1966 (o que era comum na época), mas décadas depois o código em MAD-SLIP foi recuperado nos arquivos do MIT, comprovando os detalhes de implementação <span class="citation" data-cites="Lane2025">(<a href="#ref-Lane2025" role="doc-biblioref">Lane et al. 2025</a>)</span>. De qualquer forma, a arquitetura descrita no artigo influenciou inúmeras reimplementações acadêmicas e didáticas nos anos seguintes.</p>
<p>Diversos entusiastas e pesquisadores reescreveram ELIZA em outras linguagens de programação, dada a simplicidade relativa de seu algoritmo. Ao longo dos anos surgiram versões em Lisp, PL/I, BASIC, Pascal, Prolog, Java, Python, OZ, JavaScript, entre muitas outras. Cada versão normalmente incluía o mesmo conjunto de regras do script terapeuta ou pequenas variações.</p>
<p>As ideias de ELIZA também inspiraram chatbots mais avançados. Poucos anos depois, em 1972, surgiu PARRY, escrito pelo psiquiatra Kenneth Colby, que simulava um paciente paranoico. PARRY tinha um modelo interno de estado emocional e atitudes, mas na camada de linguagem ainda usava muitas respostas baseadas em regras, chegando a “conversar” com o próprio ELIZA em experimentos da época.</p>
<p>Em 1995, Richard Wallace desenvolveu o chatbot ALICE (Artificial Linguistic Internet Computer Entity), que levava o paradigma de ELIZA a uma escala muito maior. ALICE utilizava um formato XML chamado AIML (Artificial Intelligence Markup Language) para definir milhares de categorias de padrões e respostas. Com mais de 16.000 templates mapeando entradas para saídas <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>, ALICE conseguia manter diálogos bem mais naturais e abrangentes que o ELIZA original, embora o princípio básico de correspondência de padrões permanecesse. Esse avanço rendeu a ALICE três vitórias no Prêmio Loebner (competição de chatbots) no início dos anos 2000 <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>.</p>
<p>Outras variações e sucessores notáveis incluem Jabberwacky (1988) – que já aprendia novas frases – e uma profusão de assistentes virtuais e bots de domínio específico nas décadas seguintes <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>. Em suma, o legado de ELIZA perdurou por meio de inúmeros chatbots baseados em regras, até a transição para abordagens estatísticas e de aprendizado de máquina no final do século XX.</p>
</section>
<section id="comparação-com-modelos-de-linguagem-modernos" class="level2">
<h2 class="anchored" data-anchor-id="comparação-com-modelos-de-linguagem-modernos">Comparação com Modelos de Linguagem Modernos</h2>
<p>A técnica de ELIZA, baseada em palavras-chave com respostas predefinidas, contrasta fortemente com os métodos de Large Language Models (LLMs) atuais, como o GPT-4, que utilizam redes neurais de milhões (ou trilhões) de parâmetros e mecanismos de atenção.</p>
<section id="mecanismo-de-pesos-palavras-chave-vs.-atenção-neural" class="level3">
<h3 class="anchored" data-anchor-id="mecanismo-de-pesos-palavras-chave-vs.-atenção-neural">Mecanismo de Pesos: Palavras-Chave vs.&nbsp;Atenção Neural</h3>
<p>No ELIZA, a “importância” de uma palavra era determinada manualmente pelo programador através de pesos ou rankings atribuídos a certas palavras-chave no script. Ou seja, o programa não aprendia quais termos focar – ele seguia uma lista fixa de gatilhos. Por exemplo, termos como “sempre” ou “igual” tinham prioridade alta no script DOCTOR para garantir respostas apropriadas.</p>
<p>Em contraste, modelos modernos como o GPT não possuem uma lista fixa de palavras importantes; em vez disso, eles utilizam o mecanismo de self-attention para calcular dinamicamente pesos entre todas as palavras da entrada conforme o contexto <span class="citation" data-cites="Vaswani2017">(<a href="#ref-Vaswani2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>.</p>
<p>Na arquitetura Transformer, cada palavra (token) de entrada gera consultas e chaves que interagem com todas as outras, permitindo ao modelo atribuir pesos maiores às palavras mais relevantes daquela frase ou parágrafo <span class="citation" data-cites="Vaswani2017">(<a href="#ref-Vaswani2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. Em outras palavras, o modelo aprende sozinho quais termos ou sequências devem receber mais atenção para produzir a próxima palavra na resposta. Esse mecanismo de atenção captura dependências de longo alcance e nuances contextuais que um sistema de palavras-chave fixas como o ELIZA não consegue representar.</p>
<p>Além disso, o “vocabulário” efetivo de um LLM é imenso – um moddelo GPT pode ser treinado com trilhões de palavras e ter ajustado seus parâmetros para modelar estatisticamente a linguagem humana <span class="citation" data-cites="Vaswani2017">(<a href="#ref-Vaswani2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. Como resultado, pode-se dizer metaforicamente que os LLMs têm uma lista de “palavras-chave” milhões de vezes maior (na prática, distribuída em vetores contínuos) e um método bem mais sofisticado de calcular respostas do que o ELIZA.</p>
<p>Enquanto ELIZA dependia de coincidências exatas de termos para disparar regras, modelos como GPT avaliam similaridades semânticas e contexto histórico graças às representações densas (embeddings) aprendidas durante o treinamento de rede neural.</p>
</section>
<section id="contextualização-e-geração-de-linguagem" class="level3">
<h3 class="anchored" data-anchor-id="contextualização-e-geração-de-linguagem">Contextualização e Geração de Linguagem</h3>
<p>Devido à sua abordagem baseada em regras locais, o ELIZA tinha capacidade de contextualização muito limitada. Cada input do usuário era tratado quase isoladamente: o programa não construía uma representação acumulada da conversa, além de artifícios simples como repetir algo mencionado (a estrutura de memória) ou usar pronomes para manter a ilusão de continuidade. Se o usuário mudasse de tópico abruptamente, o ELIZA não “perceberia” – ele apenas buscaria a próxima palavra-chave disponível ou recorreria a frases genéricas.</p>
<p>Em contraste, modelos de linguagem modernos levam em conta um longo histórico de diálogo. Chatbots que usam GPT podem manter um contexto centenas ou milhares de tokens (palavras ou fragmentos) em sua janela de atenção, o que significa que eles conseguem referenciar informações mencionadas vários parágrafos atrás e integrá-las na resposta corrente. O mecanismo de self-attention, em particular, permite que o modelo incorpore relações contextuais complexas: cada palavra gerada pode considerar influências de palavras distantes no texto de entrada <span class="citation" data-cites="Vaswani2017">(<a href="#ref-Vaswani2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>.</p>
<p>Por exemplo, ao conversar com um LLM, se você mencionar no início da conversa que tem um irmão chamado Alex e depois perguntar “ele pode me ajudar com o problema?”, o modelo entenderá que “ele” se refere ao Alex mencionado anteriormente (desde que dentro da janela de contexto). Já o ELIZA original não teria como fazer essa ligação, a menos que houvesse uma regra explícita para “ele” e algum armazenamento específico do nome – algo impraticável de antecipar via regras fixas para todos os casos.</p>
<p>Outra diferença crucial está na geração de linguagem. O ELIZA não gera texto original no sentido pleno: suas respostas são em grande parte frases prontas (ou templates fixos) embaralhadas com partes da fala do usuário. Assim, seu vocabulário e estilo são limitados pelo script escrito manualmente. Modelos GPT, por sua vez, geram respostas novas combinando probabilisticamente o conhecimento adquirido de um extenso corpus. Eles não se restringem a repetir trechos da entrada, podendo elaborar explicações, fazer analogias, criar perguntas inéditas – tudo coerente com os exemplos linguísticos em sua base de treinamento. Enquanto ELIZA tendia a responder com perguntas genéricas ou devolvendo as palavras do usuário, os LLMs podem produzir respostas informativas e detalhadas sobre o assunto (pois “aprenderam” uma ampla gama de tópicos durante o treinamento). Por exemplo, se perguntarmos algo factual ou complexo, o ELIZA falharia por não ter nenhuma regra a respeito, provavelmente dando uma resposta vazia. Já um modelo como GPT-4 tentará formular uma resposta baseada em padrões linguísticos aprendidos e em conhecimento implícito dos dados, muitas vezes fornecendo detalhes relevantes.</p>
<p>Em termos de fluência e variedade, os modelos modernos superam o ELIZA amplamente. O ELIZA frequentemente se repetia ou caía em loops verbais quando confrontado com inputs fora do roteiro – um limite claro de sistemas por regras estáticas. Os LLMs produzem linguagem muito mais natural e adaptável, a ponto de muitas vezes enganarem os usuários sobre estarem conversando com uma máquina (um efeito buscado desde o Teste de Turing). Ironicamente, ELIZA nos anos 60 já provocou um precursor desse fenômeno – o chamado Efeito ELIZA, em que pessoas atribuem compreensão ou sentimentos a respostas de computador que, na verdade, são superficiais. Hoje, em chatbots GPT, esse efeito se intensifica pela qualidade das respostas, mas a distinção fundamental permanece: ELIZA seguia scripts sem compreender, enquanto LLMs inferem padrões e significados de forma estatística, sem entendimento consciente, mas atingindo resultados que simulam compreensão de maneira muito mais convincente.</p>
<p>Em resumo, os avanços de arquitetura (especialmente o mecanismo de atenção) ampliaram drasticamente a capacidade de contextualização e geração dos chatbots modernos, marcando uma evolução significativa desde o mecanismo simples porém pioneiro de ELIZA.</p>
</section>
</section>
</section>
<section id="artificial-intelligence-markup-language-aiml" class="level1">
<h1>Artificial Intelligence Markup Language (AIML)</h1>
<p>O Artificial Intelligence Markup Language (AIML) é uma especificação baseada em XML, proposta por <span class="citation" data-cites="Wallace2009">(<a href="#ref-Wallace2009" role="doc-biblioref">Richard S. Wallace 2009</a>)</span>, destinada à programação de agentes conversacionais, comumente denominados chatbots. A concepção da linguagem prioriza o minimalismo, característica que simplifica o processo de criação de bases de conhecimento por indivíduos sem experiência prévia em programação <span class="citation" data-cites="Wallace2009">(<a href="#ref-Wallace2009" role="doc-biblioref">Richard S. Wallace 2009</a>)</span>. A arquitetura fundamental de um interpretador AIML genérico é ilustrada na Figura&nbsp;<a href="#fig:interpretador" data-reference-type="ref" data-reference="fig:interpretador">3.1</a>.</p>
<figure id="fig:interpretador" class="figure">
<p>
<img src="./fig/image8.png" style="width:80.0%" alt="image" class="figure-img"> <span id="fig:interpretador" data-label="fig:interpretador"></span>
</p>
<p>
Adaptado de <span class="citation" data-cites="Silva2007"></span>
</p>
<figcaption>
Interpretador AIML arquitetura.
</figcaption>
</figure>
<p>A técnica central empregada pelo AIML é a correspondência de padrões (<em>pattern matching</em>). Este método é amplamente utilizado no desenvolvimento de chatbots, particularmente em sistemas orientados a perguntas e respostas <span class="citation" data-cites="Abdul-Kader2015">(<a href="#ref-Abdul-Kader2015" role="doc-biblioref">Abdul-Kader and Woods 2015</a>)</span>. Uma das metas de projeto do AIML é possibilitar a fusão de bases de conhecimento de múltiplos chatbots especializados em domínios distintos. Teoricamente, um interpretador poderia agregar essas bases, eliminando automaticamente categorias redundantes para formar um <em>chatbot</em> mais abrangente <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>.</p>
<p>AIML é frequentemente associado aos chatbots de terceira geração <span class="citation" data-cites="Maria2010">(<a href="#ref-Maria2010" role="doc-biblioref">Maria et al. 2010</a>)</span> e estima-se sua adoção em mais de 50.000 implementações em diversos idiomas. Extensões da linguagem foram propostas, como o iAIML, que introduziu novas <em>tags</em> e incorporou o conceito de intenção com base nos princípios da Teoria da Análise da Conversação (TAC) <span class="citation" data-cites="Neves2005">(<a href="#ref-Neves2005" role="doc-biblioref">Neves and Barros 2005</a>)</span>. Adicionalmente, ferramentas baseadas na Web foram desenvolvidas para apoiar a construção de bases de conhecimento AIML <span class="citation" data-cites="Krassmann2017">(<a href="#ref-Krassmann2017" role="doc-biblioref">Krassmann et al. 2017</a>)</span>. Um exemplo proeminente é o <em>chatbot</em> ALICE, cuja implementação em AIML compreendia aproximadamente 16.000 categorias, cada uma potencialmente contendo múltiplas <em>tags</em> XML aninhadas <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>. Uma representação visual desta estrutura de conhecimento é apresentada na Figura&nbsp;<a href="#fig:representacaovisual" data-reference-type="ref" data-reference="fig:representacaovisual">3.2</a>.</p>
<figure id="fig:representacaovisual" class="figure">
<p>
<img src="fig/image9.png" style="width:70.0%" alt="image" class="figure-img"> <span id="fig:representacaovisual" data-label="fig:representacaovisual"></span>
</p>
<p>
Retirado de <span class="citation" data-cites="Wallace2003"></span>
</p>
<figcaption>
Representação visual da base de conhecimento do chatbot ALICE.
</figcaption>
</figure>
<p><span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span> estabeleceu analogias entre o funcionamento de interpretadores AIML e a teoria do Raciocínio Baseado em Casos (RBC). Nessa perspectiva, as categorias AIML funcionam como "casos", onde o algoritmo identifica o padrão que melhor se alinha à entrada do usuário. Cada categoria estabelece um vínculo direto entre um padrão de estímulo e um modelo de resposta. Consequentemente, chatbots AIML inserem-se na tradição da robótica minimalista, reativa ou de estímulo-resposta <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>, conforme esquematizado na Figura&nbsp;<a href="#fig:teoriaestimulo" data-reference-type="ref" data-reference="fig:teoriaestimulo">3.3</a>. Vale notar que a própria técnica de RBC já foi integrada a interpretadores AIML como um mecanismo para consultar fontes de dados externas e expandir a base de conhecimento do agente <span class="citation" data-cites="Kraus2008">(<a href="#ref-Kraus2008" role="doc-biblioref">Kraus and Fernandes 2008</a>)</span>.</p>
<figure id="fig:teoriaestimulo" class="figure">
<p>
<img src="fig/image10.png" style="width:70.0%" alt="image" class="figure-img"> <span id="fig:teoriaestimulo" data-label="fig:teoriaestimulo"></span>
</p>
<p>
Retirado de <span class="citation" data-cites="Lima2017"></span>
</p>
<figcaption>
Teoria estímulo-resposta aplicada no AIML
</figcaption>
</figure>
<p>Os chatbots que utilizam AIML são classificados como sistemas "baseados em recuperação" (retrieval-based). Tais modelos operam a partir de um repositório de respostas predefinidas, selecionando a mais apropriada com base na entrada do usuário e no contexto conversacional, guiando assim o fluxo da interação. Esta abordagem é frequentemente empregada na construção de chatbots destinados a operar em domínios de conhecimento restritos <span class="citation" data-cites="Borah2019">(<a href="#ref-Borah2019" role="doc-biblioref">Borah, Pathak, and Sarmah 2019</a>)</span>.</p>
<p>A Figura&nbsp;<a href="#fig:exemplodeumabase" data-reference-type="ref" data-reference="fig:exemplodeumabase">3.4</a> demonstra a estrutura elementar de um arquivo AIML. A <em>tag</em> <code>&lt;category&gt;</code> encapsula a unidade básica de conhecimento. Internamente, a <em>tag</em> <code>&lt;pattern&gt;</code> define o padrão de entrada a ser reconhecido (no exemplo, o caractere curinga <code>*</code>, que corresponde a qualquer entrada), enquanto a <em>tag</em> <code>&lt;template&gt;</code> contém a resposta associada. No exemplo ilustrado, o <em>chatbot</em> responderia "Hello!" a qualquer interação. Uma visão abstrata da árvore de conhecimento resultante pode ser observada na Figura&nbsp;<a href="#fig:representacaovisualabstrata" data-reference-type="ref" data-reference="fig:representacaovisualabstrata">3.5</a>. O AIML padrão suporta transições baseadas primariamente em correspondência de padrões, uma limitação inerente, embora extensões específicas de interpretadores possam permitir a integração de outras técnicas de processamento.</p>
<figure id="fig:exemplodeumabase" class="figure">
<pre><code>        &lt;aiml&gt;
        &lt;category&gt;
            &lt;pattern&gt;*&lt;/pattern&gt;
            &lt;template&gt;Hello!&lt;/template&gt;
        &lt;/category&gt;
        &lt;/aiml</code></pre>
<p>
Retirado de <span class="citation" data-cites="Wallace2000"></span>
</p>
<figcaption>
Exemplo de uma base de conhecimento em AIML
</figcaption>
</figure>
<figure id="fig:representacaovisualabstrata" class="figure">
<p>
<img src="./fig/image12.png" style="width:80.0%" alt="image" class="figure-img"> <span id="fig:representacaovisualabstrata" data-label="fig:representacaovisualabstrata"></span>
</p>
<p>
Retirado de <a href="https://www.pandorabots.com/docs/aiml-fundamentals/" class="uri">https://www.pandorabots.com/docs/aiml-fundamentals/</a>
</p>
<figcaption>
Representação visual abstrata de uma base de conhecimento AIML
</figcaption>
</figure>
<p>O profissional responsável pela criação, manutenção e curadoria da base de conhecimento de um <em>chatbot</em> AIML é denominado <em>botmaster</em> <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>. Suas atribuições englobam a edição da base (frequentemente via ferramentas auxiliares), a análise de logs de diálogo para identificar padrões de interação e a subsequente criação ou refino de respostas. Este papel pode ser exercido por indivíduos com diferentes perfis, incluindo <em>webmasters</em>, desenvolvedores, redatores, engenheiros ou outros interessados na construção de chatbots <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>.</p>
<p>Algumas implementações de interpretadores AIML podem incorporar capacidades rudimentares de compreensão semântica através do <em>Resource Description Framework</em> (RDF)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. O RDF é um padrão W3C para representação de informações na Web, usualmente por meio de triplas (sujeito-predicado-objeto) que descrevem relações entre entidades. No contexto AIML, RDF pode ser utilizado para armazenar e consultar fatos. Contudo, mesmo com tais adições, as capacidades linguísticas permanecem aquém da complexidade e do potencial gerativo da linguagem humana, conforme descrito por <span class="citation" data-cites="chomsky2002syntactic">(<a href="#ref-chomsky2002syntactic" role="doc-biblioref">Chomsky and Lightfoot 2002</a>)</span>.</p>
<p>Embora <span class="citation" data-cites="Hohn2019">(<a href="#ref-Hohn2019" role="doc-biblioref">Höhn 2019</a>)</span> argumente que o AIML padrão carece de um conceito explícito de "intenção" (<em>intent</em>), similar ao encontrado em plataformas de <em>Natural Language Understanding</em> (NLU), é possível emular o reconhecimento de intenções. Isso é tipicamente alcançado definindo categorias que representam "formas canônicas" ou "padrões atômicos" para uma intenção específica<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Variações de entrada (e.g., "oi", "olá") podem ser mapeadas para uma categoria canônica (e.g., "saudação") usando a <em>tag</em> <code>&lt;srai&gt;</code> (<em>Symbolic Reduction Artificial Intelligence</em>), que redireciona o fluxo de processamento (ver Figura&nbsp;<a href="#fig:sodatagsrai" data-reference-type="ref" data-reference="fig:sodatagsrai">3.6</a>). Dessa forma, um <em>chatbot</em> AIML pode gerenciar intenções distintas dentro de seu domínio, como realizar um pedido ou verificar o status de entrega.</p>
<figure id="fig:sodatagsrai" class="figure">
<p>
<img src="./fig/image13.png" style="width:50.0%" alt="image" class="figure-img"> <span id="fig:sodatagsrai" data-label="fig:sodatagsrai"></span>
</p>
<p>
Retirado de <span class="citation" data-cites="DeGasperis2013"></span>
</p>
<figcaption>
Uso da tag <code>&lt;srai&gt;</code>
</figcaption>
</figure>
<p>chatbots baseados em AIML têm obtido sucesso significativo em competições como o Prêmio Loebner. Notavelmente, o <em>chatbot</em> Mitsuku<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, desenvolvido por Steve Worswick, conquistou múltiplos títulos recentes<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, seguindo vitórias anteriores do ALICE. <span class="citation" data-cites="Wallace2000">(<a href="#ref-Wallace2000" role="doc-biblioref">Richard S. Wallace 2000</a>)</span>.</p>
<p>Adicionalmente, Mitsuku foi classificado em primeiro lugar numa análise comparativa envolvendo oito chatbots <span class="citation" data-cites="Sharma2020">(<a href="#ref-Sharma2020" role="doc-biblioref">Sharma, Verma, and Sahni 2020</a>)</span>. Nesse estudo, que avaliou atributos conversacionais com base em um conjunto padronizado de perguntas, o Google Assistant obteve a segunda posição, seguido pela Siri em terceiro. O <em>chatbot</em> ALICE. alcançou a quarta posição, enquanto o ELIZA ficou na última colocação entre os sistemas comparados <span class="citation" data-cites="Sharma2020">(<a href="#ref-Sharma2020" role="doc-biblioref">Sharma, Verma, and Sahni 2020</a>)</span>.</p>
<section id="tags-do-aiml-1.0-explicação-e-exemplos" class="level2">
<h2 class="anchored" data-anchor-id="tags-do-aiml-1.0-explicação-e-exemplos">Tags do AIML 1.0: Explicação e Exemplos</h2>
<p>Esta seção descreve as principais tags do AIML, versão 1.0, com explicações e exemplos.</p>
<section id="aiml" class="level5">
<h5 class="anchored" data-anchor-id="aiml"><code>&lt;aiml&gt;</code></h5>
<p><strong>Descrição:</strong> Tag raiz que engloba todo o conteúdo AIML.</p>
<pre><code>    &lt;aiml version="1.0"&gt;
        &lt;!-- Categorias aqui --&gt;
    &lt;/aiml&gt;</code></pre>
</section>
<section id="category" class="level5">
<h5 class="anchored" data-anchor-id="category"><code>&lt;category&gt;</code></h5>
<p><strong>Descrição:</strong> Unidade básica de conhecimento, contendo um padrão e uma resposta.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;OLÁ&lt;/pattern&gt;
        &lt;template&gt;Oi! Como posso ajudar você hoje?&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="pattern" class="level5">
<h5 class="anchored" data-anchor-id="pattern"><code>&lt;pattern&gt;</code></h5>
<p><strong>Descrição:</strong> Define o padrão de entrada do usuário, com curingas como <code>*</code> e <code>_</code>.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;EU GOSTO DE *&lt;/pattern&gt;
        &lt;template&gt;Que bom que você gosta de &lt;star/&gt;!&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="template" class="level5">
<h5 class="anchored" data-anchor-id="template"><code>&lt;template&gt;</code></h5>
<p><strong>Descrição:</strong> Define a resposta do bot ao padrão correspondente.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;QUAL É O SEU NOME&lt;/pattern&gt;
        &lt;template&gt;Meu nome é neo chatbot.&lt;/template&gt;
    &lt;/category&gt; </code></pre>
</section>
<section id="star" class="level5">
<h5 class="anchored" data-anchor-id="star"><code>&lt;star/&gt;</code></h5>
<p><strong>Descrição:</strong> Captura o conteúdo do curinga <code>*</code> ou <code>_</code>.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;MEU NOME É *&lt;/pattern&gt;
        &lt;template&gt;Olá, &lt;star/&gt;!&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="that" class="level5">
<h5 class="anchored" data-anchor-id="that"><code>&lt;that&gt;</code></h5>
<p><strong>Descrição:</strong> Considera a última resposta do bot para decidir a próxima.</p>
<pre><code>&lt;category&gt;
    &lt;pattern&gt;SIM&lt;/pattern&gt;
    &lt;that&gt;Você gosta de programar?&lt;/that&gt;
    &lt;template&gt;Ótimo! Qual linguagem você prefere?&lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
<section id="topic" class="level5">
<h5 class="anchored" data-anchor-id="topic"><code>&lt;topic&gt;</code></h5>
<p><strong>Descrição:</strong> Define um contexto ou tópico para categorias.</p>
<pre><code>&lt;category&gt;
  &lt;pattern&gt;VAMOS FALAR SOBRE ESPORTE&lt;/pattern&gt;
  &lt;template&gt;Ok! &lt;topic name="esporte"/&gt;&lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
<section id="random-e-li" class="level5">
<h5 class="anchored" data-anchor-id="random-e-li"><code>&lt;random&gt;</code> e <code>&lt;li&gt;</code></h5>
<p><strong>Descrição:</strong> Escolhe aleatoriamente uma resposta de uma lista.</p>
<pre><code>&lt;category&gt;
  &lt;pattern&gt;COMO ESTÁ O TEMPO&lt;/pattern&gt;
  &lt;template&gt;
    &lt;random&gt;
      &lt;li&gt;Está ensolarado!&lt;/li&gt;
      &lt;li&gt;Está chovendo.&lt;/li&gt;
    &lt;/random&gt;
  &lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
<section id="condition" class="level5">
<h5 class="anchored" data-anchor-id="condition"><code>&lt;condition&gt;</code></h5>
<p><strong>Descrição:</strong> Adiciona lógica condicional baseada em variáveis.</p>
<pre><code>&lt;category&gt;
  &lt;pattern&gt;COMO EU ESTOU&lt;/pattern&gt;
  &lt;template&gt;
    &lt;condition name="humor"&gt;
      &lt;li value="feliz"&gt;Você está bem!&lt;/li&gt;
      &lt;li&gt;Não sei ainda!&lt;/li&gt;
    &lt;/condition&gt;
  &lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
<section id="set-e-get" class="level5">
<h5 class="anchored" data-anchor-id="set-e-get"><code>&lt;set&gt;</code> e <code>&lt;get&gt;</code></h5>
<p><strong>Descrição:</strong> Define e recupera variáveis.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;MEU NOME É *&lt;/pattern&gt;
        &lt;template&gt;&lt;set name="nome"&gt;&lt;star/&gt;&lt;/set&gt;Olá, &lt;get name="nome"/&gt;!&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="srai" class="level5">
<h5 class="anchored" data-anchor-id="srai"><code>&lt;srai&gt;</code></h5>
<p><strong>Descrição:</strong> Redireciona a entrada para outro padrão.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;OI&lt;/pattern&gt;
        &lt;template&gt;&lt;srai&gt;OLÁ&lt;/srai&gt;&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="think" class="level5">
<h5 class="anchored" data-anchor-id="think"><code>&lt;think&gt;</code></h5>
<p><strong>Descrição:</strong> Executa ações sem exibir o conteúdo.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;EU SOU TRISTE&lt;/pattern&gt;
        &lt;template&gt;&lt;think&gt;&lt;set name="humor"&gt;triste&lt;/set&gt;&lt;/think&gt;Sinto muito!&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="person-person2-gender" class="level5">
<h5 class="anchored" data-anchor-id="person-person2-gender"><code>&lt;person&gt;</code>, <code>&lt;person2&gt;</code>, <code>&lt;gender&gt;</code></h5>
<p><strong>Descrição:</strong> Transforma pronomes ou ajusta gênero.</p>
<pre><code>    &lt;category&gt;
        &lt;pattern&gt;EU TE AMO&lt;/pattern&gt;
        &lt;template&gt;&lt;person&gt;&lt;star/&gt;&lt;/person&gt; ama você também!&lt;/template&gt;
    &lt;/category&gt;</code></pre>
</section>
<section id="formal-uppercase-lowercase" class="level5">
<h5 class="anchored" data-anchor-id="formal-uppercase-lowercase"><code>&lt;formal&gt;</code>, <code>&lt;uppercase&gt;</code>, <code>&lt;lowercase&gt;</code></h5>
<p><strong>Descrição:</strong> Formata texto (capitaliza, maiúsculas, minúsculas).</p>
<pre><code>&lt;category&gt;
  &lt;pattern&gt;MEU NOME É joão&lt;/pattern&gt;
  &lt;template&gt;Olá, &lt;formal&gt;&lt;star/&gt;&lt;/formal&gt;!&lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
<section id="sentence" class="level5">
<h5 class="anchored" data-anchor-id="sentence"><code>&lt;sentence&gt;</code></h5>
<p><strong>Descrição:</strong> Formata como frase (primeira letra maiúscula, ponto final).</p>
<pre><code>&lt;category&gt;
  &lt;pattern&gt;oi&lt;/pattern&gt;
  &lt;template&gt;&lt;sentence&gt;&lt;star/&gt;&lt;/sentence&gt;&lt;/template&gt;
&lt;/category&gt;</code></pre>
</section>
</section>
</section>
<section id="processamento-de-linguagem-natural" class="level1">
<h1>Processamento de Linguagem Natural</h1>
<p>O <strong>Processamento de Linguagem Natural (PLN)</strong> é um campo intrinsecamente ligado à inteligência artificial, dedicando-se a equipar computadores com a capacidade de analisar e compreender a linguagem humana. No cenário da construção de <em>chatbots</em>, o PLN emerge como um componente fundamental, atuando como o "cérebro" da aplicação conversacional. Sua função primordial reside em processar a entrada bruta do usuário, realizando a limpeza e a preparação dos dados textuais para que o sistema possa interpretar a mensagem e tomar as ações subsequentes apropriadas.</p>
<p>Em um espectro mais amplo, o PLN engloba uma vasta gama de tarefas que transcendem a interação com <em>chatbots</em>. Ele se nutre de conceitos e metodologias provenientes da ciência da computação, da linguística, da matemática, da própria inteligência artificial, do aprendizado de máquina e da psicologia. O objetivo central do PLN é, portanto, manipular e analisar a linguagem natural, seja em sua forma escrita ou falada, com o intuito de concretizar tarefas específicas e úteis. Este processo multifacetado envolve a decomposição da linguagem em unidades menores, a compreensão do seu significado intrínseco e a determinação da resposta ou ação mais adequada.</p>
<section id="entendimento-de-linguagem-natural-uln-como-subconjunto-do-pln" class="level2">
<h2 class="anchored" data-anchor-id="entendimento-de-linguagem-natural-uln-como-subconjunto-do-pln">Entendimento de Linguagem Natural (ULN) como Subconjunto do PLN</h2>
<p>O <strong>Entendimento de Linguagem Natural (ULN)</strong> é apresentado nas fontes como um subdomínio específico dentro do universo mais vasto do PLN. Enquanto o PLN abarca um conjunto diversificado de operações sobre a linguagem, o ULN se concentra de maneira particular na habilidade da máquina de apreender e interpretar a linguagem natural tal como ela é comunicada pelos seres humanos. Em outras palavras, o ULN é o ramo do PLN dedicado à extração de significado e à identificação da intenção por trás do texto inserido pelo usuário. As aplicações do ULN são extensas e incluem funcionalidades cruciais para <em>chatbots</em>, como a capacidade de responder a perguntas, realizar buscas em linguagem natural, identificar relações entre entidades, analisar o sentimento expresso no texto, sumarizar informações textuais e auxiliar em processos de descoberta legal.</p>
</section>
<section id="técnicas-fundamentais-de-pln-para-chatbots" class="level2">
<h2 class="anchored" data-anchor-id="técnicas-fundamentais-de-pln-para-chatbots">Técnicas Fundamentais de PLN para Chatbots</h2>
<p>A construção de <em>chatbots</em> eficazes repousa sobre o emprego de diversas técnicas de PLN, cada uma contribuindo para a capacidade do sistema de interagir de forma inteligente com os usuários. As fontes detalham algumas dessas técnicas essenciais:</p>
<section id="tokenização" class="level3">
<h3 class="anchored" data-anchor-id="tokenização">Tokenização</h3>
<p>Este é o processo inicial de segmentar um texto em unidades menores denominadas <em>tokens</em>, que podem ser palavras, pontuações ou símbolos. A tokenização é um passo preparatório fundamental para qualquer análise linguística subsequente.</p>
<p>Tokenizar não é só separar por espaços, mas também lidar com pontuações, contrações e outros aspectos que podem afetar a análise. Por exemplo, "não é" pode ser tokenizado como ["não", "é"] ou ["não", "é"], dependendo do contexto e da abordagem adotada.</p>
<p>Um exemplo simples seria a frase "Eu estou feliz.", que seria tokenizada em ["Eu", "estou", "feliz", "."]. Não necessariamente uma palavra equivale a um token. Em alguns casos, como em palavras compostas ou expressões idiomáticas, um único token pode representar uma ideia ou conceito mais amplo. Por exemplo, "São Paulo" poderia ser considerado um único token em vez de dois ("São" e "Paulo").</p>
<p>Existem diferentes abordagens para tokenização, incluindo tokenização baseada em regras, onde padrões específicos são definidos para identificar tokens (geralmente utilizando expressão regular), e tokenização baseada em aprendizado de máquina, onde algoritmos aprendem a segmentar o texto com base em exemplos anteriores.</p>
<p>A tokenização pode ser feita de várias maneiras, dependendo do idioma e do objetivo da análise. Em inglês, por exemplo, a tokenização pode ser mais simples devido à estrutura gramatical, enquanto em idiomas como o chinês, onde não há espaços entre as palavras, a tokenização pode ser mais complexa.</p>
</section>
<section id="marcação-morfossintática-pos-tagging" class="level3">
<h3 class="anchored" data-anchor-id="marcação-morfossintática-pos-tagging">Marcação Morfossintática (POS Tagging)</h3>
<p>Esta técnica consiste em atribuir a cada <em>token</em> em um texto uma categoria gramatical, como substantivo, verbo, adjetivo, advérbio, etc.. A marcação POS é crucial para identificar entidades e compreender a estrutura gramatical das frases. Por exemplo, na frase "Eu estou aprendendo como construir chatbots", a marcação POS poderia identificar "Eu" como um pronome (PRON), "estou aprendendo" como um verbo (VERB) e "chatbots" como um substantivo (NOUN).</p>
</section>
</section>
<section id="stemming-e-lemmatização" class="level2">
<h2 class="anchored" data-anchor-id="stemming-e-lemmatização">Stemming e Lemmatização</h2>
<p>Ambas as técnicas visam reduzir palavras flexionadas à sua forma base. O <em>stemming</em> é um processo mais heurístico que remove sufixos, podendo nem sempre resultar em uma palavra válida. Já a <em>lemmatização</em> é um processo algorítmico que considera o significado da palavra para determinar seu <em>lema</em>, ou seja, sua forma canônica. Por exemplo, a palavra "correndo" poderia ser reduzida ao stem "corr" pelo <em>stemming</em> e ao lema "correr" pela <em>lemmatização</em>. A lematização é geralmente preferível em aplicações que exigem maior precisão semântica. A remoção de sufixos é um objetivo comum dessas técnicas.</p>
<section id="reconhecimento-de-entidades-nomeadas-ner" class="level3">
<h3 class="anchored" data-anchor-id="reconhecimento-de-entidades-nomeadas-ner">Reconhecimento de Entidades Nomeadas (NER)</h3>
<p>O NER é a tarefa de identificar e classificar entidades nomeadas em um texto, como nomes de pessoas (PERSON), organizações (ORG), localizações geográficas (GPE, LOC), datas (DATE), valores monetários (MONEY), etc.. Por exemplo, na frase "Google tem sua sede em Mountain View, Califórnia, com uma receita de 109.65 bilhões de dólares americanos", o NER identificaria "Google" como uma organização (ORG), "Mountain View" e "Califórnia" como localizações geográficas (GPE) e "109.65 bilhões de dólares americanos" como um valor monetário (MONEY). Essa capacidade é vital para que <em>chatbots</em> compreendam os detalhes relevantes nas <em>utterances</em> dos usuários.</p>
</section>
<section id="remoção-de-palavras-de-parada-stop-words" class="level3">
<h3 class="anchored" data-anchor-id="remoção-de-palavras-de-parada-stop-words">Remoção de Palavras de Parada (Stop Words)</h3>
<p>Palavras de parada são vocábulos de alta frequência que geralmente não carregam muito significado contextual, como "a", "o", "de", "para", "que". A remoção dessas palavras pode melhorar a eficácia de certos algoritmos de PLN, focando nas palavras mais informativas do texto.</p>
</section>
<section id="análise-de-dependências-dependency-parsing" class="level3">
<h3 class="anchored" data-anchor-id="análise-de-dependências-dependency-parsing">Análise de Dependências (Dependency Parsing)</h3>
<p>Esta técnica examina as relações gramaticais entre as palavras em uma frase, revelando a estrutura sintática e as dependências entre os <em>tokens</em>. A análise de dependências pode ajudar a entender quem está fazendo o quê a quem. Por exemplo, na frase "Reserve um voo de Bangalore para Goa", a análise de dependências pode identificar "Bangalore" e "Goa" como modificadores de "voo" através das preposições "de" e "para", respectivamente, e "Reserve" como a raiz da ação. Essa análise é útil para extrair informações sobre as intenções do usuário, mesmo em frases mais complexas.</p>
</section>
<section id="identificação-de-grupos-nominais-noun-chunks" class="level3">
<h3 class="anchored" data-anchor-id="identificação-de-grupos-nominais-noun-chunks">Identificação de Grupos Nominais (Noun Chunks)</h3>
<p>Esta técnica visa identificar sequências contínuas de palavras que atuam como um sintagma nominal. Grupos nominais representam entidades ou conceitos chave em uma frase. Um exemplo seria na frase "Boston Dynamics está se preparando para produzir milhares de cães robóticos", onde "Boston Dynamics" e "milhares de cães robóticos" seriam identificados como grupos nominais.</p>
</section>
<section id="busca-por-similaridade" class="level3">
<h3 class="anchored" data-anchor-id="busca-por-similaridade">Busca por Similaridade</h3>
<p>Utilizando vetores de palavras (<em>word embeddings</em>), como os gerados pelo algoritmo GloVe, é possível calcular a similaridade semântica entre palavras ou frases. Essa técnica permite que <em>chatbots</em> reconheçam que palavras diferentes podem ter significados relacionados. Por exemplo, "carro" e "caminhão" seriam considerados mais similares do que "carro" e "google". Isso é útil para lidar com a variedade de expressões que os usuários podem usar para expressar a mesma intenção.</p>
</section>
<section id="expressões-regulares" class="level3">
<h3 class="anchored" data-anchor-id="expressões-regulares">Expressões Regulares</h3>
<p>São padrões de texto que podem ser usados para corresponder a sequências específicas de caracteres. Embora não sejam uma técnica de PLN no mesmo sentido que as outras, as expressões regulares são ferramentas poderosas para identificar padrões em texto, como números de telefone, endereços de e-mail ou formatos específicos de entrada.</p>
</section>
<section id="classificação-de-texto" class="level3">
<h3 class="anchored" data-anchor-id="classificação-de-texto">Classificação de Texto</h3>
<p>Uma técnica de aprendizado de máquina que atribui um texto a uma ou mais categorias predefinidas. No contexto de <em>chatbots</em>, a classificação de texto é fundamental para a detecção de intenção, onde as categorias representam as diferentes intenções do usuário. Algoritmos como o <em>Naïve Bayes</em> são modelos estatísticos populares para essa tarefa, baseados no teorema de Bayes e em fortes suposições de independência entre as características. O treinamento desses classificadores requer um <em>corpus</em> de dados rotulados, onde cada <em>utterance</em> (entrada do usuário) é associada a uma intenção específica.</p>
</section>
</section>
<section id="ferramentas-e-bibliotecas-de-pln-populares" class="level2">
<h2 class="anchored" data-anchor-id="ferramentas-e-bibliotecas-de-pln-populares">Ferramentas e Bibliotecas de PLN Populares</h2>
<ul>
<li><p><strong>spaCy</strong>: Uma biblioteca de PLN de código aberto em Python e Cython, conhecida por sua velocidade e eficiência. O spaCy oferece APIs intuitivas e modelos pré-treinados para diversas tarefas de PLN, incluindo tokenização, POS tagging, lematização, NER e análise de dependências. Sua arquitetura é focada em desempenho para aplicações em produção.</p></li>
<li><p><strong>NLTK (Natural Language Toolkit)</strong>: Uma biblioteca Python fundamental para PLN, oferecendo uma ampla gama de ferramentas e recursos para tarefas como tokenização, stemming, POS tagging, análise sintática e NER. O NLTK é frequentemente utilizado para fins educacionais e de pesquisa.</p></li>
<li><p><strong>CoreNLP (Stanford CoreNLP)</strong>: Um conjunto de ferramentas de PLN robusto e amplamente utilizado, desenvolvido em Java. O CoreNLP oferece capacidades abrangentes de análise linguística, incluindo POS tagging, análise de dependências, NER e análise de sentimentos. Possui APIs para integração com diversas linguagens de programação, incluindo Python.</p></li>
<li><p><strong>gensim</strong>: Uma biblioteca Python especializada em modelagem de tópicos, análise de similaridade semântica e vetores de palavras. O gensim é particularmente útil para identificar estruturas semânticas em grandes coleções de texto.</p></li>
<li><p><strong>TextBlob</strong>: Uma biblioteca Python mais simples, construída sobre NLTK e spaCy, que fornece uma interface fácil de usar para tarefas básicas de PLN, como POS tagging, análise de sentimentos e correção ortográfica.</p></li>
<li><p><strong>Rasa NLU</strong>: Um componente de código aberto do framework Rasa para construir <em>chatbots</em>, focado em entendimento de linguagem natural. Rasa NLU permite treinar modelos personalizados para classificação de intenção e extração de entidades, oferecendo flexibilidade e controle sobre os dados.</p></li>
</ul>
</section>
<section id="o-papel-crucial-do-pln-na-construção-de-chatbots" class="level2">
<h2 class="anchored" data-anchor-id="o-papel-crucial-do-pln-na-construção-de-chatbots">O Papel Crucial do PLN na Construção de Chatbots</h2>
<p>No cerne da funcionalidade de um <em>chatbot</em> reside a sua capacidade de compreender as mensagens dos usuários e responder de forma adequada. O PLN desempenha um papel central nesse processo, permitindo que o <em>chatbot</em>:</p>
<ul>
<li><p><strong>Detecte a Intenção do Usuário</strong>: Identificar o objetivo por trás da mensagem do usuário é o primeiro passo crucial. Isso é frequentemente abordado como um problema de classificação de texto, onde o <em>chatbot</em> tenta classificar a <em>utterance</em> do usuário em uma das intenções predefinidas. As fontes mencionam o uso de técnicas de aprendizado de máquina, como o algoritmo <em>Naïve Bayes</em>, para construir esses classificadores. Plataformas como LUIS.ai e Rasa NLU simplificam significativamente o processo de treinamento e implantação desses modelos de intenção.</p></li>
<li><p><strong>Extraia Entidades Relevantes</strong>: Além da intenção geral, as mensagens dos usuários frequentemente contêm detalhes específicos, conhecidos como entidades, que são essenciais para atender à solicitação. Por exemplo, em "Reserve um voo de Londres para Nova York amanhã", a intenção é reservar um voo, e as entidades são a cidade de origem ("Londres"), a cidade de destino ("Nova York") e a data ("amanhã"). As técnicas de NER e os modelos de extração de entidades fornecidos por ferramentas como spaCy, NLTK, CoreNLP, LUIS.ai e Rasa NLU são fundamentais para identificar e extrair essas informações cruciais.</p></li>
<li><p><strong>Processe Linguagem Variada e Informal</strong>: Os usuários podem se comunicar com <em>chatbots</em> usando uma ampla gama de vocabulário, gramática e estilo, incluindo erros de digitação, abreviações e linguagem informal. As técnicas de PLN, como stemming, lematização e busca por similaridade, ajudam o <em>chatbot</em> a lidar com essa variabilidade e a compreender a essência da mensagem, mesmo que não seja expressa de forma perfeitamente gramatical.</p></li>
<li><p><strong>Mantenha o Contexto da Conversa</strong>: Em conversas mais longas, o significado de uma <em>utterance</em> pode depender do que foi dito anteriormente. Embora as fontes não detalhem profundamente o gerenciamento de contexto, subentendem que o PLN, juntamente com outras técnicas de gerenciamento de diálogo, contribui para a capacidade do <em>chatbot</em> de lembrar informações e entender referências implícitas.</p></li>
</ul>
</section>
<section id="pln-na-arquitetura-de-chatbots" class="level2">
<h2 class="anchored" data-anchor-id="pln-na-arquitetura-de-chatbots">PLN na Arquitetura de Chatbots</h2>
<p>A arquitetura típica de um <em>chatbot</em> envolve uma camada de processamento de linguagem natural (NLP/NLU engine) que recebe a entrada de texto do usuário. Essa camada é responsável por realizar as tarefas de PLN mencionadas anteriormente: tokenização, análise morfossintática, extração de entidades, detecção de intenção, etc.. O resultado desse processamento é uma representação estruturada da mensagem do usuário, que pode ser entendida pela lógica de negócios do <em>chatbot</em>.</p>
<p>Com base nessa representação estruturada, um motor de decisão (<em>decision engine</em>) no <em>chatbot</em> pode então corresponder a intenção do usuário a fluxos de trabalho preconfigurados ou a regras de negócio específicas. Em alguns casos, a geração de linguagem natural (NLG), outro subcampo do PLN, é utilizada para formular a resposta do <em>chatbot</em> ao usuário.</p>
</section>
</section>
<section id="chap:intents" class="level1">
<h1>Intents em Chatbots</h1>
<p>Os Intents representam a intenção ou o propósito por trás da mensagem de um usuário ao interagir com o chatbot. Em termos mais simples, é o que o usuário deseja que o chatbot faça ou sobre o que ele quer saber.</p>
<section id="sec:intents_definicao" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_definicao">Definição e Propósito</h2>
<p>Um intent é usado para identificar programaticamente a intenção da pessoa que está usando o chatbot. O chatbot deve ser capaz de executar alguma ação com base no "intent" que detecta na mensagem do usuário. Cada tarefa que o chatbot deve realizar define um intent.</p>
</section>
<section id="sec:intents_exemplos" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_exemplos">Exemplos de Intents</h2>
<p>A aplicação prática dos intents varia conforme o domínio do chatbot:</p>
<ul>
<li><p>Para um chatbot de uma loja de moda, exemplos de intents seriam <code>busca de um produto</code> (quando um usuário quer ver produtos) e <code>endereço loja</code> (quando um usuário pergunta sobre lojas).</p></li>
<li><p>Em um chatbot para pedir comida, <code>consultar preços</code> e <code>realizar pedido</code> podem ser intents distintos.</p></li>
</ul>
</section>
<section id="sec:intents_deteccao" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_deteccao">Detecção de Intent</h2>
<p>Detectar o intent da mensagem do usuário é um problema conhecido de aprendizado de máquina, realizado por meio de uma técnica chamada classificação de texto. O objetivo é classificar frases em múltiplas classes (os intents). O modelo de aprendizado de máquina é treinado com um conjunto de dados que contém exemplos de mensagens e seus intents correspondentes. Após o treinamento, o modelo pode prever o intent de novas mensagens que não foram vistas antes.</p>
</section>
<section id="sec:intents_utterances" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_utterances">Utterances (Expressões do Usuário)</h2>
<p>Cada intent pode ser expresso de várias maneiras pelo usuário. Essas diferentes formas são chamadas de <em>utterances</em> ou expressões do usuário.</p>
<p>Por exemplo, para o intent <code>realizar pedido</code>, as utterances poderiam ser ""Eu gostaria de fazer um pedido", "Quero pedir comida", "Como faço para pedir?", etc. Cada uma dessas expressões representa a mesma intenção, mas com palavras diferentes. O modelo de aprendizado de máquina deve ser capaz de reconhecer todas essas variações como pertencentes ao mesmo intent.</p>
<p>É sugerido fornecer um número ótimo de utterances variadas por intent para garantir um bom treinamento do modelo de reconhecimento.</p>
</section>
<section id="sec:intents_entities" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_entities">Entities (Entidades)</h2>
<p>Os Intents frequentemente contêm metadados importantes chamados <em>Entities</em>. Estas são palavras-chave ou frases dentro da utterance do usuário que ajudam o chatbot a identificar detalhes específicos sobre o pedido, permitindo fornecer informações mais direcionadas. Por exemplo, na frase "Eu quero pedir uma pizza de calabreza com borda rechada", as entidades podem incluir:</p>
<ul>
<li><p>O <strong>Intent</strong> é <code>realizar pedido</code>.</p></li>
<li><p>As <strong>Entities</strong> podem ser: <code>pizza</code>, <code>calabreza</code>, <code>borda recheada</code>.</p></li>
</ul>
<p>As entidades extraídas permitem ao chatbot refinar sua resposta ou ação.</p>
</section>
<section id="sec:intents_treinamento" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_treinamento">Treinamento do Bot</h2>
<p>O processo de treinamento envolve a construção de um modelo de aprendizado de máquina. Este modelo aprende a partir do conjunto definido de intents, suas utterances associadas e as entidades anotadas. O objetivo do treinamento é capacitar o modelo a categorizar corretamente novas utterances (que não foram vistas durante o treinamento) no intent apropriado e a extrair as entidades relevantes.</p>
</section>
<section id="sec:intents_confianca" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_confianca">Pontuação de Confiança (Confidence Score)</h2>
<p>Quando o chatbot processa uma nova mensagem do usuário, o modelo de reconhecimento de intent não apenas classifica a mensagem em um dos intents definidos, mas também fornece uma <em>pontuação de confiança</em> (geralmente entre 0 e 1). Essa pontuação indica o quão seguro o modelo está de que a classificação está correta. É comum definir um <em>limite (threshold)</em> de confiança. Se a pontuação do intent detectado estiver abaixo desse limite, o chatbot pode pedir esclarecimentos ao usuário em vez de executar uma ação baseada em uma suposição incerta.</p>
</section>
<section id="sec:intents_uso_pratico" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_uso_pratico">Uso Prático e Análise</h2>
<p>Uma vez que um intent é detectado com confiança suficiente, o chatbot pode executar a ação correspondente. Isso pode envolver consultar um banco de dados, chamar uma API externa, fornecer uma resposta estática ou iniciar um fluxo de diálogo mais complexo. Além disso, a análise dos intents mais frequentemente capturados fornece insights valiosos sobre como os usuários estão interagindo com o chatbot e quais são suas principais necessidades. Essas análises são importantes tanto para a otimização do bot quanto para as decisões de negócio.</p>
</section>
<section id="sec:intents_resumo" class="level2">
<h2 class="anchored" data-anchor-id="sec:intents_resumo">Resumo e Relação com Outros Conceitos</h2>
<p>Em resumo, Intents são um conceito central na arquitetura de chatbots modernos baseados em NLU (Natural Language Understanding). Eles representam o objetivo do usuário e permitem que o chatbot compreenda a intenção por trás das mensagens para agir de forma adequada. Os Intents estão intrinsecamente ligados a outros conceitos fundamentais:</p>
<ul>
<li><p><strong>Entities:</strong> Fornecem os detalhes específicos dentro de um intent.</p></li>
<li><p><strong>Utterances:</strong> São as diversas maneiras como um usuário pode expressar um mesmo intent.</p></li>
<li><p><strong>Actions/Responses:</strong> São as tarefas ou respostas que o chatbot executa após identificar um intent.</p></li>
</ul>
<p>A definição cuidadosa, o treinamento robusto e o gerenciamento contínuo dos intents são cruciais para a eficácia, a inteligência e a qualidade da experiência do usuário oferecida por um chatbot.</p>
</section>
</section>
<section id="llm" class="level1">
<h1>LLM</h1>
<p>Os Modelos de Linguagem de Grande Escala, conhecidos como Large Language Models (LLMs), são sistemas avançados de inteligência artificial projetados para compreender, gerar e manipular linguagem natural de forma sofisticada. Esses modelos são alimentados por vastos conjuntos de dados textuais e utilizam técnicas de aprendizado profundo, particularmente redes neurais, para aprender padrões, contextos e nuances da linguagem.</p>
<p>Os LLMs são capazes de realizar uma variedade de tarefas linguísticas, incluindo tradução automática, geração de texto, resumo de informações, resposta a perguntas e até mesmo a criação de diálogos interativos. Eles funcionam com base em arquiteturas complexas, como a Transformer, que permite que o modelo preste atenção a diferentes partes de um texto simultaneamente, facilitando a compreensão do contexto e das relações semânticas entre palavras e frases.</p>
<p>O treinamento desses modelos envolve a exposição a enormes quantidades de texto, o que lhes permite desenvolver uma compreensão profunda da gramática, do vocabulário e dos estilos de comunicação. No entanto, essa capacidade de gerar texto coerente e relevante também levanta questões éticas e de responsabilidade, especialmente em relação à desinformação, viés algorítmico e privacidade.</p>
<p>Em resumo, os Modelos de Linguagem de Grande Escala representam um marco significativo na evolução da inteligência artificial, oferecendo ferramentas poderosas para a interação humano-computador e abrindo novas possibilidades para aplicações em diversas áreas, como educação, atendimento ao cliente, criação de conteúdo e muito mais.</p>
</section>
<section id="retrieval-augmented-generation-rag" class="level1">
<h1>Retrieval-Augmented Generation (RAG)</h1>
<p>Retrieval Augmented Generation (RAG) é uma abordagem inovadora que combina duas técnicas fundamentais na área de processamento de linguagem natural: recuperação de informações e geração de texto. A ideia central do RAG é aprimorar a capacidade de um modelo de linguagem ao integrá-lo com um sistema de recuperação que busca informações relevantes de uma base de dados ou de um conjunto de documentos.</p>
<p>Na prática, o RAG opera em duas etapas principais. Primeiro, quando uma consulta ou pergunta é feita, um mecanismo de recuperação é acionado para identificar e extrair informações pertinentes de um repositório de dados. Isso pode incluir documentos, artigos, ou qualquer outro tipo de conteúdo textual que possa fornecer contexto e detalhes adicionais sobre o tema em questão. Essa fase é crucial, pois garante que o modelo de linguagem tenha acesso a informações atualizadas e específicas, em vez de depender apenas do conhecimento prévio que foi incorporado durante seu treinamento.</p>
<p>Em seguida, na segunda etapa, o modelo de linguagem utiliza as informações recuperadas para gerar uma resposta mais rica e contextualizada. Essa geração não se limita a reproduzir o conteúdo recuperado, mas sim a integrar esses dados de forma coesa, criando uma resposta que não apenas responde à pergunta, mas também fornece uma narrativa mais completa e informativa. Isso resulta em respostas que são mais precisas e relevantes, pois são fundamentadas em dados concretos e atualizados.</p>
<p>A combinação dessas duas etapas permite que o RAG supere algumas limitações dos modelos de linguagem tradicionais, que podem falhar em fornecer informações precisas ou atualizadas, especialmente em domínios que evoluem rapidamente. Além disso, essa abordagem é particularmente útil em aplicações como assistentes virtuais, chatbots e sistemas de perguntas e respostas, onde a precisão e a relevância da informação são cruciais para a experiência do usuário.</p>
<p>Em resumo, o Retrieval Augmented Generation é uma técnica poderosa que não apenas melhora a qualidade das respostas geradas por modelos de linguagem, mas também amplia o alcance e a aplicabilidade desses modelos em cenários do mundo real, onde a informação é dinâmica e em constante evolução.</p>
</section>
<section id="chatbot-eliza-em-python" class="level1">
<h1>Chatbot ELIZA em Python</h1>
<section id="introdução-2" class="level2">
<h2 class="anchored" data-anchor-id="introdução-2">Introdução</h2>
<p>Apresenta-se, nesta seção, uma implementação simplificada em Python de um chatbot inspirado no paradigma ELIZA. Esta implementação demonstra a utilização de expressões regulares para a identificação de padrões textuais (palavras-chave) na entrada fornecida pelo usuário e a subsequente geração de respostas, fundamentada em regras de transformação predefinidas manualmente.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://colab.research.google.com/github/giseldo/chatbotbook/blob/main/notebook/eliza.ipynb"><img src="fig/colab-badge.png" class="img-fluid figure-img" alt="image"></a></p>
<figcaption>image</figcaption>
</figure>
</div>
<pre><code>import re  
import random  

regras = [
    (re.compile(r'\b(hello|hi|hey)\b', re.IGNORECASE),
     ["Hello. How do you do. Please tell me your problem."]),

    (re.compile(r'\b(I am|I\'?m) (.+)', re.IGNORECASE),
     ["How long have you been {1}?",   
      "Why do you think you are {1}?"]),

    (re.compile(r'\bI need (.+)', re.IGNORECASE),
     ["Why do you need {1}?",
      "Would it really help you to get {1}?"]),

    (re.compile(r'\bI can\'?t (.+)', re.IGNORECASE),
     ["What makes you think you can't {1}?",
      "Have you tried {1}?"]),

    (re.compile(r'\bmy (mother|father|mom|dad)\b', re.IGNORECASE),
     ["Tell me more about your family.",
      "How do you feel about your parents?"]),

    (re.compile(r'\b(sorry)\b', re.IGNORECASE),
     ["Please don't apologize."]),

    (re.compile(r'\b(maybe|perhaps)\b', re.IGNORECASE),
     ["You don't seem certain."]),

    (re.compile(r'\bbecause\b', re.IGNORECASE),
     ["Is that the real reason?"]),

    (re.compile(r'\b(are you|do you) (.+)\?$', re.IGNORECASE),
     ["Why do you ask that?"]),

    (re.compile(r'\bcomputer\b', re.IGNORECASE),
     ["Do computers worry you?"]),
]

respostas_padrao = [
    "I see.",  
    "Please tell me more.",  
    "Can you elaborate on that?"  
]

def response(entrada_usuario):
    for padrao, respostas in regras:
        match = padrao.search(entrada_usuario)  
        if match:
            resposta = random.choice(respostas)
            if match.groups():
                resposta = resposta.format(*match.groups())
            return resposta
    return random.choice(respostas_padrao)


# Exemplo de uso
print("User: Hello.")
print("Bot: " + response("Hello."))

print("User: I am feeling sad.")
print("Bot: " + response("I am feeling sad."))

print("Maybe I was not good enough.")
print("Bot: " + response("Maybe I was not good enough."))

print("My mother tried to help.")
print("Bot: " + response("My mother tried to help."))</code></pre>
<p>Na implementação, são definidos múltiplos padrões de expressões regulares que correspondem a palavras-chave ou estruturas frasais de interesse (e.g., saudações, construções como “I am” ou “I need”, referências a termos familiares). A função <code>response</code>, ao receber uma string de entrada, itera sequencialmente sobre essas regras. Para cada regra, utiliza-se o método <code>padrao.search(entrada)</code> para verificar a ocorrência do padrão correspondente na sentença do usuário.</p>
<p>Quando uma correspondência (match) é encontrada, uma resposta associada à regra é selecionada. É relevante notar que diversas respostas predefinidas contêm marcadores (placeholders), como <code>{1}</code>. Estes marcadores são dinamicamente substituídos pelo conteúdo dos grupos capturados pela expressão regular na entrada original do usuário. Por exemplo, se a entrada for <em>“I am sad”</em> e esta corresponder a um padrão como <code>r"I am (.*)"</code>, o grupo capturado (<code>(.*)</code>) conterá a string <em>“sad”</em>. Se a resposta associada for <em>“Why do you think you are {1}?”</em>, o sistema a formatará como <em>“Why do you think you are sad?”</em>, substituindo <code>{1}</code> pelo conteúdo do primeiro grupo capturado.</p>
<p>Na ausência de correspondência com qualquer regra específica, o sistema seleciona aleatoriamente uma resposta genérica a partir de um conjunto predefinido (denominado, por exemplo, <code>respostas_padrao</code>), tal como <em>“I see.”</em>.</p>
</section>
<section id="exemplo-de-interação" class="level2">
<h2 class="anchored" data-anchor-id="exemplo-de-interação">Exemplo de Interação</h2>
<pre><code>Usuário: Hello
Bot: Hello. How do you do. Please tell me your problem.

Usuário: I am feeling sad
Bot: Why do you think you are feeling sad?

Usuário: Because I lost my job
Bot: Is that the real reason?

Usuário: Maybe I was not good enough.
Bot: You don't seem certain.

Usuário: My mother tried to help.
Bot: Tell me more about your family.</code></pre>
<p>Observa-se na interação que o chatbot inicialmente respondeu à saudação (<em>“Hello...”</em>) com base na regra 1. Em seguida, a entrada <em>“I am sad”</em> ativou a regra 2, resultando em uma resposta que incorpora o termo <em>“sad”</em>. A interação prossegue com o sistema respondendo a entradas iniciadas por <em>“Because...”</em> (regra 8) e <em>“Maybe...”</em> (regra 7), entre outras. Cada resposta gerada foi determinada pela regra correspondente ativada e pelo conteúdo específico da sentença do usuário, mimetizando o comportamento baseado em padrões do sistema ELIZA original <span class="citation" data-cites="Abdul-Kader2015">(<a href="#ref-Abdul-Kader2015" role="doc-biblioref">Abdul-Kader and Woods 2015</a>)</span>.</p>
</section>
</section>
<section id="usando-chatgpt-com-langchain" class="level1">
<h1>Usando chatGPT com LangChain</h1>
<p>LangChain é uma biblioteca de software de código aberto projetada para simplificar a interação com Large Language Models (LLMs) e construir aplicativos de processamento de linguagem natural robustos. Ele fornece uma camada de abstração de alto nível sobre as complexidades de trabalhar diretamente com modelos de linguagem, tornando mais acessível a criação de aplicativos de compreensão e geração de linguagem.</p>
<section id="por-que-usar-langchain" class="level2">
<h2 class="anchored" data-anchor-id="por-que-usar-langchain">Por que usar LangChain?</h2>
<p>Trabalhar com LLMs pode ser complexo devido à sua natureza sofisticada e aos requisitos de recursos computacionais. LangChain lida com muitos detalhes complexos em segundo plano, permitindo que os desenvolvedores se concentrem na construção de aplicativos de linguagem eficazes. Aqui estão algumas vantagens do uso do LangChain:</p>
<ul>
<li><p>Simplicidade: LangChain oferece uma API simples e intuitiva, ocultando os detalhes complexos de interação com LLMs. Ele abstrai as nuances de carregar modelos, gerenciar recursos computacionais e executar previsões.</p></li>
<li><p>Flexibilidade: A biblioteca suporta vários frameworks de deep learning, como TensorFlow e PyTorch, e pode ser integrada a diferentes LLMs. Isso oferece aos desenvolvedores a flexibilidade de escolher as ferramentas e modelos que melhor atendem às suas necessidades.</p></li>
<li><p>Extensibilidade: LangChain é projetado para ser extensível, permitindo que os usuários criem seus próprios componentes personalizados. Você pode adicionar novos modelos, adaptar o processamento de texto ou desenvolver recursos específicos do domínio para atender aos requisitos exclusivos do seu aplicativo.</p></li>
<li><p>Comunidade e suporte: LangChain tem uma comunidade ativa de desenvolvedores e pesquisadores que contribuem para o projeto. A documentação abrangente, tutoriais e suporte da comunidade tornam mais fácil começar e navegar por quaisquer desafios que surgirem durante o desenvolvimento.</p></li>
</ul>
</section>
<section id="arquitetura-do-langchain" class="level2">
<h2 class="anchored" data-anchor-id="arquitetura-do-langchain">Arquitetura do LangChain</h2>
<p>A arquitetura do LangChain pode ser entendida em três componentes principais:</p>
<p>Camada de Abstração: Esta camada fornece uma interface simples e unificada para interagir com diferentes LLMs. Ele abstrai as complexidades de carregar, inicializar e executar previsões em modelos, oferecendo uma API consistente independentemente do modelo subjacente.</p>
<p>Camada de Processamento de Texto: O LangChain inclui ferramentas robustas para processamento de texto, incluindo tokenização, análise sintática, reconhecimento de entidades nomeadas (NER) e muito mais. Esta camada prepara os dados de entrada e saída para que possam ser processados de forma eficaz pelos modelos de linguagem.</p>
<p>Camada de Modelo: Aqui é onde os próprios LLMs residem. O LangChain suporta uma variedade de modelos de linguagem, desde modelos pré-treinados de uso geral até modelos personalizados específicos de domínio. Esta camada lida com a execução de previsões, gerenciamento de recursos computacionais e interação com as APIs dos modelos.</p>
</section>
<section id="exemplo-básico-consultando-um-llm" class="level2">
<h2 class="anchored" data-anchor-id="exemplo-básico-consultando-um-llm">Exemplo Básico: Consultando um LLM</h2>
<p>Vamos ver um exemplo simples de como usar o LangChain para consultar um LLM e obter uma resposta. Neste exemplo, usaremos o gpt-4o-mini da OpenAI, para responder a uma pergunta.</p>
<p>Primeiro, importe as bibliotecas necessárias e configure o cliente LangChain. Em seguida, carregue o modelo de linguagem desejado. Agora, você pode usar o modelo para fazer uma consulta. Vamos perguntar quem é o presidente do Brasil.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://colab.research.google.com/github/giseldo/chatbotbook_v2/blob/main/notebook/langchain.ipynb"><img src="fig/colab-badge.png" class="img-fluid figure-img" alt="image"></a></p>
<figcaption>image</figcaption>
</figure>
</div>
<pre><code>    from langchain.chat_models import init_chat_model
    import os

    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

    model = init_chat_model("gpt-4o-mini", model_provider="openai", 
        openai_api_key=OPENAI_API_KEY)

    response = model.invoke([
        {"role":"user", "content": "quem é o presidente do Brasil?"}
    ])

    print(response.content)

    print(response.text)</code></pre>
<p>Este exemplo básico demonstra a simplicidade de usar o LangChain para interagir com LLMs. No entanto, o LangChain oferece muito mais recursos e funcionalidades para construir aplicativos de chatbot mais robustos.</p>
</section>
</section>
<section id="criando-chatbots-com-llms-através-da-engenharia-de-prompts" class="level1">
<h1>Criando Chatbots com LLMs Através da Engenharia de Prompts</h1>
<p>Modelos de Linguagem Grandes (LLMs), como a família GPT, são incrivelmente poderosos na compreensão e geração de texto. Uma maneira eficaz e relativamente rápida de criar um chatbot funcional é através da <strong>engenharia de prompts</strong>. Em vez de codificar regras complexas e árvores de decisão manualmente, você "programa" o LLM fornecendo-lhe um conjunto detalhado de instruções iniciais (o prompt).</p>
<section id="introdução-3" class="level2">
<h2 class="anchored" data-anchor-id="introdução-3">Introdução</h2>
<p>O prompt é o texto inicial que você fornece ao LLM. Ele define:</p>
<ol type="1">
<li><p><strong>O Papel do Chatbot:</strong> Quem ele é (um atendente de pizzaria, um consultor de moda, etc.).</p></li>
<li><p><strong>O Objetivo da Conversa:</strong> O que ele precisa alcançar (vender uma pizza, ajudar a escolher uma roupa, abrir uma conta, etc.).</p></li>
<li><p><strong>As Regras da Conversa:</strong> A sequência exata de perguntas a fazer, as opções válidas para cada pergunta, e como lidar com diferentes respostas do usuário (lógica condicional).</p></li>
<li><p><strong>O Tom e Estilo:</strong> Se o chatbot deve ser formal, informal, amigável, etc. (embora não especificado nos exemplos, pode ser adicionado).</p></li>
<li><p><strong>O Formato da Saída Final:</strong> Como as informações coletadas devem ser apresentadas no final.</p></li>
</ol>
</section>
<section id="como-funciona" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="como-funciona">Como Funciona?</h2>
<ol type="1">
<li><p><strong>Definição:</strong> Você escreve um prompt detalhado que descreve o fluxo da conversa passo a passo.</p></li>
<li><p><strong>Instrução:</strong> Você alimenta este prompt no LLM.</p></li>
<li><p><strong>Execução:</strong> O LLM usa o prompt como seu guia mestre. Ele inicia a conversa com o usuário seguindo o primeiro passo definido no prompt, faz as perguntas na ordem especificada, valida as respostas (se instruído), segue os caminhos condicionais e, finalmente, gera a saída desejada.</p></li>
<li><p><strong>Iteração:</strong> Se o chatbot não se comportar exatamente como esperado, você ajusta e refina o prompt até que ele siga as regras perfeitamente.</p></li>
</ol>
</section>
<section id="vantagens" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="vantagens">Vantagens:</h2>
<ul>
<li><p><strong>Rapidez:</strong> Muito mais rápido do que desenvolver um chatbot tradicional do zero.</p></li>
<li><p><strong>Flexibilidade:</strong> Fácil de modificar o comportamento alterando o prompt.</p></li>
<li><p><strong>Capacidade Conversacional:</strong> Aproveita a habilidade natural do LLM para conversas fluidas.</p></li>
</ul>
</section>
<section id="limitações" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="limitações">Limitações:</h2>
<ul>
<li><p><strong>Controle Fino:</strong> Pode ser mais difícil garantir que sempre siga exatamente um caminho lógico muito complexo, embora prompts detalhados minimizem isso.</p></li>
<li><p><strong>Estado:</strong> Gerenciar estados complexos ao longo de conversas muito longas pode exigir técnicas de prompt mais avançadas.</p></li>
</ul>
</section>
<section id="exemplos" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exemplos">Exemplos</h2>
<p>Dados os requisitos de negócio a seguir iremos implementar os chatbots utilizanddo LLM.<br>
<strong>1 Pizzaria</strong><br>
</p>
<ul>
<li><p>Construa um chatbot para uma pizzaria. O chatbot será responsável por vender uma pizza.</p></li>
<li><p>Verifique com o usuário qual o o tipo de massa desejado da pizza (pan ou fina).</p></li>
<li><p>Verifique o recheio (queijo, calabresa ou bacon)</p></li>
<li><p>Se o usuário escolheu massa pan verifique qual o recheio da borda (gorgonzola ou cheddar)</p></li>
<li><p>Ao final deve ser exibido as opções escolhidas.</p></li>
</ul>
<p><strong>2 Loja de Roupas</strong><br>
</p>
<ul>
<li><p>Construa um chatbot para uma loja de roupas, o chatbot será responsável por vender uma calça ou camisa.</p></li>
<li><p>Verifique se o usuário quer uma calça ou uma camisa.</p></li>
<li><p>Se o usuário quiser uma calça:</p></li>
<li><p>pergunte o tamanho da calça (34, 35 ou 36)</p></li>
<li><p>pergunte o tipo de fit da calça pode ser slim fit, regular fit, skinny fit.</p></li>
<li><p>Se ele quiser uma camisa:</p></li>
<li><p>verifique se a camisa é (P, M ou g)</p></li>
<li><p>verifique se ele deseja gola (v, redonda ou polo).</p></li>
<li><p>Ao final informe as opções escolhidas com uma mensagem informando que o pedido está sendo processado.</p></li>
</ul>
<p><strong>3 Empresa de Turismo</strong><br>
</p>
<ul>
<li><p>Este chatbot deve ser utilizado por uma empresa de turismo para vender um pacote turístico</p></li>
<li><p>Verifique com o usuário quais das cidades disponíveis ele quer viajar (maceio, aracaju ou fortaleza)</p></li>
<li><p>Se ele for para maceio:</p></li>
<li><p>verifique se ele já conhece as belezas naturais da cidade.</p></li>
<li><p>sugira os dois pacotes (nove ilhas e orla de alagoas)</p></li>
<li><p>Se ele for a aracaju:</p></li>
<li><p>verifique com o usuário quais dos dois passeios disponíveis serão escolhidos. existem duisponíveis um na passarela do carangueijo e outro na orla de aracaju.</p></li>
<li><p>informe que somente existe passagem de ônibus e verifique se mesmo assim ele quer continuar</p></li>
<li><p>Caso ele deseje ir a fortaleza:</p></li>
<li><p>informe que o único pacote são as falasias cearenses.</p></li>
<li><p>verifique se ele irá de ônibus ou de avião para o ceará</p></li>
<li><p>Verifique a forma de pagamento cartão ou débito em todas as opções.</p></li>
<li><p>Ao final informe as opções escolhidas com uma mensagem informando que o pedido está sendo processado.</p></li>
</ul>
<p><strong>4 Banco Financeiro</strong><br>
</p>
<ul>
<li><p>Crie uma aplicação para um banco que será responsável por abrir uma conta corrente para um usuário.</p></li>
<li><p>Verifique se o usuário já tem conta em outros bancos.</p></li>
<li><p>Caso o usuário tenha conta em outros bancos verifique se ele quer fazer portabilidade</p></li>
<li><p>Verifique o nome do correntista.</p></li>
<li><p>Verifique qual o saldo que será depositado, zero ou um outro valor inicial.</p></li>
<li><p>Verifique se o usuário quer um empréstimo.</p></li>
<li><p>Ao final informe o nome do correntista, se ele quis um empréstimo e se ele fez portabilidade e o valor inicial da conta.</p></li>
</ul>
<p><strong>5 Universidade</strong><br>
</p>
<ul>
<li><p>Desenvolver um chatbot para realização de matricula em duas disciplinas eletivas.</p></li>
<li><p>O chatbot apresenta as duas disciplinas eletivas (Inteligência artificial Avançado, Aprendizagem de Máquina)</p></li>
<li><p>Verificar se ele tem o pré-requisito introdução a programação para ambas as disciplinas.</p></li>
<li><p>Se ele escolher Inteligência artificial avançada necessário confirmar se ele cursou inteligência artificial.</p></li>
<li><p>Ao final informe qual o nome das disciplina em que ele se matriculou.</p></li>
</ul>
<p><strong>Aplicando aos Exemplos:</strong><br>
A seguir, mostramos como os fluxos de conversa do exercício anterior podem ser traduzidos em prompts para um LLM. Cada prompt instrui o modelo a agir como o chatbot específico e seguir as regras definidas.</p>
<p><strong>Exemplos de Prompts</strong><br>
<strong>Exemplo 1: Pizzaria</strong><br>
<strong>Prompt para o LLM:</strong><br>
</p>
<pre><code>Você é um chatbot de atendimento de uma pizzaria. Sua tarefa é anotar o pedido de pizza de um cliente. 

Não responda nada fora deste contexto. Diga que não sabe.

Siga EXATAMENTE estes passos:

1.  Pergunte ao cliente qual o tipo de massa desejado. As únicas opções válidas são "pan" ou "fina".
    * Exemplo de pergunta: "Olá! Qual tipo de massa você prefere para sua pizza: pan ou fina?"
2.  Depois que o cliente escolher a massa, pergunte qual o recheio desejado. As únicas opções válidas são "queijo", "calabresa" ou "bacon".
    * Exemplo de pergunta: "Ótima escolha! E qual recheio você gostaria: queijo, calabresa ou bacon?"
3.  APENAS SE o cliente escolheu a massa "pan" no passo 1, pergunte qual o recheio da borda. As únicas opções válidas são "gorgonzola" ou "cheddar".
    * Exemplo de pergunta (apenas para massa pan): "Para a massa pan, temos borda recheada! Você prefere com gorgonzola ou cheddar?"
4.  Após coletar todas as informações necessárias (massa, recheio e recheio da borda, se aplicável), exiba um resumo claro do pedido com todas as opções escolhidas pelo cliente.
    * Exemplo de resumo: "Perfeito! Seu pedido ficou assim: Pizza com massa [massa escolhida], recheio de [recheio escolhido] [se aplicável: e borda recheada com [recheio da borda escolhido]]."

Inicie a conversa agora seguindo o passo 1.</code></pre>
<p><strong>Exemplo 2: Loja de Roupas</strong><br>
<strong>Prompt para o LLM:</strong><br>
</p>
<pre><code>Você é um chatbot de vendas de uma loja de roupas. Seu objetivo é ajudar o cliente a escolher uma calça ou uma camisa. 

Não responda nada fora deste contexto. Diga que não sabe.

Siga EXATAMENTE estes passos:

1.  Pergunte ao cliente se ele está procurando por uma "calça" ou uma "camisa".
    * Exemplo de pergunta: "Bem-vindo(a) à nossa loja! Você está procurando por uma calça ou uma camisa hoje?"
2.  SE o cliente responder "calça":
    a.  Pergunte o tamanho da calça. As únicas opções válidas são "34", "35" ou "36".
        * Exemplo de pergunta: "Para calças, qual tamanho você usa: 34, 35 ou 36?"
    b.  Depois do tamanho, pergunte o tipo de fit da calça. As únicas opções válidas são "slim fit", "regular fit" ou "skinny fit".
        * Exemplo de pergunta: "E qual tipo de fit você prefere: slim fit, regular fit ou skinny fit?"
3.  SE o cliente responder "camisa":
    a.  Pergunte o tamanho da camisa. As únicas opções válidas são "P", "M" ou "G".
        * Exemplo de pergunta: "Para camisas, qual tamanho você prefere: P, M ou G?"
    b.  Depois do tamanho, pergunte o tipo de gola. As únicas opções válidas são "V", "redonda" ou "polo".
        * Exemplo de pergunta: "E qual tipo de gola você gostaria: V, redonda ou polo?"
4.  Após coletar todas as informações (tipo de peça e suas especificações), apresente um resumo das opções escolhidas e informe que o pedido está sendo processado.
    * Exemplo de resumo (Cal\c{c}a): "Entendido! Voc\^e escolheu uma cal\c{c}a tamanho [tamanho] com fit [fit]. Seu pedido est\'a sendo processado."
    * Exemplo de resumo (Camisa): "Entendido! Você escolheu uma camisa tamanho [tamanho] com gola [gola]. Seu pedido está sendo processado."
    

Inicie a conversa agora seguindo o passo 1.</code></pre>
<p><strong>Exemplo 3: Empresa de Turismo</strong><br>
<strong>Prompt para o LLM:</strong><br>
</p>
<pre><code>Você é um agente de viagens virtual de uma empresa de turismo. Sua tarefa é ajudar um cliente a escolher e configurar um pacote turístico. 

Não responda nada fora deste contexto. Diga que não sabe.

Siga EXATAMENTE estes passos:

1.  Pergunte ao cliente para qual das cidades disponíveis ele gostaria de viajar. As únicas opções são "Maceió", "Aracaju" ou "Fortaleza".
    * Exemplo de pergunta: "Olá! Temos ótimos pacotes para Maceió, Aracaju e Fortaleza. Qual desses destinos te interessa mais?"
2.  SE o cliente escolher "Maceió":
    a.  Pergunte se ele já conhece as belezas naturais da cidade. (A resposta não altera o fluxo, é apenas conversacional).
        * Exemplo de pergunta: "Maceió é linda! Você já conhece as belezas naturais de lá?"
    b.  Sugira os dois pacotes disponíveis: "Nove Ilhas" e "Orla de Alagoas". Pergunte qual ele prefere.
        * Exemplo de pergunta: "Temos dois pacotes incríveis em Maceió: 'Nove Ilhas' e 'Orla de Alagoas'. Qual deles você prefere?"
    c.  Vá para o passo 5.
3.  SE o cliente escolher "Aracaju":
    a.  Pergunte qual dos dois passeios disponíveis ele prefere: "Passarela do Caranguejo" ou "Orla de Aracaju".
        * Exemplo de pergunta: "Em Aracaju, temos passeios pela 'Passarela do Caranguejo' e pela 'Orla de Aracaju'. Qual te atrai mais?"
    b.  Informe ao cliente que para Aracaju, no momento, só temos transporte via ônibus. Pergunte se ele deseja continuar mesmo assim.
        * Exemplo de pergunta: "Importante: para Aracaju, nosso transporte é apenas de ônibus. Podemos continuar com a reserva?"
    c.  Se ele confirmar, vá para o passo 5. Se não, agradeça e encerre.
4.  SE o cliente escolher "Fortaleza":
    a.  Informe que o pacote disponível é o "Falésias Cearenses".
        * Exemplo de informação: "Para Fortaleza, temos o pacote especial 'Falésias Cearenses'."
    b.  Pergunte se ele prefere ir de "ônibus" ou "avião" para o Ceará.
        * Exemplo de pergunta: "Como você prefere viajar para o Ceará: de ônibus ou avião?"
    c.  Vá para o passo 5.
5.  Depois de definir o destino, pacote/passeio e transporte (se aplicável), pergunte qual a forma de pagamento preferida. As únicas opções são "cartão" ou "débito".
    * Exemplo de pergunta: "Para finalizar, como você prefere pagar: cartão ou débito?"
6.  Ao final, apresente um resumo completo das opções escolhidas (destino, pacote/passeio, transporte se aplicável, forma de pagamento) e informe que o pedido está sendo processado.
    * Exemplo de resumo: "Confirmado! Seu pacote para [Destino] inclui [Pacote/Passeio], transporte por [Ônibus/Avião, se aplicável], com pagamento via [Forma de Pagamento]. Seu pedido está sendo processado!"

Inicie a conversa agora seguindo o passo 1.</code></pre>
<p><strong>Exemplo 4: Banco Financeiro</strong><br>
<strong>Prompt para o LLM:</strong><br>
</p>
<pre><code>Você é um assistente virtual de um banco e sua função é auxiliar usuários na abertura de uma conta corrente. 

Não responda nada fora deste contexto. Diga que não sabe.

Siga EXATAMENTE estes passos:

1.  Pergunte ao usuário se ele já possui conta em outros bancos. Respostas esperadas: "sim" ou "não".
    * Exemplo de pergunta: "Bem-vindo(a) ao nosso banco! Para começar, você já possui conta corrente em alguma outra instituição bancária?"
2.  APENAS SE a resposta for "sim", pergunte se ele gostaria de fazer a portabilidade da conta para o nosso banco. Respostas esperadas: "sim" ou "não".
    * Exemplo de pergunta: "Entendido. Você gostaria de solicitar a portabilidade da sua conta existente para o nosso banco?"
3.  Pergunte o nome completo do futuro correntista.
    * Exemplo de pergunta: "Por favor, informe o seu nome completo para o cadastro."
4.  Pergunte qual será o valor do depósito inicial na conta. Informe que pode ser "zero" ou qualquer outro valor.
    * Exemplo de pergunta: "Qual valor você gostaria de depositar inicialmente? Pode ser R$ 0,00 ou outro valor à sua escolha."
5.  Pergunte se o usuário tem interesse em solicitar um empréstimo pré-aprovado junto com a abertura da conta. Respostas esperadas: "sim" ou "não".
    * Exemplo de pergunta: "Você teria interesse em verificar uma oferta de empréstimo pré-aprovado neste momento?"
6.  Ao final, apresente um resumo com as informações coletadas: nome do correntista, se solicitou portabilidade (sim/não), se solicitou empréstimo (sim/não) e o valor do depósito inicial.
    * Exemplo de resumo: "Perfeito! Finalizamos a solicitação. Resumo da abertura: Correntista: [Nome Completo], Portabilidade Solicitada: [Sim/Não], Empréstimo Solicitado: [Sim/Não], Depósito Inicial: R$ [Valor]."

Inicie a conversa agora seguindo o passo 1.</code></pre>
<p><strong>Exemplo 5: Universidade</strong></p>
<p><strong>Prompt para o LLM:</strong><br>
</p>
<pre class="Tex" data-language="Tex"><code>
Você é um assistente de matrícula de uma universidade. Sua tarefa é ajudar um aluno a se matricular em até duas disciplinas eletivas. 

Não responda nada fora deste contexto. Diga que não sabe.

Siga EXATAMENTE estes passos:

1.  Apresente as duas disciplinas eletivas disponíveis: "Inteligência Artificial Avançado" e "Aprendizagem de Máquina".
    * Exemplo de apresentação: "Olá! Temos duas disciplinas eletivas disponíveis para matrícula: 'Inteligência Artificial Avançado' e 'Aprendizagem de Máquina'."
2.  Verifique se o aluno possui o pré-requisito obrigatório "Introdução à Programação", que é necessário para AMBAS as disciplinas. Pergunte se ele já cursou e foi aprovado nesta disciplina. Respostas esperadas: "sim" ou "não".
    * Exemplo de pergunta: "Para cursar qualquer uma delas, é necessário ter sido aprovado em 'Introdução à Programação'. Você já cumpriu esse pré-requisito?"
3.  SE a resposta for "não", informe que ele não pode se matricular nas eletivas no momento e encerre a conversa.
    * Exemplo de mensagem: "Entendo. Infelizmente, sem o pré-requisito 'Introdução à Programação', não é possível se matricular nestas eletivas agora. Procure a coordenação para mais informações."
4.  SE a resposta for "sim" (possui o pré-requisito):
    a.  Pergunte em qual(is) das duas disciplinas ele deseja se matricular. Ele pode escolher uma ou ambas.
        * Exemplo de pergunta: "Ótimo! Em qual(is) disciplina(s) você gostaria de se matricular: 'Inteligência Artificial Avançado', 'Aprendizagem de Máquina' ou ambas?"
    b.  APENAS SE o aluno escolher "Inteligência Artificial Avançado" (seja sozinha ou junto com a outra), pergunte se ele já cursou a disciplina "Inteligência Artificial". Respostas esperadas: "sim" ou "não".
        * Exemplo de pergunta (se escolheu IA Avançado): "Para cursar 'Inteligência Artificial Avançado', é recomendado ter cursado 'Inteligência Artificial' anteriormente. Você já cursou essa disciplina?"
        * (Nota: O prompt original não especifica o que fazer se ele NÃO cursou IA. Vamos assumir que ele ainda pode se matricular, mas a pergunta serve como um aviso ou coleta de dados).
    c.  Após coletar as escolhas e a informação sobre IA (se aplicável), informe as disciplinas em que o aluno foi efetivamente matriculado. Liste apenas as disciplinas que ele escolheu E para as quais ele confirmou ter os pré-requisitos verificados neste fluxo (no caso, 'Introdução à Programação').
        * Exemplo de finalização (matriculado em ambas, confirmou IA): "Matrícula realizada com sucesso! Você está matriculado em: Inteligência Artificial Avançado e Aprendizagem de Máquina."
        * Exemplo de finalização (matriculado apenas em Aprendizagem de Máquina): "Matrícula realizada com sucesso! Você está matriculado em: Aprendizagem de Máquina."
        * Exemplo de finalização (matriculado em IA Avançado, mesmo sem ter cursado IA antes): "Matrícula realizada com sucesso! Você está matriculado em: Inteligência Artificial Avançado."

Inicie a conversa agora seguindo o passo 1.</code></pre>
<figure id="fig:chat_chatgpt_pizza" class="figure">
<p>
<img src="fig/chat_chatgpt_pizza.png" style="width:100.0%" alt="image" class="figure-img"> <span id="fig:chat_chatgpt_pizza" data-label="fig:chat_chatgpt_pizza"></span>
</p>
<figcaption>
Chatbot criado com LLM (ChatGPT)
</figcaption>
</figure>
<p>Lembre-se que a qualidade da resposta do LLM depende muito da clareza e do detalhamento do prompt. Quanto mais específico você for nas instruções, mais provável será que o chatbot se comporte exatamente como desejado. Veja na Figura&nbsp;<a href="#fig:chat_chatgpt_pizza" data-reference-type="ref" data-reference="fig:chat_chatgpt_pizza">10.1</a> um exemplo de implementação e diálogo.</p>
</section>
</section>
<section id="expressões-regulares-1" class="level1">
<h1>Expressões Regulares</h1>
<p>Expressões regulares, frequentemente abreviadas como regex, são sequências de caracteres que definem padrões de busca. Elas são utilizadas em chatbots para diversas tarefas relacionadas ao processamento e à análise de texto fornecido pelos usuários. Algumas das aplicações incluem:</p>
<ul>
<li><p><strong>Extração de entidades:</strong> Identificação e extração de informações específicas, como endereços de e-mail, números de telefone, datas e outros dados estruturados presentes na entrada do usuário.</p></li>
<li><p><strong>Validação de entradas do usuário:</strong> Verificação se a entrada do usuário corresponde a um formato esperado, como datas em um formato específico (DD/MM/AAAA), códigos postais ou outros padrões predefinidos.</p></li>
<li><p><strong>Detecção de Intenção:</strong> Detecção de comandos específicos inseridos pelo usuário, como <code>/ajuda</code>, <code>/iniciar</code> ou palavras-chave que indicam uma intenção específica.</p></li>
<li><p><strong>Limpeza de texto:</strong> Remoção de ruídos e elementos indesejados do texto, como tags HTML, espaços em branco excessivos ou caracteres especiais que podem interferir no processamento subsequente.</p></li>
<li><p><strong>Tokenização simples:</strong> Embora métodos mais avançados sejam comuns em PLN, regex pode ser usada para dividir o texto em unidades menores (tokens) com base em padrões simples.</p></li>
</ul>
<p>Essas tarefas são fundamentais para garantir que o chatbot possa interpretar e responder adequadamente às entradas dos usuários, especialmente em cenários onde a informação precisa ser estruturada ou verificada antes de ser processada por modelos de linguagem mais complexos.</p>
<section id="fundamentos-do-módulo-re-em-python" class="level2">
<h2 class="anchored" data-anchor-id="fundamentos-do-módulo-re-em-python">Fundamentos do Módulo <code>re</code> em Python</h2>
<p>O módulo <code>re</code> em Python é a biblioteca padrão para trabalhar com expressões regulares. Ele fornece diversas funções que permitem realizar operações de busca, correspondência e substituição em strings com base em padrões definidos por regex. Algumas das funções mais utilizadas incluem:</p>
<ul>
<li><p><code>re.match(pattern, string)</code>: Tenta encontrar uma correspondência do padrão no <em>início</em> da string. Se uma correspondência for encontrada, retorna um objeto de correspondência; caso contrário, retorna <code>None</code>.</p></li>
<li><p><code>re.search(pattern, string)</code>: Procura a primeira ocorrência do padrão em <em>qualquer posição</em> da string. Retorna um objeto de correspondência se encontrado, ou <code>None</code> caso contrário.</p></li>
<li><p><code>re.findall(pattern, string)</code>: Encontra <em>todas</em> as ocorrências não sobrepostas do padrão na string e as retorna como uma lista de strings.</p></li>
<li><p><code>re.sub(pattern, repl, string)</code>: Substitui todas as ocorrências do padrão na string pela string de substituição <code>repl</code>. Retorna a nova string resultante.</p></li>
</ul>
<section id="exemplo-básico-extração-de-e-mails" class="level3">
<h3 class="anchored" data-anchor-id="exemplo-básico-extração-de-e-mails">Exemplo Básico: Extração de E-mails</h3>
<p>Um caso de uso comum em chatbots é a extração de endereços de e-mail do texto fornecido pelo usuário. O seguinte exemplo em Python demonstra como usar <code>re.findall</code> para realizar essa tarefa:</p>
<div class="sourceCode" id="lst:extracao_email" data-language="Python" data-caption="Extração de e-mails com regex" data-label="lst:extracao_email"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:extracao_email-1"><a href="#lst:extracao_email-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="lst:extracao_email-2"><a href="#lst:extracao_email-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:extracao_email-3"><a href="#lst:extracao_email-3" aria-hidden="true" tabindex="-1"></a>texto <span class="op">=</span> <span class="st">"Entre em contato em exemplo@email.com ou suporte@outroemail.com."</span></span>
<span id="lst:extracao_email-4"><a href="#lst:extracao_email-4" aria-hidden="true" tabindex="-1"></a>padrao <span class="op">=</span> <span class="vs">r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'</span></span>
<span id="lst:extracao_email-5"><a href="#lst:extracao_email-5" aria-hidden="true" tabindex="-1"></a>emails <span class="op">=</span> re.findall(padrao, texto)</span>
<span id="lst:extracao_email-6"><a href="#lst:extracao_email-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(emails)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A saída deste código será:</p>
<pre><code>['exemplo@email.com', 'suporte@outroemail.com']</code></pre>
<p>Este exemplo ilustra a eficácia das regex para identificar e extrair informações específicas de um texto.</p>
</section>
</section>
<section id="sintaxe-de-expressões-regulares" class="level2">
<h2 class="anchored" data-anchor-id="sintaxe-de-expressões-regulares">Sintaxe de Expressões Regulares</h2>
<p>A sintaxe das expressões regulares consiste em uma combinação de caracteres literais (que correspondem a si mesmos) e metacaracteres, que possuem significados especiais e permitem definir padrões de busca mais complexos. Alguns dos metacaracteres mais importantes incluem:</p>
</section>
<section id="casos-de-uso-específicos-em-chatbots" class="level2">
<h2 class="anchored" data-anchor-id="casos-de-uso-específicos-em-chatbots">Casos de Uso Específicos em Chatbots</h2>
<p>As expressões regulares podem ser aplicadas em uma variedade de cenários no desenvolvimento de chatbots. A seguir, apresentamos alguns casos de uso comuns com exemplos práticos em Python.</p>
<section id="validação-de-datas" class="level3">
<h3 class="anchored" data-anchor-id="validação-de-datas">Validação de Datas</h3>
<p>Chatbots que lidam com agendamentos ou reservas frequentemente precisam validar se a data fornecida pelo usuário está em um formato correto. O seguinte exemplo demonstra como validar datas no formato DD/MM/AAAA:</p>
<div class="sourceCode" id="lst:validacao_data" data-language="Python" data-caption="Validação de datas com regex" data-label="lst:validacao_data"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:validacao_data-1"><a href="#lst:validacao_data-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="lst:validacao_data-2"><a href="#lst:validacao_data-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:validacao_data-3"><a href="#lst:validacao_data-3" aria-hidden="true" tabindex="-1"></a>padrao_data <span class="op">=</span> <span class="vs">r'\b\d</span><span class="sc">{2}</span><span class="vs">/\d</span><span class="sc">{2}</span><span class="vs">/\d</span><span class="sc">{4}</span><span class="vs">\b'</span></span>
<span id="lst:validacao_data-4"><a href="#lst:validacao_data-4" aria-hidden="true" tabindex="-1"></a>datas_teste <span class="op">=</span> [<span class="st">"31/12/2020"</span>, <span class="st">"1/1/2021"</span>, <span class="st">"2023-05-10"</span>, <span class="st">"25/06/2025 10:00"</span>]</span>
<span id="lst:validacao_data-5"><a href="#lst:validacao_data-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:validacao_data-6"><a href="#lst:validacao_data-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data <span class="kw">in</span> datas_teste:</span>
<span id="lst:validacao_data-7"><a href="#lst:validacao_data-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> re.match(padrao_data, data):</span>
<span id="lst:validacao_data-8"><a href="#lst:validacao_data-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"'</span><span class="sc">{</span>data<span class="sc">}</span><span class="ss">' é uma data válida no formato DD/MM/AAAA."</span>)</span>
<span id="lst:validacao_data-9"><a href="#lst:validacao_data-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="lst:validacao_data-10"><a href="#lst:validacao_data-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"'</span><span class="sc">{</span>data<span class="sc">}</span><span class="ss">' não é uma data válida no formato DD/MM/AAAA."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A saída deste código ilustra quais das strings de teste correspondem ao padrão de data especificado.</p>
</section>
<section id="análise-de-comandos" class="level3">
<h3 class="anchored" data-anchor-id="análise-de-comandos">Análise de Comandos</h3>
<p>Em interfaces de chatbot baseadas em texto, os usuários podem interagir através de comandos específicos, como <code>/ajuda</code> ou <code>/iniciar</code>. As regex podem ser usadas para detectar esses comandos de forma eficiente:</p>
<div class="sourceCode" id="lst:analise_comando" data-language="Python" data-caption="Análise de comandos com regex" data-label="lst:analise_comando"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:analise_comando-1"><a href="#lst:analise_comando-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="lst:analise_comando-2"><a href="#lst:analise_comando-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:analise_comando-3"><a href="#lst:analise_comando-3" aria-hidden="true" tabindex="-1"></a>padrao_comando <span class="op">=</span> <span class="vs">r'^/\w+'</span></span>
<span id="lst:analise_comando-4"><a href="#lst:analise_comando-4" aria-hidden="true" tabindex="-1"></a>comandos_teste <span class="op">=</span> [<span class="st">"/ajuda"</span>, <span class="st">"/iniciar"</span>, <span class="st">"ajuda"</span>, <span class="st">"iniciar/"</span>]</span>
<span id="lst:analise_comando-5"><a href="#lst:analise_comando-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:analise_comando-6"><a href="#lst:analise_comando-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> comando <span class="kw">in</span> comandos_teste:</span>
<span id="lst:analise_comando-7"><a href="#lst:analise_comando-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> re.match(padrao_comando, comando):</span>
<span id="lst:analise_comando-8"><a href="#lst:analise_comando-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"'</span><span class="sc">{</span>comando<span class="sc">}</span><span class="ss">' é um comando válido."</span>)</span>
<span id="lst:analise_comando-9"><a href="#lst:analise_comando-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="lst:analise_comando-10"><a href="#lst:analise_comando-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"'</span><span class="sc">{</span>comando<span class="sc">}</span><span class="ss">' não é um comando válido."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Este exemplo mostra como identificar strings que começam com uma barra seguida por um ou mais caracteres alfanuméricos.</p>
</section>
<section id="tokenização-simples" class="level3">
<h3 class="anchored" data-anchor-id="tokenização-simples">Tokenização Simples</h3>
<p>Embora para tarefas complexas de PLN sejam utilizadas técnicas de tokenização mais avançadas, as regex podem ser úteis para realizar uma tokenização básica, dividindo o texto em palavras ou unidades menores com base em padrões de separação:</p>
<div class="sourceCode" id="lst:tokenizacao_simples" data-language="Python" data-caption="Tokenização simples com regex" data-label="lst:tokenizacao_simples"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:tokenizacao_simples-1"><a href="#lst:tokenizacao_simples-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="lst:tokenizacao_simples-2"><a href="#lst:tokenizacao_simples-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:tokenizacao_simples-3"><a href="#lst:tokenizacao_simples-3" aria-hidden="true" tabindex="-1"></a>texto <span class="op">=</span> <span class="st">"Olá, como vai você?"</span></span>
<span id="lst:tokenizacao_simples-4"><a href="#lst:tokenizacao_simples-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> re.split(<span class="vs">r'\W+'</span>, texto)</span>
<span id="lst:tokenizacao_simples-5"><a href="#lst:tokenizacao_simples-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A saída será uma lista de strings, onde o padrão <code>\W+</code> corresponde a um ou mais caracteres não alfanuméricos, utilizados como delimitadores.</p>
</section>
<section id="limpeza-de-texto" class="level3">
<h3 class="anchored" data-anchor-id="limpeza-de-texto">Limpeza de Texto</h3>
<p>Chatbots podem precisar processar texto que contém elementos indesejados, como tags HTML. As regex podem ser usadas para remover esses elementos:</p>
<div class="sourceCode" id="lst:limpeza_html" data-language="Python" data-caption="Limpeza de texto removendo tags HTML" data-label="lst:limpeza_html"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:limpeza_html-1"><a href="#lst:limpeza_html-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="lst:limpeza_html-2"><a href="#lst:limpeza_html-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:limpeza_html-3"><a href="#lst:limpeza_html-3" aria-hidden="true" tabindex="-1"></a>texto_html <span class="op">=</span> <span class="st">"&lt;p&gt;Este é um parágrafo com &lt;b&gt;texto em negrito&lt;/b&gt;.&lt;/p&gt;"</span></span>
<span id="lst:limpeza_html-4"><a href="#lst:limpeza_html-4" aria-hidden="true" tabindex="-1"></a>texto_limpo <span class="op">=</span> re.sub(<span class="vs">r'&lt;[^&gt;]+&gt;'</span>, <span class="st">''</span>, texto_html)</span>
<span id="lst:limpeza_html-5"><a href="#lst:limpeza_html-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(texto_limpo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="aplicação-em-frameworks-de-chatbot" class="level2">
<h2 class="anchored" data-anchor-id="aplicação-em-frameworks-de-chatbot">Aplicação em Frameworks de Chatbot</h2>
<p>Frameworks populares para desenvolvimento de chatbots, como Rasa, frequentemente integram o uso de expressões regulares para aprimorar a extração de entidades. Por exemplo, em Rasa, as regex podem ser definidas nos dados de treinamento para ajudar o sistema a reconhecer padrões específicos como nomes de ruas ou códigos de produtos. Essa abordagem permite melhorar a precisão do reconhecimento de entidades, um componente crucial para a compreensão da intenção do usuário.</p>
</section>
<section id="tópicos-avançados" class="level2">
<h2 class="anchored" data-anchor-id="tópicos-avançados">Tópicos Avançados</h2>
<p>Embora os fundamentos das regex sejam suficientes para muitas tarefas, existem construções mais avançadas que podem ser úteis em cenários complexos. Alguns exemplos incluem:</p>
<ul>
<li><p><strong>Lookaheads e Lookbehinds:</strong> Permitem verificar se um padrão é seguido ou precedido por outro padrão, sem incluir esse outro padrão na correspondência.</p></li>
<li><p><strong>Correspondência não-gulosa:</strong> Ao usar quantificadores como <code>*</code> ou <code>+</code>, a correspondência padrão é "gulosa", ou seja, tenta corresponder à maior string possível. Adicionar um <code>?</code> após o quantificador (<code>*?</code>, <code>+?</code>) torna a correspondência "não-gulosa", correspondendo à menor string possível.</p></li>
</ul>
<p>A exploração detalhada desses tópicos está além do escopo deste capítulo introdutório, mas são ferramentas poderosas para lidar com padrões mais complexos.</p>
</section>
<section id="limitações-e-contexto" class="level2">
<h2 class="anchored" data-anchor-id="limitações-e-contexto">Limitações e Contexto</h2>
<p>É importante reconhecer que, apesar de sua utilidade, as expressões regulares têm limitações significativas quando se trata de compreender a complexidade da linguagem natural. As regex são baseadas em padrões estáticos e não possuem a capacidade de entender o contexto, a semântica ou as nuances da linguagem humana.</p>
<p>Para tarefas que exigem uma compreensão mais profunda do significado e da intenção por trás das palavras, técnicas avançadas de Processamento de Linguagem Natural (PLN), como modelagem de linguagem, análise de sentimentos e reconhecimento de entidades nomeadas (NER) baseados em aprendizado de máquina, são indispensáveis.</p>
<p>No contexto de um fluxo de trabalho de chatbot, as expressões regulares são frequentemente mais eficazes nas etapas de pré-processamento, como limpeza e validação de entradas, enquanto técnicas de PLN mais sofisticadas são empregadas para a compreensão da linguagem em um nível mais alto. Os capítulos posteriores deste livro abordarão essas técnicas avançadas, incluindo o uso de Modelos de Linguagem Grandes (LLMs) e Retrieval-Augmented Generation (RAG), que complementam o uso de regex, permitindo a construção de chatbots mais inteligentes e contextualmente conscientes.</p>
</section>
<section id="conclusão" class="level2">
<h2 class="anchored" data-anchor-id="conclusão">Conclusão</h2>
<p>As expressões regulares representam uma ferramenta essencial para o processamento de texto em chatbots, oferecendo uma maneira eficaz de extrair informações específicas, validar formatos de entrada e realizar tarefas básicas de limpeza de texto. Através do módulo <code>re</code> em Python, os desenvolvedores têm à disposição um conjunto de funcionalidades poderosas para manipular strings com base em padrões definidos.</p>
<p>No entanto, é crucial entender as limitações das regex, especialmente no que diz respeito à compreensão da linguagem natural em sua totalidade. Para tarefas que exigem análise semântica e contextual, técnicas avançadas de PLN são necessárias. As expressões regulares, portanto, encontram seu melhor uso como parte de um fluxo de trabalho mais amplo, onde complementam outras abordagens para criar chatbots robustos e eficientes.</p>
<p>Encorajamos o leitor a praticar a criação de diferentes padrões de regex e a experimentar com os exemplos fornecidos neste capítulo. A familiaridade com as expressões regulares é uma habilidade valiosa para qualquer pessoa envolvida no desenvolvimento de chatbots e no processamento de linguagem natural em geral.</p>
</section>
</section>
<section id="usando-o-gpt2" class="level1">
<h1>Usando o GPT2</h1>
<p>A biblioteca transformers da Hugging Face torna muito mais fácil trabalhar com modelos pré-treinados como GPT-2. Aqui está um exemplo de como gerar texto usando o GPT-2 pré-treinado:</p>
<div class="sourceCode" id="lst:gpt2_exemplo" data-language="Python" data-caption="Exemplo de uso do GPT-2 com a biblioteca transformers" data-label="lst:gpt2_exemplo"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst:gpt2_exemplo-1"><a href="#lst:gpt2_exemplo-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="lst:gpt2_exemplo-2"><a href="#lst:gpt2_exemplo-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:gpt2_exemplo-3"><a href="#lst:gpt2_exemplo-3" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span><span class="st">'gpt2'</span>)</span>
<span id="lst:gpt2_exemplo-4"><a href="#lst:gpt2_exemplo-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:gpt2_exemplo-5"><a href="#lst:gpt2_exemplo-5" aria-hidden="true" tabindex="-1"></a><span class="bu">input</span> <span class="op">=</span> <span class="st">'Olá, como vai você?'</span></span>
<span id="lst:gpt2_exemplo-6"><a href="#lst:gpt2_exemplo-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:gpt2_exemplo-7"><a href="#lst:gpt2_exemplo-7" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pipe(<span class="bu">input</span>)</span>
<span id="lst:gpt2_exemplo-8"><a href="#lst:gpt2_exemplo-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:gpt2_exemplo-9"><a href="#lst:gpt2_exemplo-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Este código é simples porque ele usa um modelo que já foi treinado em um grande dataset. Também é possível ajustar (fine-tune) um modelo pré-treinado em seus próprios dados para obter resultados melhores.</p>

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Abdul-Kader2015" class="csl-entry" role="listitem">
Abdul-Kader, Sameera A., and John Woods. 2015. <span>“<span class="nocase">Survey on Chatbot Design Techniques in Speech Conversation Systems</span>.”</span> <em>International Journal of Advanced Computer Science and Applications</em> 6 (7): 72–80. <a href="https://doi.org/10.14569/ijacsa.2015.060712">https://doi.org/10.14569/ijacsa.2015.060712</a>.
</div>
<div id="ref-AZEVEDO2015" class="csl-entry" role="listitem">
Azevedo, Ryan Ribeiro de. 2015. <span>“<span class="nocase">Um sistema de dialogo inteligente baseado em logica de descricoes</span>.”</span> PhD thesis.
</div>
<div id="ref-Bada2012" class="csl-entry" role="listitem">
Bada, Everton Moschen. 2012. <span>“<span class="nocase">Uma proposta para extracao de perguntas e respostas de textos</span>.”</span> <em>XVII Congreso Internacional de Informatica Educativa, TISE</em>, 44–49.
</div>
<div id="ref-Borah2019" class="csl-entry" role="listitem">
Borah, Bhriguraj, Dhrubajyoti Pathak, and Priyankoo Sarmah. 2019. <span>“<span class="nocase">Survey of Text based Chatbot in Perspective of Recent Technologies</span>.”</span> In <em>International Conference on Computational Intelligence, Communications, and Business Analytics. CICBA 2018: Computational Intelligence, Communications, and Business Analytics</em>, 1031:84–96. Springer Singapore. <a href="https://doi.org/10.1007/978-981-13-8581-0">https://doi.org/10.1007/978-981-13-8581-0</a>.
</div>
<div id="ref-chomsky2002syntactic" class="csl-entry" role="listitem">
Chomsky, Noam, and David W Lightfoot. 2002. <em><span class="nocase">Syntactic structures</span></em>. Walter de Gruyter.
</div>
<div id="ref-DeGasperis2013" class="csl-entry" role="listitem">
De Gasperis, Giovanni, Isabella Chiari, and Niva Florio. 2013. <em><span class="nocase">AIML knowledge base construction from text corpora</span></em>. Vol. 427. June 2014. <a href="https://doi.org/10.1007/978-3-642-29694-9_12">https://doi.org/10.1007/978-3-642-29694-9_12</a>.
</div>
<div id="ref-Ferrucci2012" class="csl-entry" role="listitem">
Ferrucci, David. 2012. <span>“<span>This Is Watson</span>.”</span> <em>Journal of Research and Development</em> 56 (3): 88.
</div>
<div id="ref-Hohn2019" class="csl-entry" role="listitem">
Höhn, Sviatlana. 2019. <em><span class="nocase">Artificial Companion for Second Language Conversation</span></em>.
</div>
<div id="ref-Jacobstein1998" class="csl-entry" role="listitem">
Jacobstein, Murray, Sams, and Sincoff. 1998. <span>“A Multi-Agent Associate System Guide for a Virtual Collaboration Center.”</span> <em>Proceedings of the International Conference on Virtual Worlds and Simulation Conference</em>, 215–20.
</div>
<div id="ref-Junior2008" class="csl-entry" role="listitem">
Junior, Antonio Fernando Lavareda Jacob. 2008. <span>“<span class="nocase">Buti: um Companheiro Virtual baseado em Computacao Afetiva para Auxiliar na Manutencao da Saude Cardiovascular</span>.”</span> PhD thesis.
</div>
<div id="ref-Klopfenstein2017" class="csl-entry" role="listitem">
Klopfenstein, Lorenz Cuno, Saverio Delpriori, Silvia Malatini, and Alessandro Bogliolo. 2017. <span>“<span class="nocase">The Rise of Bots: A Survey of Conversational Interfaces, Patterns, and Paradigms.</span>”</span> <em>Proceedings of the 2017 Conference on Designing Interactive Systems</em>, 555–65. <a href="https://doi.org/10.1145/3064663.3064672">https://doi.org/10.1145/3064663.3064672</a>.
</div>
<div id="ref-Krassmann2017" class="csl-entry" role="listitem">
Krassmann, Aliane Loureiro, Fabrício Herpich, Álvaro Souza Pereira da Silva, Anita Raquel da Silva, Cristiane de Souza Abreu, Marcelo Augusto Rauh Schmitt, Magda Bercht, and Liane Margarida Rockenbach Tarouco. 2017. <span>“<span class="nocase">FastAIML: uma ferramenta para apoiar a geracao de base de conhecimento para chatbots educacionais</span>.”</span> <em>Revista Novas Tecnologias Na Educacao (RENOTE)</em> 15 (2): 1–10. <a href="https://doi.org/10.22456/1679-1916.79256">https://doi.org/10.22456/1679-1916.79256</a>.
</div>
<div id="ref-Kraus2008" class="csl-entry" role="listitem">
Kraus, Helton, and Anita Fernandes. 2008. <span>“<span class="nocase">Ivetebyte: Um Chatterbot para Area Imobiliaria Integrando Raciocinio Baseado em Casos</span>.”</span> <em>Revista Iberica de Sistemas e Tecnologias de Informacao</em>, no. 1: 40–51. <a href="http://www.aisti.eu/risti/ristin1.pdf">http://www.aisti.eu/risti/ristin1.pdf</a>.
</div>
<div id="ref-Lane2025" class="csl-entry" role="listitem">
Lane, Rupert, Anthony Hay, Arthur Schwarz, David M. Berry, and Jeff Shrager. 2025. <span>“<span class="nocase">ELIZA Reanimated: The world’s first chatbot restored on the world’s first time sharing system</span>,”</span> 1–21. <a href="https://doi.org/10.1063/5.0239302">https://doi.org/10.1063/5.0239302</a>.
</div>
<div id="ref-Leonhardt2003" class="csl-entry" role="listitem">
Leonhardt, Michelle Denise, Ricardo Neisse, and Liane Margarida Rockenbach Tarouco. 2003. <span>“<span class="nocase">MEARA: Um Chatterbot Tem<span class="nocase">á</span>tico para Uso em Ambiente Educacional</span>.”</span> <a href="https://doi.org/10.5753/CBIE.SBIE.2003.81-88">https://doi.org/10.5753/CBIE.SBIE.2003.81-88</a>.
</div>
<div id="ref-Li2018" class="csl-entry" role="listitem">
Li, Jiwei, Will Monroe, Tianlin Shi, Sėbastien Jean, Alan Ritter, and Dan Jurafsky. 2018. <span>“<span class="nocase">Adversarial Learning for Neural Dialogue Generation</span>,”</span> 2157–69. <a href="https://doi.org/10.18653/v1/d17-1230">https://doi.org/10.18653/v1/d17-1230</a>.
</div>
<div id="ref-Lima2017" class="csl-entry" role="listitem">
Lima, Carlos Eduardo Teixeira Lima. 2017. <span>“<span class="nocase">Um Chatterbot para Criacao e Desenvolvimento de Ontologias com Logica de Descricao</span>.”</span> PhD thesis.
</div>
<div id="ref-Macedo2014" class="csl-entry" role="listitem">
Macedo, Rafael Luiz De, and Elvis Fusco. 2014. <span>“<span class="nocase">An Intelligent Robotic Engine Using Digital Repository of the DSpace Platform</span>,”</span> no. c: 17–23.
</div>
<div id="ref-Madhumitha2015" class="csl-entry" role="listitem">
Madhumitha, S., B. Keerthana, and B. Hemalatha. 2015. <span>“<span>Interactive Chatbot Using AIML</span>.”</span> <em>International Journal Of Advanced Networking And Applications</em>, 217–23.
</div>
<div id="ref-B2020" class="csl-entry" role="listitem">
Marcondes, Francisco Supino, Jose Joao Almeida, and Paulo Novais. 2020. <span>“<span class="nocase">A Short Survey on Chatbot Technology : Failure in Raising the State of the Art</span>,”</span> 28–36. <a href="https://doi.org/10.1007/978-3-030-23887-2">https://doi.org/10.1007/978-3-030-23887-2</a>.
</div>
<div id="ref-Marchuschi1986" class="csl-entry" role="listitem">
Marcuschi, Luís Antonio. 1986. <em><span class="nocase">An<span class="nocase">á</span>lise da Conversa<span class="nocase">ç</span><span class="nocase">ã</span>o</span></em>.
</div>
<div id="ref-Maria2010" class="csl-entry" role="listitem">
Maria, Filomena, Gonçalves Da, Silva Cordeiro, and Rodrigo Lins Rodrigues. 2010. <span>“<span class="nocase">Um ambiente virtual de aprendizagem apoiado por um agente virtual: chatterbot</span>.”</span> <em>Encontro Internacional TIC e Educacao 2010 Lisboa Portugal</em>.
</div>
<div id="ref-Mauldin1994" class="csl-entry" role="listitem">
Mauldin, Michael L. 1994. <span>“<span class="nocase">CHATTERBOTS, TINYMUDS, and the Turing Test Entering the Loebner Prize Competition</span>.”</span> <em>AAAI</em> 94: 16–21. <a href="http://www.aaai.org/Papers/AAAI/1994/AAAI94-003.pdf">http://www.aaai.org/Papers/AAAI/1994/AAAI94-003.pdf</a>.
</div>
<div id="ref-Neves2005" class="csl-entry" role="listitem">
Neves, André M. M., and Flávia de Almeida Barros. 2005. <span>“<span class="nocase">iAIML: Um mecanismo para tratamento de intencao em chatterbots</span>.”</span> <em>Congresso Da Sociedade Brasileira de Computacao</em>, 1032–41.
</div>
<div id="ref-primo2001chatterbot" class="csl-entry" role="listitem">
PRIMO, Alex Fernando Teixeira, and Luciano Roth COELHO. 2001. <span>“<span class="nocase">A chatterbot Cybelle: experi<span class="nocase">ê</span>ncia pioneira no Brasil</span>.”</span> <em>M<span>í</span>dia, Textos e Contextos. Porto Alegre: EDIPUCRS</em>, 259–76.
</div>
<div id="ref-Raj2019" class="csl-entry" role="listitem">
Raj, Sumit. 2019. <em><span class="nocase">Building Chatbots with Python</span></em>. <a href="https://doi.org/10.1007/978-1-4842-4096-0">https://doi.org/10.1007/978-1-4842-4096-0</a>.
</div>
<div id="ref-Ramesh2019" class="csl-entry" role="listitem">
Ramesh, Kiran, Surya Ravishankaran, Abhishek Joshi, and K. Chandrasekaran. 2017. <span>“<span class="nocase">A Survey of Design Techniques for Conversational Agents</span>.”</span> In <em>International Conference on Information, Communication and Computing Technology</em>, 835:336–50. <a href="https://doi.org/10.1007/978-981-13-5992-7">https://doi.org/10.1007/978-981-13-5992-7</a>.
</div>
<div id="ref-Russel2013" class="csl-entry" role="listitem">
Russel, Stuart, and Peter Norving. 2013. <em><span class="nocase">Intelig<span class="nocase">ê</span>ncia Artificial</span></em>.
</div>
<div id="ref-Shaikh2016" class="csl-entry" role="listitem">
Shaikh, Ayesha, Geetanjali Phalke, Pranita Pat, Sangita Bhosale, and Jyoti Raghatwan. 2016. <span>“<span>A Survey On Chatbot Conversational Systems</span>.”</span> <em>International Journal of Engineering Science and Computing</em> 6 (11): 3117–19. <a href="http://ijesc.org/upload/464758c5f7d1a1cd13085e8a584ec5f3.A Survey On Chatbot Conversational Systems.pdf">http://ijesc.org/upload/464758c5f7d1a1cd13085e8a584ec5f3.A Survey On Chatbot Conversational Systems.pdf</a>.
</div>
<div id="ref-Sharma2020" class="csl-entry" role="listitem">
Sharma, Moolchand, Shivang Verma, and Lakshay Sahni. 2020. <span>“<span class="nocase">Comparative Analysis of Chatbots</span>.”</span> <em>SSRN Electronic Journal</em>. <a href="https://doi.org/10.2139/ssrn.3563674">https://doi.org/10.2139/ssrn.3563674</a>.
</div>
<div id="ref-Shum2018" class="csl-entry" role="listitem">
Shum, Heung-yeung, Xiao-dong He, and Di Li. 2018. <span>“<span class="nocase">From Eliza to XiaoIce: challenges and opportunities with social chatbots</span>.”</span> <em>Frontiers of Information Technology e Electronic Engineering</em> 19 (1): 10–26. <a href="https://doi.org/10.1631/fitee.1700826">https://doi.org/10.1631/fitee.1700826</a>.
</div>
<div id="ref-Torreao2005" class="csl-entry" role="listitem">
Torreao, Paula Geralda Barbosa Coelho. 2005. <span>“<span class="nocase">Project Management Knowledge Learning Environment: Ambiente Inteligente de Aprendizado para Educacao em Gerenciamento de Projetos</span>.”</span> PhD thesis.
</div>
<div id="ref-Vaswani2017" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“<span class="nocase">Attention is all you need</span>.”</span> <em>Advances in Neural Information Processing Systems</em> 2017-Decem (Nips): 5999–6009. <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
<div id="ref-Wallace2000" class="csl-entry" role="listitem">
Wallace, Richard S. 2000. <span>“<span class="nocase">Don’ t Read Me: A.L.I.C.E. and AIML Documentation</span>,”</span> 1–72.
</div>
<div id="ref-Wallace2009" class="csl-entry" role="listitem">
Wallace, Richard S. 2009. <span>“<span class="nocase">The anatomy of A.L.I.C.E.</span>”</span> <em>Parsing the Turing Test. Springer, Dordrecht</em>, 181–210. <a href="https://doi.org/10.1093/labmed/30.3.161">https://doi.org/10.1093/labmed/30.3.161</a>.
</div>
<div id="ref-Weizenbaum1996" class="csl-entry" role="listitem">
Weizenbaum, Joseph. 1966. <span>“<span class="nocase">ELIZA - A Computer Program For the Study of Natural Language Communication Between Man And Machine</span>.”</span> <em>Communications of the ACM</em> 9 (1). <a href="https://doi.org/10.1038/d41586-017-07228-2">https://doi.org/10.1038/d41586-017-07228-2</a>.
</div>
<div id="ref-Yamaguchi2018" class="csl-entry" role="listitem">
Yamaguchi, Hiroshi, Maxim Mozgovoy, and Anna Danielewicz-Betz. 2018. <span>“<span>A Chatbot Based On AIML Rules Extracted From Twitter Dialogues</span>.”</span> <em>Communication Papers of the 2018 Federated Conference on Computer Science and Information Systems</em> 17: 37–42. <a href="https://doi.org/10.15439/2018f297">https://doi.org/10.15439/2018f297</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://github.com/keiffster/program-y/wiki/RDF" class="uri">https://github.com/keiffster/program-y/wiki/RDF</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://medium.com/pandorabots-blog/new-feature-visualize-your-aiml-26e33a590da1" class="uri">https://medium.com/pandorabots-blog/new-feature-visualize-your-aiml-26e33a590da1</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://www.pandorabots.com/mitsuku/" class="uri">https://www.pandorabots.com/mitsuku/</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://aisb.org.uk/category/loebner-prize/" class="uri">https://aisb.org.uk/category/loebner-prize/</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>