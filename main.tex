\documentclass[a4paper,oneside]{book}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}

% \usepackage{setspace}
% \onehalfspacing
\usepackage{anyfontsize}
\fontsize{14pt}{16pt}\selectfont

\usepackage{geometry} % Para controlar as margens
\geometry{
  left=4cm, % Aumente a margem esquerda para caber as notas
  right=2cm, % Margem direita menor, já que não terá notas
  marginparwidth=2.5cm, % Largura das notas
  marginparsep=0.5cm % Separação entre texto e nota
}

% \makeatletter
% \renewcommand{\verbatim@font}{\ttfamily\footnotesize}
% \makeatother

\usepackage{marginnote}
\reversemarginpar
\renewcommand*{\marginfont}{\color{blue}}

\usepackage{tikz}
\usetikzlibrary{trees} % Ensure the required TikZ libraries are loaded

\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{float}
\usepackage{charter}
\usepackage{xcolor}   
\usepackage[
    colorlinks=true,
    linkcolor=blue,   
    citecolor=blue,  
    urlcolor=blue  
]{hyperref}

\usepackage{listings}
\usepackage{xcolor}

% Configuração para código AIML
\lstset{
    language=XML,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    stringstyle=\color{red},
    commentstyle=\color{gray},
    morecomment=[l][\color{gray}]{<!--},
    morecomment=[l][\color{gray}]{-->},
    breaklines=true,
    frame=single,
    tabsize=2
}

\lstset{
	language=Python,
	basicstyle=\ttfamily\small\linespread{1.2}\selectfont,
	keywordstyle=\color{blue}\bfseries,
	stringstyle=\color{red},
	commentstyle=\color{green!60!black},
	showstringspaces=false,
	breaklines=true,
	frame=single,
	numbers=left,
	numberstyle=\scriptsize\color{gray},
	captionpos=b
}

\title{Construíndo bons chatbots}
\author{Giseldo Neo}
\date{\today}

\begin{document}

\begin{titlepage}
	\begin{center}
		\vspace*{2cm}
		\includegraphics[width=0.6\textwidth]{fig/capa.png}
		\vfill
		\Huge \textbf{Construíndo bons chatbots} \\
		\vspace{1cm}
		\Large \textit{Giseldo Neo} \\
		% \vspace{2cm}
		% \normalsize \today
	\end{center}
\end{titlepage}

% \maketitle


\tableofcontents
\newpage

\chapter{Chatbots: Definições e Contexto}

\section{Introdução}

\marginnote{Definição}
Um chatbot é um programa de computador que simula uma conversa humana, geralmente utilizando texto ou áudio. Eles oferecem respostas diretas a perguntas e auxiliam em diversas tarefas, servindo tanto para conversas gerais quanto para ações específicas, como abrir uma conta bancária.

\marginnote{Origem do termo}
Embora o chatbot ELIZA \cite{Weizenbaum1996} seja frequentemente considerado um dos primeiros exemplos de software conversacional, o termo ``chatbot'' ainda não era utilizado na época de sua criação. O termo ``chatterbot'', sinônimo de ``chatbot'', foi popularizado por Michael Mauldin em 1994, ao descrever seu programa JULIA \cite{Mauldin1994}. Publicações acadêmicas, como os anais da \textit{Virtual Worlds and Simulation Conference} de 1998 \cite{Jacobstein1998}, também ajudaram a consolidar o uso do termo.

\marginnote{ELIZA}
O ELIZA, criado em 1966 por Joseph Weizenbaum,  representou um experimento revolucionário na interação humano-computador \cite{Weizenbaum1996}. Seu script mais famoso, DOCTOR, imitava rudimentarmente um psicoterapeuta, utilizando correspondência de padrões simples. Por exemplo, quando um usuário inseria a frase “Estou triste”, o ELIZA respondia “Por que você está triste hoje?”, reformulando a entrada como uma pergunta. Seu funcionamento baseia-se em um conjunto de regras que lhe permitem analisar e compreender a linguagem humana de forma limitada e aproximada. Esse tipo de aplicação do ELIZA adequou-se bem a esse domínio, pois dependia de pouco conhecimento sobre o ambiente externo; as regras no script DOCTOR permitiam que o programa respondesse ao usuário com outras perguntas ou simplesmente refletisse a afirmação original. O ELIZA não possuía uma real ``compreensão'' da linguagem humana; ele apenas utilizava palavras-chave e manipulava frases para que a interação parecesse natural. Uma descrição detalhada do funcionamento do ELIZA, com exemplos em Python, será apresentada em seções posteriores.

\marginnote{ChatGPT}
Outro chatbot famoso é o ChatGPT. Desenvolvido pela OpenAI, este é um modelo de linguagem capaz de gerar texto muito semelhante ao criado por humanos. Ele utiliza aprendizagem profunda (deep learning) e redes neurais para gerar sentenças e parágrafos com base nas entradas e informações fornecidas. É capaz de produzir textos coerentes e até mesmo realizar tarefas simples, como responder a perguntas e gerar ideias. Contudo, é importante lembrar que o ChatGPT não possui consciência nem a capacidade de compreender contexto ou emoções. Ele é um exemplo de Modelo de Linguagem Grande (Large Language Model - LLM), baseado na arquitetura conhecida como Transformers, introduzida em 2017 [2]. Esses modelos são treinados com terabytes de texto, utilizando mecanismos de autoatenção que avaliam a relevância de cada palavra em uma frase. Ao contrário das regras manuais do ELIZA, os LLMs extraem padrões linguísticos a partir da vasta quantidade de dados com que a rede neural foi treinada.

\marginnote{Tipo Conversacional}
Esses dois chatbots, ELIZA e ChatGPT, são bons representantes de chatbots do tipo conversacional. Os chatbots conversacionais são utilizados para interagir sobre um propósito específico ou mesmo sobre assuntos gerais.


\marginnote{Tipo Orientado a tarefas} Outro tipo de chatbot é o orientado a tarefas. Os chatbots orientados a tarefas executam ações específicas, como abrir uma conta bancária ou pedir uma pizza. Geralmente, as empresas disponibilizam chatbots orientados a tarefas para seus usuários, com regras de negócio embutidas na conversação e com fluxos bem definidos. Normalmente, não se espera pedir uma pizza e, no mesmo chatbot, discutir os estudos sobre Ética do filósofo Immanuel Kant (embora talvez haja quem queira). 

Essas duas classificações - conversacional e orientado a tarefas - (Figura~\ref{fig:tipo}) ainda não são suficientes para uma completa classifição dada diversas caractéristicas e enorme quantidade de chatbots existentes. Existem outras classificações que serão discutidas em seções posteriores.

\begin{figure}
	\centering
	\caption{Classificação de tipos de chatbots.}
	\begin{tikzpicture}[
		level 1/.style={sibling distance=6cm},
		level 2/.style={sibling distance=3cm},
		every node/.style={align=center}
	]
		\node {Tipo chatbot}
			child {node {Conversacional}}
			child {node {Orientado a\\Tarefas}};
	\end{tikzpicture}
	\label{fig:tipo}
\end{figure}

A popularidade dos chatbots tem crescido significativamente em diversos domínios de aplicação \cite{B2020, Klopfenstein2017, Sharma2020}. Essa tendência é corroborada pelo aumento do interesse de busca pelo termo ``chatbots'', conforme análise de dados do Google Trends no período entre 2020 e 2025 (Figura~\ref{fig:trends}). Nesta figura, os valores representam o interesse relativo de busca ao longo do tempo, onde 100 indica o pico de popularidade no período analisado e 0 (ou a ausência de dados) indica interesse mínimo ou dados insuficientes.

\begin{figure}[!hbp]
	\centering
	\caption{Evolução do interesse de busca pelo termo ``chatbot'' (Google Trends, 2020-2025).}
	\includegraphics[width=1\linewidth]{fig/trends.png}
	\label{fig:trends}
	{\footnotesize Fonte: Google Trends acesso em 05/04/2025} % Sugestão: Adicionar a fonte e data de acesso para dados do Trends.
\end{figure}

% \begin{figure}[H]
% 	\centering
% 	\begin{tikzpicture}[
% 		level 1/.style={sibling distance=6cm},
% 		level 2/.style={sibling distance=3cm},
% 		every node/.style={align=center}
% 	]
% 		\node {Tipo}
% 			child {node {Conversacional}}
% 			child {node {Orientado a\\Tarefas}};
% 	\end{tikzpicture}
% 	\caption{Classificação de tipos de chatbots.}
% 	\label{fig:tipo}
% \end{figure}

% \begin{figure}[H]
% 	\centering
% 	\caption{Tipo de chatbot}
% 	\includegraphics[width=0.7\linewidth]{fig/tipo.png}
% 	\label{fig:tipo}
% 	{\footnotesize \centering

% 		Fonte: Giseldo Neo (2025)}
% \end{figure}

\section{Chatbots e Agentes: Definições e Distinções}

Define-se chatbot como um programa computacional projetado para interagir com usuários por meio de linguagem natural. Por outro lado, o conceito de agente possui uma definição mais ampla: trata-se de uma entidade computacional que percebe seu ambiente por meio de sensores e atua sobre esse ambiente por meio de atuadores \cite{Russel2013}. A Figura~\ref{fig:agente} ilustra uma arquitetura conceitual de alto nível para um agente.

\begin{figure}
	\centering
	\caption{Arquitetura conceitual de um agente.}
	\includegraphics[width=0.7\linewidth]{fig/ia.png}
	\label{fig:agente}
	{\footnotesize \centering

		Fonte: Diretamente retirado de \cite{Russel2013}}
\end{figure}

Nesse contexto, um chatbot (Figura~\ref{fig:chatbot}) pode ser considerado uma instanciação específica de um agente, cujo propósito primário é a interação conversacional em linguagem natural.

\begin{figure}
	\centering
	\caption{Representação esquemática de um chatbot.}
	\includegraphics[width=0.9\linewidth]{fig/chatbot.png}
	\label{fig:chatbot}
	{\footnotesize \centering

		Fonte: Giseldo Neo (2025)}
\end{figure}

Com o advento de modelos de linguagem avançados, como os baseados na arquitetura \textit{Generative Pre-trained Transformer} (GPT), observou-se uma recontextualização do termo ``agente'' no domínio dos sistemas conversacionais. Nessa abordagem mais recente, um sistema focado predominantemente na geração de texto conversacional tende a ser denominado ``chatbot''. Em contraste, o termo ``agente'' é frequentemente reservado para sistemas que, além da capacidade conversacional, integram e utilizam ferramentas externas (por exemplo, acesso à internet, execução de código, interação com APIs) para realizar tarefas complexas e interagir proativamente com o ambiente digital. Um sistema capaz de realizar uma compra online, processar um pagamento e confirmar um endereço de entrega por meio do navegador do usuário seria, portanto, classificado como um agente, diferentemente de chatbots mais simples como ELIZA, cujo foco era estritamente o diálogo.


\section{Gerenciamento do Diálogo e Fluxo Conversacional}

A interação textual mediada por chatbots não se constitui em uma mera justaposição aleatória de turnos de conversação ou pares isolados de estímulo-resposta. Pelo contrário, espera-se que a conversação exiba coerência e mantenha relações lógicas e semânticas entre os turnos consecutivos. O estudo da estrutura e organização da conversa humana é abordado por disciplinas como a Análise da Conversação.

\marginnote{Análise da Conversação}
No contexto da linguística textual e análise do discurso em língua portuguesa, os trabalhos de Marcuschi \cite{Marchuschi1986} são relevantes ao investigar a organização da conversação. Marcuschi analisou a estrutura conversacional em termos de unidades coesas, como o ``tópico conversacional'', que agrupa turnos relacionados a um mesmo assunto ou propósito interacional.

\marginnote{Fluxo de diálogo}
Conceitos oriundos da Análise da Conversação, como a gestão de tópicos, têm sido aplicados no desenvolvimento de chatbots para aprimorar sua capacidade de manter diálogos coerentes e contextualmente relevantes com usuários humanos \cite{Neves2005}. Na prática de desenvolvimento de sistemas conversacionais, a estrutura lógica e sequencial da interação é frequentemente modelada e referida como ``fluxo de conversação'' ou ``fluxo de diálogo''. Contudo, é importante ressaltar que a implementação explícita de modelos sofisticados de gerenciamento de diálogo, inspirados na Análise da Conversação, não é uma característica universal de todos os chatbots, variando conforme a complexidade e o propósito do sistema. Um exemplo esquemático de um fluxo conversacional é apresentado na Figura~\ref{fig:fluxo}.

\begin{figure}
	\centering
	\caption{Exemplo esquemático de um fluxo conversacional em um chatbot.}
	\includegraphics[width=1\linewidth]{fig/fluxo.png}
	\label{fig:fluxo}
	{\footnotesize 
	
	Fonte: Giseldo Neo (2025)}
\end{figure}

Um fluxograma para um chatbot que vende roupas está representada na Figura~\ref{fig:representacaodeumaarvore}.

\begin{figure}
\caption{Representação de uma árvore de decisão para comprar roupas online}
\vspace{0.5cm}
    \centering
   	\vspace*{0,2cm}
    \includegraphics[width=0.9\textwidth]{./04-figuras/image14}
    \label{fig:representacaodeumaarvore}
	{
	
	\cite{Raj2019}.}
\end{figure}

\section{Depois do ELIZA}

\marginnote{ALICE \\ AIML}
Um marco significativo na evolução dos chatbots foi o ALICE, que introduziu a Artificial Intelligence Markup Language (AIML), uma linguagem de marcação baseada em XML \cite{Wallace2000}. A AIML estabeleceu um paradigma para a construção de agentes conversacionais ao empregar algoritmos de correspondência de padrões. Essa abordagem utiliza modelos pré-definidos para mapear as entradas do usuário a respostas correspondentes, permitindo a definição modular de blocos de conhecimento \cite{Wallace2000}.

No contexto brasileiro, um dos primeiros chatbots documentados capaz de interagir em português, inspirado no modelo ELIZA, foi o Cybele \cite{primo2001chatterbot}. Posteriormente, desenvolveu-se o Elecktra, também em língua portuguesa, com aplicação voltada para a educação a distância \cite{Leonhardt2003}. Em um exemplo mais recente de aplicação governamental, no ano de 2019, o processo de inscrição para o Exame Nacional do Ensino Médio (ENEM) foi disponibilizado por meio de uma interface conversacional baseada em chatbot (Figura~\ref{fig:enem}).

\begin{figure}
	\centering
	\caption{Interface de chatbot para inscrição no ENEM 2019.}
	\includegraphics[width=0.5\linewidth]{fig/enem.png}
	\label{fig:enem}
	{\footnotesize Fonte: Captura de tela realizada por Giseldo Neo.}
\end{figure}

O desenvolvimento de chatbots avançados tem atraído investimentos de grandes corporações. Notavelmente, a IBM desenvolveu um sistema de resposta a perguntas em domínio aberto utilizando sua plataforma Watson \cite{Ferrucci2012}. Esse tipo de tarefa representa um desafio computacional e de inteligência artificial (IA) considerável. Em 2011, o sistema baseado em Watson demonstrou sua capacidade ao competir e vencer competidores humanos no programa de perguntas e respostas JEOPARDY! \cite{Ferrucci2012}.

Diversos outros chatbots foram desenvolvidos para atender a demandas específicas em variados domínios. Exemplos incluem: BUTI, um companheiro virtual com computação afetiva para auxiliar na manutenção da saúde cardiovascular \cite{Junior2008}; EduBot, um agente conversacional projetado para a criação e desenvolvimento de ontologias com lógica de descrição \cite{Lima2017}; PMKLE, um ambiente inteligente de aprendizado focado na educação em gerenciamento de projetos \cite{Torreao2005}; RENAN, um sistema de diálogo inteligente fundamentado em lógica de descrição \cite{AZEVEDO2015}; e MOrFEu, voltado para a mediação de atividades cooperativas em ambientes inteligentes na Web \cite{Bada2012}.

\section{Abordagens}

Desde o pioneirismo do ELIZA, múltiplas abordagens e técnicas foram exploradas para o desenvolvimento de chatbots. Entre as mais relevantes, destacam-se: AIML com correspondência de padrões (pattern matching), análise sintática (Parsing), modelos de cadeia de Markov (Markov Chain Models), uso de ontologias, redes neurais recorrentes (RNNs), redes de memória de longo prazo (LSTMs), modelos neurais sequência-a-sequência (Sequence-to-Sequence), aprendizado adversarial para geração de diálogo, além de abordagens baseadas em recuperação (Retrieval-Based) e generativas (Generative-Based) \cite{Borah2019, Ramesh2019, Shaikh2016, Abdul-Kader2015, Li2018}, entre outras.

Além disso, diversos frameworks têm sido desenvolvidos para facilitar a criação desses agentes complexos, como CrewAI e bibliotecas associadas a plataformas como Hugging Face (e.g., Transformers Agents), que fornecem abstrações e ferramentas em Python para orquestrar múltiplos componentes e o uso de ferramentas externas.

\section{Problemática}	

Apesar do progresso recente de chatbots, como o XiaoIce e o ChatGPT, o mecanismo fundamental da inteligência em nível humano, frequentemente refletido na comunicação, ainda não está totalmente esclarecido \cite{Shum2018}. Para avançar na solução desses desafios, serão necessários progressos em diversas áreas da IA cognitiva, tais como: modelagem empática de conversas, modelagem de conhecimento e memória, inteligência de máquina interpretável e controlável, e calibração de recompensas emocionais \cite{Shum2018}.

Uma das dificuldades na construção de chatbots reside em gerenciar a complexidade das estruturas condicionais ("se-então") que definem o fluxo do diálogo \cite{Raj2019}. Quanto maior o número de decisões a serem tomadas, mais numerosas e intrincadas tendem a ser essas estruturas condicionais. Contudo, elas são essenciais para codificar fluxos de conversação complexos. Se a tarefa que o chatbot visa simular é inerentemente complexa e envolve múltiplas condições, o código precisará refletir essa complexidade. Para facilitar a visualização desses fluxos, uma solução eficaz é a utilização de fluxogramas. Embora simples de criar e entender, os fluxogramas constituem uma poderosa ferramenta de representação para este problema.

Os chatbots baseados em AIML (Artificial Intelligence Markup Language) apresentam desvantagens específicas. Por exemplo, o conhecimento é representado como instâncias de arquivos AIML. Se esse conhecimento for criado com base em dados coletados da Internet, ele não será atualizado automaticamente, exigindo atualizações periódicas manuais \cite{Madhumitha2015}. No entanto, já existem abordagens para mitigar essa limitação, permitindo carregar conteúdo AIML a partir de fontes como arquivos XML \cite{Macedo2014}, um corpus textual \cite{DeGasperis2013} ou dados do Twitter \cite{Yamaguchi2018}.

Outra desvantagem do AIML reside na relativa complexidade de seus padrões de correspondência (patterns). Além disso, a manutenção do sistema pode ser árdua, pois, embora a inserção de conteúdo (categorias) seja conceitualmente simples, grandes volumes de informação frequentemente precisam ser adicionados manualmente \cite{Madhumitha2015}.

Especificamente no caso do AIML, a construção e a visualização de fluxos de diálogo complexos enfrentam dificuldades adicionais. Devido ao seu formato baseado em texto, muitas vezes é difícil perceber claramente como as diferentes categorias (unidades de conhecimento e resposta) se interligam para formar a estrutura da conversação.

%%%%%%%%%%%%%%%%
%%%%CAPITULO%%%%
%%%%%%%%%%%%%%%%

\chapter{Eliza Explicado}

\section{Introdução}

o ELIZA foi um dos primeiros programas de processamento de linguagem natural e foi apresentado em 1966 por Joseph Weizenbaum no MIT \cite{Weizenbaum1996}.

\marginnote{SCRIPT}
O conjunto de padrões e respostas predefinidas constitui o que Weizenbaum chamou de “roteiro” (script) de conversa. O mecanismo do ELIZA separa o motor genérico de processamento (o algoritmo de busca de palavras-chave e aplicação de regras) dos dados do script em si. Isso significa que ELIZA podia em teoria simular diferentes personalidades ou tópicos apenas carregando um script diferente, sem alterar o código do programa (veja na Figura~\ref{fig:elizaeditor}). Também foi codificado um editor de texto para alteração do Script.

\begin{figure}[!htbp]
	\centering	
	\caption{ELIZA: separação entre o código fonte, o script e o editor de texto.}
	\begin{tikzpicture}
		% Texto à esquerda
		\node[align=center] at (0,0) {código fonte};
		
		% Sinal de +
		\node at (3,0) {$+$};
		
		% Texto à direita
		\node[align=center] at (6,0) {script (exemplo: DOCTOR)\\  \\ editor de texto};
	\end{tikzpicture}
	\label{fig:elizaeditor}
\end{figure}

\marginnote{SCRIPT DOCTOR}
Um destes scripts (o DOCTOR) o deixou famoso. Com este script carregado, o ELIZA simulava um psicoterapeuta (do estilo Rogeriano), refletindo as palavras do usuário de volta em forma de pergunta. A primeira linha do script é a introdução do chatbot, a primeira palavra que ele escrever para o usuário. START é um comando técnico do script, serve para indicar que a seguir virão as regras. REMEMBER 5 estabelece que a prioridade da palavra REMEMBER é 5, ou seja, se o usuário disser algo que contenha a palavra REMEMBER, o ELIZA irá responder com uma das perguntas definidas entre parênteses. A seguir estão as regras de transformação de frases (decomposition rule e reassembly rule) associadas à palavra-chave REMEMBER. O exemplo abaixo mostra como o script DOCTOR é estruturado:

\begin{verbatim}
		
	(REMEMBER 5 
		(
			(0 YOU REMEMBER 0) 
			(DO YOU OFTEN THINK OF 4) 
			(DOES THINKING OF ~ BRING ANYTHING ELSE TO MINO) 
			(WHAT ELSE OO YOU REMEMBER)
			(WHY DO YOU REMEMBER 4 JUST NOW) 
			(WHAT IN THE PRESENT SITUATION REMINDS YOU OF 4) 
			(WHAT IS THE CONNECTION BETWEEN ME AND 4)
		) 
		(
			(0 DO I REMEMBER 0) 
			(DID YOU THINK I WOULD FORGET 5) 
			(WHY DO YOU THINK I SHOULD RECALL 5 NOW) 
			(WHAT ABOUT 5) 
			(=WHAT) 
			(YOU MENTIONED S)
		) 
	) 
	
	(IF 3 
		(
			(0 IF 0) 
			(DO YOU THINK ITS LIKELY THAT 3) 
			(DO YOU WISH THAT 3) 
			(WHAT DO YOU THINK ABOUT 3) 
			(REALLY, 2 3)
		)
	) 
	

\end{verbatim}


A seguir é apresentado um exemplo de diálogo (retirado do artigo original) entre um usuário humano e ELIZA, mostrando as respostas em letras maiúsculas. Nesse exemplo, o usuário faz afirmações pessoais (“Men are all alike.”, “Well, my boyfriend made me come here.”) e ELIZA responde com perguntas ou reformulações (“IN WHAT WAY”, “YOUR BOYFRIEND MADE YOU COME HERE?”), reutilizando termos do próprio usuário. Esse estilo reflexivo encoraja o usuário a continuar falando sem fornecer respostas diretas.

\begin{verbatim}
	Men are all alike. 
	IN WHAT WAY 
	They're always bugging us about something or other. 
	CAN YOU THINK OF A SPECIFIC EXAMPLE 
	Well, my boyfriend made me come here. 
	YOUR BOYFRIEND MADE YOU COME HERE 
	He says I'm depressed much of the time. 
	I AM SORRY TO HEAR YOU ARE DEPRESSED 
	It's true. I am unhappy. 
	DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY 
	I need some help, that much seems certain. 
	WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP 
	Perhaps I could learn to get along with my mother. 
	TELL ME MORE ABOUT YOUR FAMILY 
	My mother takes care of me. 
	WHO ELSE IN YOUR FAMILY TAKES CARE OF YOU 
	My father. 
	YOUR FATHER 
	You are like my father in some ways. 
	WHAT RESEMBLANCE DO YOU SEE 
	You are not very aggressive but I think you don't want me to 
	notice that. 
	WHAT MAKES YOU THINK I AM NOT VERY AGGRESSIVE 
	You don't argue with me. 
	WHY DO YOU THINK I DON'T ARGUE WITH YOU 
	You are afraid of me. 
	DOES IT PLEASE YOU TO BELIEVE I AM AFRAID OF YOU 
	My father is afraid of everybody. 
	WHAT ELSE COMES TO MIND WHEN YOU THINK OF YOUR FATHER 
	Bullies. 
	DOES THAT HAVE ANYTHING TO DO WITH THE FACT THAT YOUR BOYFRIEND MADE YOU COME HERE 
\end{verbatim}
	

% Um detalhamento do algoritmo do ELIZA está no Algoritmo 1.

% Algoritmo 1 - Algoritmo Eliza

% Fonte: Buscar a Fonte do Algoritmo Adaptado por Giseldo Neo

\section{Processamento de Entradas e Palavras-Chave}

\marginnote{Pattern Matching}
O funcionamento do ELIZA baseia-se em correspondência de padrões por palavras-chave (técnica também chamado casamento de padrão, em inglês \textit{pattner matching} ou baseado em regras \textit{rule-based}). A cada turno, o texto de entrada do usuário é analisado em busca de palavras-chave predefinidas. O ELIZA fazia uma varredura da sentença da esquerda para a direita, identificando se alguma palavra correspondia a uma palavra-chave do script. Caso encontrasse, ELIZA selecionava a palavra-chave mais “importante” (havia um peso de prioridade associado a cada palavra-chave) e ignorava o restante da entrada.

Por exemplo, o script DOCTOR, definia palavras-chave como “ALIKE” ou “SAME” com alta prioridade; assim, na frase “Men are all alike.” o programa detectava a palavra “ALIKE” e disparava uma resposta associada a ela (no caso: “In what way?”). Se múltiplas palavras-chave aparecessem, ELIZA escolhia aquela de maior peso para formular a resposta.

Primeiro o texto de entrada digitado pelo usuário era separado em palavras, em um técnica que hoje chamamos de tokenização de palavras. A palavra-chave era identificada, comparando-a sequencialmente até o fim das palavras existentes, ou até ser encontrado uma pontuação. Caso fosse encontrado uma pontuação (ponto final ou vírgula), o texto após a pontuação era ignorado se já tivesse sido identificado uma palavra-chave. Assim cada processamento da resposta foca em apenas uma única afirmação (ou frase) do usuário. Se várias palavras-chave fossem encontradas antes da pontuação, a de maior peso era selecionada.

Por exemplo, o usuário entra com o texto: “I am sick. but, today is raining”. Se houvesse uma palavra-chave no script rankeando a palavra “SICK" com alta prioridade, a entrada processada seria somente “I am sick”, o restante depois da pontuação (neste caso, o ponto) seria gnorado pelo programa.

Se nenhuma palavra-chave fosse encontrada na entrada, ELIZA recorria a frases genéricas programadas, chamadas de respostas vazias ou sem conteúdo. Nesses casos, o chatbot emitia mensagens do tipo “I see.” ou “Please, go on.” . Esse mecanismo evitava silêncio quando o usuário dizia algo fora do escopo do script.

Além disso, a implementação original incluía uma estrutura de memória: algumas declarações recentes do usuário eram armazenadas e, se uma entrada subsequente não contivesse novas keywords, ELIZA poderia recuperar um tópico anterior e introduzi-lo na conversa. Por exemplo, se o usuário mencionasse família em um momento e depois fizesse uma afirmação vaga, o programa poderia responder retomando o assunto da família (“DOES THAT HAVE ANYTHING TO DO WITH YOUR FAMILY?”). Essa estratégia dava uma pseudo-continuidade ao diálogo, simulando que o sistema “lembrava” de informações fornecidas anteriormente.

\section{Regras de Transformação de Frases}

Encontrada a palavra-chave, ELIZA aplicava uma regra de transformação associada a ela para gerar a resposta. As regras são definidas em pares: um padrão de análise (decomposition rule) e um modelo de reconstrução de frase (reassembly rule).

Primeiro, a frase do usuário é decomposta conforme um padrão que identifica a contexto mínimo em torno da palavra-chave. Essa decomposição frequentemente envolve separar a frase em partes e reconhecer pronomes ou estruturas gramaticais relevantes. Por exemplo, considere a entrada “You are very helpful.”. Uma regra de decomposição pode identificar a estrutura “You are X” — onde “X” representa o restante da frase — e extrair o complemento “very helpful” como um componente separado.

Em seguida, a regra de reassembly correspondente é aplicada, remontando uma sentença de resposta em que “X” é inserido em um template pré-definido. No exemplo dado, o template de resposta poderia ser “What makes you think I am X?”; ao inserir X = “very helpful”, gera-se “What makes you think I am very helpful?”. Observe que há uma inversão de pessoa: o pronome “you” do usuário foi trocado por “I” na resposta do bot.

De fato, uma parte importante das transformações do ELIZA envolve substituir pronomes (eu/você, meu/seu) para que a resposta faça sentido como uma frase do ponto de vista do computador falando com o usuário. Esse algoritmo de substituição é relativamente simples (por exemplo, “meu” → “seu”, “eu” → “você”, etc.), mas essencial para dar a impressão de entendimento gramatical.

\section{Implementação Original e Variações Modernas}

A implementação original de ELIZA foi feita em uma linguagem chamada MAD-SLIP (um dialecto de Lisp) rodando em um mainframe IBM 7094 no sistema CTSS do MIT. O código fonte do programa principal continha o mecanismo de correspondência, enquanto as regras de conversação (script DOCTOR) eram fornecidas separadamente em formato de listas associativas, similar a uma lista em Lisp. Infelizmente, Weizenbaum não publicou o código completo no artigo de 1966 (o que era comum na época), mas décadas depois o código em MAD-SLIP foi recuperado nos arquivos do MIT, comprovando os detalhes de implementação \cite{Lane2025}. De qualquer forma, a arquitetura descrita no artigo influenciou inúmeras reimplementações acadêmicas e didáticas nos anos seguintes.

Diversos entusiastas e pesquisadores reescreveram ELIZA em outras linguagens de programação, dada a simplicidade relativa de seu algoritmo. Ao longo dos anos surgiram versões em Lisp, PL/I, BASIC, Pascal, Prolog, Java, Python, OZ, JavaScript, entre muitas outras. Cada versão normalmente incluía o mesmo conjunto de regras do script terapeuta ou pequenas variações.

As ideias de ELIZA também inspiraram chatbots mais avançados. Poucos anos depois, em 1972, surgiu PARRY, escrito pelo psiquiatra Kenneth Colby, que simulava um paciente paranoico. PARRY tinha um modelo interno de estado emocional e atitudes, mas na camada de linguagem ainda usava muitas respostas baseadas em regras, chegando a “conversar” com o próprio ELIZA em experimentos da época.

Em 1995, Richard Wallace desenvolveu o chatbot ALICE (Artificial Linguistic Internet Computer Entity), que levava o paradigma de ELIZA a uma escala muito maior. ALICE utilizava um formato XML chamado AIML (Artificial Intelligence Markup Language) para definir milhares de categorias de padrões e respostas. Com mais de 16.000 templates mapeando entradas para saídas \cite{Wallace2000}, ALICE conseguia manter diálogos bem mais naturais e abrangentes que o ELIZA original, embora o princípio básico de correspondência de padrões permanecesse. Esse avanço rendeu a ALICE três vitórias no Prêmio Loebner (competição de chatbots) no início dos anos 2000 \cite{Wallace2000}.

Outras variações e sucessores notáveis incluem Jabberwacky (1988) – que já aprendia novas frases – e uma profusão de assistentes virtuais e bots de domínio específico nas décadas seguintes \cite{Wallace2000}. Em suma, o legado de ELIZA perdurou por meio de inúmeros chatbots baseados em regras, até a transição para abordagens estatísticas e de aprendizado de máquina no final do século XX.

\section{Comparação com Modelos de Linguagem Modernos}

A técnica de ELIZA, baseada em palavras-chave com respostas predefinidas, contrasta fortemente com os métodos de Large Language Models (LLMs) atuais, como o GPT-4, que utilizam redes neurais de milhões (ou trilhões) de parâmetros e mecanismos de atenção.

\subsection{Mecanismo de Pesos: Palavras-Chave vs. Atenção Neural}

No ELIZA, a “importância” de uma palavra era determinada manualmente pelo programador através de pesos ou rankings atribuídos a certas palavras-chave no script. Ou seja, o programa não aprendia quais termos focar – ele seguia uma lista fixa de gatilhos. Por exemplo, termos como “sempre” ou “igual” tinham prioridade alta no script DOCTOR para garantir respostas apropriadas.

Em contraste, modelos modernos como o GPT não possuem uma lista fixa de palavras importantes; em vez disso, eles utilizam o mecanismo de self-attention para calcular dinamicamente pesos entre todas as palavras da entrada conforme o contexto \cite{Vaswani2017}.

Na arquitetura Transformer, cada palavra (token) de entrada gera consultas e chaves que interagem com todas as outras, permitindo ao modelo atribuir pesos maiores às palavras mais relevantes daquela frase ou parágrafo \cite{Vaswani2017}. Em outras palavras, o modelo aprende sozinho quais termos ou sequências devem receber mais atenção para produzir a próxima palavra na resposta. Esse mecanismo de atenção captura dependências de longo alcance e nuances contextuais que um sistema de palavras-chave fixas como o ELIZA não consegue representar.

Além disso, o “vocabulário” efetivo de um LLM é imenso – um moddelo GPT pode ser treinado com trilhões de palavras e ter ajustado seus parâmetros para modelar estatisticamente a linguagem humana \cite{Vaswani2017}. Como resultado, pode-se dizer metaforicamente que os LLMs têm uma lista de “palavras-chave” milhões de vezes maior (na prática, distribuída em vetores contínuos) e um método bem mais sofisticado de calcular respostas do que o ELIZA.

Enquanto ELIZA dependia de coincidências exatas de termos para disparar regras, modelos como GPT avaliam similaridades semânticas e contexto histórico graças às representações densas (embeddings) aprendidas durante o treinamento de rede neural.

\subsection{Contextualização e Geração de Linguagem}

Devido à sua abordagem baseada em regras locais, o ELIZA tinha capacidade de contextualização muito limitada. Cada input do usuário era tratado quase isoladamente: o programa não construía uma representação acumulada da conversa, além de artifícios simples como repetir algo mencionado (a estrutura de memória) ou usar pronomes para manter a ilusão de continuidade. Se o usuário mudasse de tópico abruptamente, o ELIZA não “perceberia” – ele apenas buscaria a próxima palavra-chave disponível ou recorreria a frases genéricas.

Em contraste, modelos de linguagem modernos levam em conta um longo histórico de diálogo. Chatbots que usam GPT podem manter um contexto centenas ou milhares de tokens (palavras ou fragmentos) em sua janela de atenção, o que significa que eles conseguem referenciar informações mencionadas vários parágrafos atrás e integrá-las na resposta corrente. O mecanismo de self-attention, em particular, permite que o modelo incorpore relações contextuais complexas: cada palavra gerada pode considerar influências de palavras distantes no texto de entrada \cite{Vaswani2017}.

Por exemplo, ao conversar com um LLM, se você mencionar no início da conversa que tem um irmão chamado Alex e depois perguntar “ele pode me ajudar com o problema?”, o modelo entenderá que “ele” se refere ao Alex mencionado anteriormente (desde que dentro da janela de contexto). Já o ELIZA original não teria como fazer essa ligação, a menos que houvesse uma regra explícita para “ele” e algum armazenamento específico do nome – algo impraticável de antecipar via regras fixas para todos os casos.

Outra diferença crucial está na geração de linguagem. O ELIZA não gera texto original no sentido pleno: suas respostas são em grande parte frases prontas (ou templates fixos) embaralhadas com partes da fala do usuário. Assim, seu vocabulário e estilo são limitados pelo script escrito manualmente. Modelos GPT, por sua vez, geram respostas novas combinando probabilisticamente o conhecimento adquirido de um extenso corpus. Eles não se restringem a repetir trechos da entrada, podendo elaborar explicações, fazer analogias, criar perguntas inéditas – tudo coerente com os exemplos linguísticos em sua base de treinamento. Enquanto ELIZA tendia a responder com perguntas genéricas ou devolvendo as palavras do usuário, os LLMs podem produzir respostas informativas e detalhadas sobre o assunto (pois “aprenderam” uma ampla gama de tópicos durante o treinamento). Por exemplo, se perguntarmos algo factual ou complexo, o ELIZA falharia por não ter nenhuma regra a respeito, provavelmente dando uma resposta vazia. Já um modelo como GPT-4 tentará formular uma resposta baseada em padrões linguísticos aprendidos e em conhecimento implícito dos dados, muitas vezes fornecendo detalhes relevantes.

Em termos de fluência e variedade, os modelos modernos superam o ELIZA amplamente. O ELIZA frequentemente se repetia ou caía em loops verbais quando confrontado com inputs fora do roteiro – um limite claro de sistemas por regras estáticas. Os LLMs produzem linguagem muito mais natural e adaptável, a ponto de muitas vezes enganarem os usuários sobre estarem conversando com uma máquina (um efeito buscado desde o Teste de Turing). Ironicamente, ELIZA nos anos 60 já provocou um precursor desse fenômeno – o chamado Efeito ELIZA, em que pessoas atribuem compreensão ou sentimentos a respostas de computador que, na verdade, são superficiais. Hoje, em chatbots GPT, esse efeito se intensifica pela qualidade das respostas, mas a distinção fundamental permanece: ELIZA seguia scripts sem compreender, enquanto LLMs inferem padrões e significados de forma estatística, sem entendimento consciente, mas atingindo resultados que simulam compreensão de maneira muito mais convincente. 

Em resumo, os avanços de arquitetura (especialmente o mecanismo de atenção) ampliaram drasticamente a capacidade de contextualização e geração dos chatbots modernos, marcando uma evolução significativa desde o mecanismo simples porém pioneiro de ELIZA.

%%%%%%%%%%%%%%%%
%%%%CAPITULO%%%%
%%%%%%%%%%%%%%%%


\chapter{Artificial Intelligence Markup
Language (AIML)}

O Artificial Intelligence Markup Language (AIML) é uma especificação baseada em XML, proposta por \cite{Wallace2009}, destinada à programação de agentes conversacionais, comumente denominados chatbots. A concepção da linguagem prioriza o minimalismo, característica que simplifica o processo de criação de bases de conhecimento por indivíduos sem experiência prévia em programação \cite{Wallace2009}. A arquitetura fundamental de um interpretador AIML genérico é ilustrada na Figura~\ref{fig:interpretador}.

\begin{figure}
    \centering
    \caption{Interpretador AIML arquitetura.}
    \includegraphics[width=0.8\textwidth]{./04-figuras/image8} % Ajuste o caminho se necessário
    \label{fig:interpretador}
    \vspace{0.2cm} % Espaçamento opcional
    {\footnotesize Adaptado de \cite{Silva2007}}
\end{figure}

A técnica central empregada pelo AIML é a correspondência de padrões (\emph{pattern matching}). Este método é amplamente utilizado no desenvolvimento de chatbots, particularmente em sistemas orientados a perguntas e respostas \cite{Abdul-Kader2015}. Uma das metas de projeto do AIML é possibilitar a fusão de bases de conhecimento de múltiplos chatbots especializados em domínios distintos. Teoricamente, um interpretador poderia agregar essas bases, eliminando automaticamente categorias redundantes para formar um \emph{chatbot} mais abrangente \cite{Wallace2000}.

AIML é frequentemente associado aos chatbots de terceira geração \cite{Maria2010} e estima-se sua adoção em mais de 50.000 implementações em diversos idiomas. Extensões da linguagem foram propostas, como o iAIML, que introduziu novas \emph{tags} e incorporou o conceito de intenção com base nos princípios da Teoria da Análise da Conversação (TAC) \cite{Neves2005}. Adicionalmente, ferramentas baseadas na Web foram desenvolvidas para apoiar a construção de bases de conhecimento AIML \cite{Krassmann2017}. Um exemplo proeminente é o \emph{chatbot} ALICE, cuja implementação em AIML compreendia aproximadamente 16.000 categorias, cada uma potencialmente contendo múltiplas \emph{tags} XML aninhadas \cite{Wallace2000}. Uma representação visual desta estrutura de conhecimento é apresentada na Figura~\ref{fig:representacaovisual}.

\begin{figure}
    \centering
    \caption{Representação visual da base de conhecimento do chatbot ALICE.}
    \includegraphics[width=0.7\textwidth]{./04-figuras/image9} % Ajuste o caminho se necessário
    \label{fig:representacaovisual}
    \vspace{0.2cm} % Espaçamento opcional
    {\footnotesize \cite{Wallace2003}}
\end{figure}

\cite{Wallace2000} estabeleceu analogias entre o funcionamento de interpretadores AIML e a teoria do Raciocínio Baseado em Casos (RBC). Nessa perspectiva, as categorias AIML funcionam como "casos", onde o algoritmo identifica o padrão que melhor se alinha à entrada do usuário. Cada categoria estabelece um vínculo direto entre um padrão de estímulo e um modelo de resposta. Consequentemente, chatbots AIML inserem-se na tradição da robótica minimalista, reativa ou de estímulo-resposta \cite{Wallace2000}, conforme esquematizado na Figura~\ref{fig:teoriaestimulo}. Vale notar que a própria técnica de RBC já foi integrada a interpretadores AIML como um mecanismo para consultar fontes de dados externas e expandir a base de conhecimento do agente \cite{Kraus2008}.

\begin{figure}
    \centering
    \caption{Teoria estímulo-resposta aplicada no AIML}
    \includegraphics[width=0.7\textwidth]{./04-figuras/image10} % 
    \label{fig:teoriaestimulo}
    \vspace{0.2cm}
    {\footnotesize \cite{Lima2017}}
\end{figure}

chatbots que utilizam AIML são classificados como sistemas "baseados em recuperação" (\emph{retrieval-based}). Tais modelos operam a partir de um repositório de respostas predefinidas, selecionando a mais apropriada com base na entrada do usuário e no contexto conversacional, guiando assim o fluxo da interação. Esta abordagem é frequentemente empregada na construção de chatbots destinados a operar em domínios de conhecimento restritos \cite{Borah2019}.

A Figura~\ref{fig:exemplodeumabase} demonstra a estrutura elementar de um arquivo AIML. A \emph{tag} \texttt{<category>} encapsula a unidade básica de conhecimento. Internamente, a \emph{tag} \texttt{<pattern>} define o padrão de entrada a ser reconhecido (no exemplo, o caractere curinga \texttt{*}, que corresponde a qualquer entrada), enquanto a \emph{tag} \texttt{<template>} contém a resposta associada. No exemplo ilustrado, o \emph{chatbot} responderia "Hello!" a qualquer interação. Uma visão abstrata da árvore de conhecimento resultante pode ser observada na Figura~\ref{fig:representacaovisualabstrata}. O AIML padrão suporta transições baseadas primariamente em correspondência de padrões, uma limitação inerente, embora extensões específicas de interpretadores possam permitir a integração de outras técnicas de processamento.

\begin{figure}
	\centering
	\caption{Exemplo de uma base de conhecimento em AIML}
	\begin{verbatim}
		<aiml>
		<category>
			<pattern>*</pattern>
			<template>Hello!</template>
		</category>
		</aiml
	\end{verbatim}	
	\label{fig:exemplodeumabase}
	\vspace{0.2cm} % Espaçamento opcional
    {\footnotesize \cite{Wallace2000}}
\end{figure}

\begin{figure}
    \centering
    \caption{Representação visual abstrata de uma base de conhecimento AIML}
    \includegraphics[width=0.8\textwidth]{./04-figuras/image12} % Ajuste o caminho se necessário
    \label{fig:representacaovisualabstrata}
    \vspace{0.2cm} % Espaçamento opcional
    {\footnotesize \url{https://www.pandorabots.com/docs/aiml-fundamentals/}}
\end{figure}

O profissional responsável pela criação, manutenção e curadoria da base de conhecimento de um \emph{chatbot} AIML é denominado \emph{botmaster} \cite{Wallace2000}. Suas atribuições englobam a edição da base (frequentemente via ferramentas auxiliares), a análise de logs de diálogo para identificar padrões de interação e a subsequente criação ou refino de respostas. Este papel pode ser exercido por indivíduos com diferentes perfis, incluindo \emph{webmasters}, desenvolvedores, redatores, engenheiros ou outros interessados na construção de chatbots \cite{Wallace2000}.

Algumas implementações de interpretadores AIML podem incorporar capacidades rudimentares de compreensão semântica através do \emph{Resource Description Framework} (RDF)\footnote{\url{https://github.com/keiffster/program-y/wiki/RDF}}. O RDF é um padrão W3C para representação de informações na Web, usualmente por meio de triplas (sujeito-predicado-objeto) que descrevem relações entre entidades. No contexto AIML, RDF pode ser utilizado para armazenar e consultar fatos. Contudo, mesmo com tais adições, as capacidades linguísticas permanecem aquém da complexidade e do potencial gerativo da linguagem humana, conforme descrito por \cite{chomsky2002syntactic}.

Embora \cite{Hohn2019} argumente que o AIML padrão carece de um conceito explícito de "intenção" (\emph{intent}), similar ao encontrado em plataformas de \emph{Natural Language Understanding} (NLU), é possível emular o reconhecimento de intenções. Isso é tipicamente alcançado definindo categorias que representam "formas canônicas" ou "padrões atômicos" para uma intenção específica\footnote{\url{https://medium.com/pandorabots-blog/new-feature-visualize-your-aiml-26e33a590da1}}. Variações de entrada (e.g., "oi", "olá") podem ser mapeadas para uma categoria canônica (e.g., "saudação") usando a \emph{tag} \texttt{<srai>} (\emph{Symbolic Reduction Artificial Intelligence}), que redireciona o fluxo de processamento (ver Figura~\ref{fig:sodatagsrai}). Dessa forma, um \emph{chatbot} AIML pode gerenciar intenções distintas dentro de seu domínio, como realizar um pedido ou verificar o status de entrega.

\begin{figure}
    \centering
    \caption{Uso da tag \texttt{<srai>}}
    \includegraphics[width=0.5\textwidth]{./04-figuras/image13} % Ajuste o caminho se necessário
    \label{fig:sodatagsrai}
    \vspace{0.2cm} % Espaçamento opcional
    {\footnotesize \cite{DeGasperis2013}}
\end{figure}

chatbots baseados em AIML têm obtido sucesso significativo em competições como o Prêmio Loebner. Notavelmente, o \emph{chatbot} Mitsuku\footnote{\url{https://www.pandorabots.com/mitsuku/}}, desenvolvido por Steve Worswick, conquistou múltiplos títulos recentes\footnote{\url{https://aisb.org.uk/category/loebner-prize/}}, seguindo vitórias anteriores do ALICE. \cite{Wallace2000}.

Adicionalmente, Mitsuku foi classificado em primeiro lugar numa análise comparativa envolvendo oito chatbots \cite{Sharma2020}. Nesse estudo, que avaliou atributos conversacionais com base em um conjunto padronizado de perguntas, o Google Assistant obteve a segunda posição, seguido pela Siri em terceiro. O \emph{chatbot} ALICE. alcançou a quarta posição, enquanto o ELIZA ficou na última colocação entre os sistemas comparados \cite{Sharma2020}.

\section{Tags do AIML 1.0: Explicação e Exemplos}

Esta seção descreve as principais tags do AIML, versão 1.0, com explicações e exemplos.

\paragraph{\texttt{<aiml>}} 

\textbf{Descrição:} Tag raiz que engloba todo o conteúdo AIML. 

\textbf{Exemplo:}

\begin{verbatim}
	<aiml version="1.0">
		<!-- Categorias aqui -->
	</aiml>
\end{verbatim}

\paragraph{\texttt{<category>}} 

\textbf{Descrição:} Unidade básica de conhecimento, contendo um padrão e uma resposta. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>OLÁ</pattern>
		<template>Oi! Como posso ajudar você hoje?</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<pattern>}} 

\textbf{Descrição:} Define o padrão de entrada do usuário, com curingas como \texttt{*} e \texttt{\_}. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>EU GOSTO DE *</pattern>
		<template>Que bom que você gosta de <star/>!</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<template>}} 

\textbf{Descrição:} Define a resposta do bot ao padrão correspondente. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>QUAL É O SEU NOME</pattern>
		<template>Meu nome é Grok.</template>
	</category> 
\end{verbatim}

\paragraph{\texttt{<star/>}} 

\textbf{Descrição:} Captura o conteúdo do curinga \texttt{*} ou \texttt{\_}. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>MEU NOME É *</pattern>
		<template>Olá, <star/>!</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<that>}} 

\textbf{Descrição:} Considera a última resposta do bot para decidir a próxima. 

\textbf{Exemplo:}

\begin{verbatim}
<category>
	<pattern>SIM</pattern>
	<that>Você gosta de programar?</that>
	<template>Ótimo! Qual linguagem você prefere?</template>
</category>
\end{verbatim}

\paragraph{\texttt{<topic>}} 

\textbf{Descrição:} Define um contexto ou tópico para categorias. 

\textbf{Exemplo:}

\begin{verbatim}
<category>
  <pattern>VAMOS FALAR SOBRE ESPORTE</pattern>
  <template>Ok! <topic name="esporte"/></template>
</category>
\end{verbatim}

\paragraph{\texttt{<random>} e \texttt{<li>}} 

\textbf{Descrição:} Escolhe aleatoriamente uma resposta de uma lista. 

\textbf{Exemplo:}

\begin{verbatim}
<category>
  <pattern>COMO ESTÁ O TEMPO</pattern>
  <template>
    <random>
      <li>Está ensolarado!</li>
      <li>Está chovendo.</li>
    </random>
  </template>
</category>
\end{verbatim}

\paragraph{\texttt{<condition>}} 

\textbf{Descrição:} Adiciona lógica condicional baseada em variáveis. 

\textbf{Exemplo:}

\begin{verbatim}
<category>
  <pattern>COMO EU ESTOU</pattern>
  <template>
    <condition name="humor">
      <li value="feliz">Você está bem!</li>
      <li>Não sei ainda!</li>
    </condition>
  </template>
</category>
\end{verbatim}

\paragraph{\texttt{<set>} e \texttt{<get>}} 

\textbf{Descrição:} Define e recupera variáveis. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>MEU NOME É *</pattern>
		<template><set name="nome"><star/></set>Olá, <get name="nome"/>!</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<srai>}} 

\textbf{Descrição:} Redireciona a entrada para outro padrão. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>OI</pattern>
		<template><srai>OLÁ</srai></template>
	</category>
\end{verbatim}

\paragraph{\texttt{<think>}} 

\textbf{Descrição:} Executa ações sem exibir o conteúdo. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>EU SOU TRISTE</pattern>
		<template><think><set name="humor">triste</set></think>Sinto muito!</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<person>}, \texttt{<person2>}, \texttt{<gender>}} 

\textbf{Descrição:} Transforma pronomes ou ajusta gênero. 

\textbf{Exemplo:}

\begin{verbatim}
	<category>
		<pattern>EU TE AMO</pattern>
		<template><person><star/></person> ama você também!</template>
	</category>
\end{verbatim}

\paragraph{\texttt{<formal>}, \texttt{<uppercase>}, \texttt{<lowercase>}} 

\textbf{Descrição:} Formata texto (capitaliza, maiúsculas, minúsculas). 

\textbf{Exemplo:}

\begin{verbatim}
<category>
  <pattern>MEU NOME É joão</pattern>
  <template>Olá, <formal><star/></formal>!</template>
</category>
\end{verbatim}

\paragraph{\texttt{<sentence>}} 

\textbf{Descrição:} Formata como frase (primeira letra maiúscula, ponto final). 

\textbf{Exemplo:}

\begin{verbatim}
<category>
  <pattern>oi</pattern>
  <template><sentence><star/></sentence></template>
</category>
\end{verbatim}

%%%%%%%%%%%%%%%%
%%%%CAPITULO%%%%
%%%%%%%%%%%%%%%%

\chapter{Chatbot ELIZA em Python}

Apresenta-se, nesta seção, uma implementação simplificada em Python de um chatbot inspirado no paradigma ELIZA. Esta implementação demonstra a utilização de expressões regulares para a identificação de padrões textuais (palavras-chave) na entrada fornecida pelo usuário e a subsequente geração de respostas, fundamentada em regras de transformação predefinidas manualmente.

\vspace{\baselineskip}
\href{https://colab.research.google.com/github/giseldo/chatbotbook/blob/main/notebook/eliza.ipynb}{
  \includegraphics{fig/colab-badge.png}
}

\begin{verbatim}
import re  
import random  

regras = [
    (re.compile(r'\b(hello|hi|hey)\b', re.IGNORECASE),
     ["Hello. How do you do. Please tell me your problem."]),

    (re.compile(r'\b(I am|I\'?m) (.+)', re.IGNORECASE),
     ["How long have you been {1}?",   
      "Why do you think you are {1}?"]),

    (re.compile(r'\bI need (.+)', re.IGNORECASE),
     ["Why do you need {1}?",
      "Would it really help you to get {1}?"]),

    (re.compile(r'\bI can\'?t (.+)', re.IGNORECASE),
     ["What makes you think you can't {1}?",
      "Have you tried {1}?"]),

    (re.compile(r'\bmy (mother|father|mom|dad)\b', re.IGNORECASE),
     ["Tell me more about your family.",
      "How do you feel about your parents?"]),

    (re.compile(r'\b(sorry)\b', re.IGNORECASE),
     ["Please don't apologize."]),

    (re.compile(r'\b(maybe|perhaps)\b', re.IGNORECASE),
     ["You don't seem certain."]),

    (re.compile(r'\bbecause\b', re.IGNORECASE),
     ["Is that the real reason?"]),

    (re.compile(r'\b(are you|do you) (.+)\?$', re.IGNORECASE),
     ["Why do you ask that?"]),

    (re.compile(r'\bcomputer\b', re.IGNORECASE),
     ["Do computers worry you?"]),
]

respostas_padrao = [
    "I see.",  
    "Please tell me more.",  
    "Can you elaborate on that?"  
]

def response(entrada_usuario):
    for padrao, respostas in regras:
        match = padrao.search(entrada_usuario)  
        if match:
            resposta = random.choice(respostas)
            if match.groups():
                resposta = resposta.format(*match.groups())
            return resposta
    return random.choice(respostas_padrao)


# Exemplo de uso
print("User: Hello.")
print("Bot: " + response("Hello."))

print("User: I am feeling sad.")
print("Bot: " + response("I am feeling sad."))

print("Maybe I was not good enough.")
print("Bot: " + response("Maybe I was not good enough."))

print("My mother tried to help.")
print("Bot: " + response("My mother tried to help."))

\end{verbatim}

Na implementação, são definidos múltiplos padrões de expressões regulares que correspondem a palavras-chave ou estruturas frasais de interesse (e.g., saudações, construções como ``I am'' ou ``I need'', referências a termos familiares). A função \texttt{response}, ao receber uma string de entrada, itera sequencialmente sobre essas regras. Para cada regra, utiliza-se o método \texttt{padrao.search(entrada)} para verificar a ocorrência do padrão correspondente na sentença do usuário.

Quando uma correspondência (match) é encontrada, uma resposta associada à regra é selecionada. É relevante notar que diversas respostas predefinidas contêm marcadores (placeholders), como \texttt{\{1\}}. Estes marcadores são dinamicamente substituídos pelo conteúdo dos grupos capturados pela expressão regular na entrada original do usuário. Por exemplo, se a entrada for \textit{``I am sad''} e esta corresponder a um padrão como \texttt{r"I am (.*)"}, o grupo capturado (\texttt{(.*)}) conterá a string \textit{``sad''}. Se a resposta associada for \textit{``Why do you think you are \{1\}?''}, o sistema a formatará como \textit{``Why do you think you are sad?''}, substituindo \texttt{\{1\}} pelo conteúdo do primeiro grupo capturado.

Na ausência de correspondência com qualquer regra específica, o sistema seleciona aleatoriamente uma resposta genérica a partir de um conjunto predefinido (denominado, por exemplo, \texttt{respostas\_padrao}), tal como \textit{``I see.''}.

% Usando \paragraph para um subtítulo menos proeminente, ou use \subsubsection se preferir
\subsection{Exemplo de Interação}

\begin{verbatim}
Usuário: Hello
Bot: Hello. How do you do. Please tell me your problem.

Usuário: I am feeling sad
Bot: Why do you think you are feeling sad?

Usuário: Because I lost my job
Bot: Is that the real reason?

Usuário: Maybe I was not good enough.
Bot: You don't seem certain.

Usuário: My mother tried to help.
Bot: Tell me more about your family.
\end{verbatim}

Observa-se na interação que o chatbot inicialmente respondeu à saudação (\textit{``Hello...''}) com base na regra 1. Em seguida, a entrada \textit{``I am sad''} ativou a regra 2, resultando em uma resposta que incorpora o termo \textit{``sad''}. A interação prossegue com o sistema respondendo a entradas iniciadas por \textit{``Because...''} (regra 8) e \textit{``Maybe...''} (regra 7), entre outras. Cada resposta gerada foi determinada pela regra correspondente ativada e pelo conteúdo específico da sentença do usuário, mimetizando o comportamento baseado em padrões do sistema ELIZA original \cite{Abdul-Kader2015}.

%%%%%%%%%%%%%%%%
%%%%CAPITULO%%%%
%%%%%%%%%%%%%%%%

\chapter{LangChain}

LangChain é uma biblioteca de software de código aberto projetada para simplificar a interação com Large Language Models (LLMs) e construir aplicativos de processamento de linguagem natural robustos. Ele fornece uma camada de abstração de alto nível sobre as complexidades de trabalhar diretamente com modelos de linguagem, tornando mais acessível a criação de aplicativos de compreensão e geração de linguagem.

\section{Por que usar LangChain?}

Trabalhar com LLMs pode ser complexo devido à sua natureza sofisticada e aos requisitos de recursos computacionais. LangChain lida com muitos detalhes complexos em segundo plano, permitindo que os desenvolvedores se concentrem na construção de aplicativos de linguagem eficazes. Aqui estão algumas vantagens do uso do LangChain:

\begin{itemize}
    \item Simplicidade: LangChain oferece uma API simples e intuitiva, ocultando os detalhes complexos de interação com LLMs. Ele abstrai as nuances de carregar modelos, gerenciar recursos computacionais e executar previsões.
    
    \item Flexibilidade: A biblioteca suporta vários frameworks de deep learning, como TensorFlow e PyTorch, e pode ser integrada a diferentes LLMs. Isso oferece aos desenvolvedores a flexibilidade de escolher as ferramentas e modelos que melhor atendem às suas necessidades.
    
    \item Extensibilidade: LangChain é projetado para ser extensível, permitindo que os usuários criem seus próprios componentes personalizados. Você pode adicionar novos modelos, adaptar o processamento de texto ou desenvolver recursos específicos do domínio para atender aos requisitos exclusivos do seu aplicativo.
    
    \item Comunidade e suporte: LangChain tem uma comunidade ativa de desenvolvedores e pesquisadores que contribuem para o projeto. A documentação abrangente, tutoriais e suporte da comunidade tornam mais fácil começar e navegar por quaisquer desafios que surgirem durante o desenvolvimento.
    
\end{itemize}
\section{Arquitetura do LangChain}

A arquitetura do LangChain pode ser entendida em três componentes principais:

Camada de Abstração: Esta camada fornece uma interface simples e unificada para interagir com diferentes LLMs. Ele abstrai as complexidades de carregar, inicializar e executar previsões em modelos, oferecendo uma API consistente independentemente do modelo subjacente.

Camada de Processamento de Texto: O LangChain inclui ferramentas robustas para processamento de texto, incluindo tokenização, análise sintática, reconhecimento de entidades nomeadas (NER) e muito mais. Esta camada prepara os dados de entrada e saída para que possam ser processados de forma eficaz pelos modelos de linguagem.

Camada de Modelo: Aqui é onde os próprios LLMs residem. O LangChain suporta uma variedade de modelos de linguagem, desde modelos pré-treinados de uso geral até modelos personalizados específicos de domínio. Esta camada lida com a execução de previsões, gerenciamento de recursos computacionais e interação com as APIs dos modelos.

\section{Exemplo Básico: Consultando um LLM}

Vamos ver um exemplo simples de como usar o LangChain para consultar um LLM e obter uma resposta. Neste exemplo, usaremos um modelo de linguagem de uso geral, como o GPT-3, para responder a uma pergunta.

Primeiro, importe as bibliotecas necessárias e configure o cliente LangChain. Em seguida, carregue o modelo de linguagem desejado. Para este exemplo, usaremos o modelo GPT-3. Agora, você pode usar o modelo para fazer uma consulta. Vamos perguntar ao modelo sobre a capital da França.

Instale as dendências necessárias:

\begin{verbatim}
	$ pip install langchain transformers torch langchain_community
\end{verbatim}

Código-Fonte:

\begin{verbatim}
	from langchain.chat_models import init_chat_model
	import os

	OPENAI_API_KEY =  os.environ.get("OPENAI_API_KEY")

	model = init_chat_model("gpt-4o-mini", model_provider="openai", openai_api_key=OPENAI_API_KEY)

	response = model.invoke([
	{"role":"user", "content": "quem é o presidente do Brasil?"}
	])

	print(response.content)

	print(response.text)

\end{verbatim}

Este exemplo básico demonstra a simplicidade de usar o LangChain para interagir com LLMs. No entanto, o LangChain oferece muito mais recursos e funcionalidades para construir aplicativos de chatbot mais robustos.

\bibliographystyle{plain}
\bibliography{ref}

\end{document}